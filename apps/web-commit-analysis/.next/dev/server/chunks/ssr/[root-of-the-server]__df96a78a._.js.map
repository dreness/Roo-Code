{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/schema.ts"],"sourcesContent":["import { sqliteTable, text, integer, real, uniqueIndex, index } from \"drizzle-orm/sqlite-core\"\nimport { relations } from \"drizzle-orm\"\n\n// Core commit metadata\nexport const commits = sqliteTable(\n\t\"commits\",\n\t{\n\t\tsha: text(\"sha\").primaryKey(),\n\t\tshortSha: text(\"short_sha\").notNull(),\n\t\tauthor: text(\"author\").notNull(),\n\t\tauthorEmail: text(\"author_email\").notNull(),\n\t\tdate: integer(\"date\", { mode: \"timestamp\" }).notNull(),\n\t\tmessage: text(\"message\").notNull(),\n\t\tmessageType: text(\"message_type\"), // fix, feat, chore, etc.\n\t\tmessageScope: text(\"message_scope\"), // e.g., \"ui\", \"provider\"\n\t\tprNumber: integer(\"pr_number\"),\n\t\tfilesChanged: integer(\"files_changed\").default(0),\n\t\tinsertions: integer(\"insertions\").default(0),\n\t\tdeletions: integer(\"deletions\").default(0),\n\t\tanalyzedAt: integer(\"analyzed_at\", { mode: \"timestamp\" }),\n\t\tdeepAnalyzedAt: integer(\"deep_analyzed_at\", { mode: \"timestamp\" }),\n\t},\n\t(table) => [index(\"commits_date_idx\").on(table.date), index(\"commits_message_type_idx\").on(table.messageType)],\n)\n\nexport const commitsRelations = relations(commits, ({ many, one }) => ({\n\tfileChanges: many(fileChanges),\n\tclassification: one(classifications, {\n\t\tfields: [commits.sha],\n\t\treferences: [classifications.commitSha],\n\t}),\n\tcausedBugs: many(bugCausality, { relationName: \"causedBugs\" }),\n\tfixedBy: many(bugCausality, { relationName: \"fixedBy\" }),\n}))\n\n// Per-file change details\nexport const fileChanges = sqliteTable(\n\t\"file_changes\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tcommitSha: text(\"commit_sha\")\n\t\t\t.notNull()\n\t\t\t.references(() => commits.sha, { onDelete: \"cascade\" }),\n\t\tfilePath: text(\"file_path\").notNull(),\n\t\tchangeType: text(\"change_type\", { enum: [\"A\", \"M\", \"D\", \"R\"] }).notNull(),\n\t\tinsertions: integer(\"insertions\").default(0),\n\t\tdeletions: integer(\"deletions\").default(0),\n\t\tsubsystem: text(\"subsystem\"),\n\t},\n\t(table) => [\n\t\tindex(\"file_changes_commit_sha_idx\").on(table.commitSha),\n\t\tindex(\"file_changes_subsystem_idx\").on(table.subsystem),\n\t],\n)\n\nexport const fileChangesRelations = relations(fileChanges, ({ one }) => ({\n\tcommit: one(commits, {\n\t\tfields: [fileChanges.commitSha],\n\t\treferences: [commits.sha],\n\t}),\n}))\n\n// Commit category enum values\nexport const commitCategories = [\n\t\"bugfix\",\n\t\"feature\",\n\t\"refactor\",\n\t\"documentation\",\n\t\"test\",\n\t\"build\",\n\t\"ci\",\n\t\"chore\",\n\t\"style\",\n\t\"performance\",\n\t\"revert\",\n\t\"unknown\",\n] as const\n\nexport type CommitCategory = (typeof commitCategories)[number]\n\n// Analysis results\nexport const classifications = sqliteTable(\n\t\"classifications\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tcommitSha: text(\"commit_sha\")\n\t\t\t.notNull()\n\t\t\t.references(() => commits.sha, { onDelete: \"cascade\" }),\n\t\tcategory: text(\"category\", { enum: commitCategories }).notNull(),\n\t\tconfidence: real(\"confidence\").notNull().default(0),\n\t\tflags: text(\"flags\", { mode: \"json\" }).$type<string[]>().default([]),\n\t\triskScore: real(\"risk_score\").notNull().default(0),\n\t\tanalysisVersion: integer(\"analysis_version\").notNull().default(1),\n\t},\n\t(table) => [\n\t\tuniqueIndex(\"classifications_commit_sha_idx\").on(table.commitSha),\n\t\tindex(\"classifications_category_idx\").on(table.category),\n\t\tindex(\"classifications_risk_score_idx\").on(table.riskScore),\n\t],\n)\n\nexport const classificationsRelations = relations(classifications, ({ one }) => ({\n\tcommit: one(commits, {\n\t\tfields: [classifications.commitSha],\n\t\treferences: [commits.sha],\n\t}),\n}))\n\n// Version releases\nexport const releases = sqliteTable(\n\t\"releases\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tversion: text(\"version\").notNull().unique(),\n\t\tdate: integer(\"date\", { mode: \"timestamp\" }).notNull(),\n\t\ttagSha: text(\"tag_sha\"),\n\t\tfixCount: integer(\"fix_count\").default(0),\n\t\tfeatureCount: integer(\"feature_count\").default(0),\n\t\ttotalRisk: real(\"total_risk\").default(0),\n\t},\n\t(table) => [index(\"releases_date_idx\").on(table.date)],\n)\n\n// Bug causality relationship types\nexport const relationshipTypes = [\"root_cause\", \"related_to\"] as const\nexport type RelationshipType = (typeof relationshipTypes)[number]\n\n// Bug causality - Links bug fixes to their root causes\nexport const bugCausality = sqliteTable(\n\t\"bug_causality\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tbugFixSha: text(\"bug_fix_sha\")\n\t\t\t.notNull()\n\t\t\t.references(() => commits.sha, { onDelete: \"cascade\" }),\n\t\tcauseSha: text(\"cause_sha\")\n\t\t\t.notNull()\n\t\t\t.references(() => commits.sha, { onDelete: \"cascade\" }),\n\t\trelationshipType: text(\"relationship_type\", { enum: relationshipTypes }).notNull(),\n\t\tconfidence: real(\"confidence\").notNull().default(0),\n\t\tbugAge: integer(\"bug_age\"), // Days between cause and fix\n\t\tbugAgeCommits: integer(\"bug_age_commits\"), // Commits between cause and fix\n\t\tanalysisMethod: text(\"analysis_method\"),\n\t\tnotes: text(\"notes\"),\n\t\tcreatedAt: integer(\"created_at\", { mode: \"timestamp\" }).notNull(),\n\t\tverifiedAt: integer(\"verified_at\", { mode: \"timestamp\" }),\n\t\tverifiedBy: text(\"verified_by\"),\n\t},\n\t(table) => [\n\t\tindex(\"bug_causality_bug_fix_sha_idx\").on(table.bugFixSha),\n\t\tindex(\"bug_causality_cause_sha_idx\").on(table.causeSha),\n\t\tuniqueIndex(\"bug_causality_unique_idx\").on(table.bugFixSha, table.causeSha),\n\t],\n)\n\nexport const bugCausalityRelations = relations(bugCausality, ({ one }) => ({\n\tbugFix: one(commits, {\n\t\tfields: [bugCausality.bugFixSha],\n\t\treferences: [commits.sha],\n\t\trelationName: \"fixedBy\",\n\t}),\n\tcause: one(commits, {\n\t\tfields: [bugCausality.causeSha],\n\t\treferences: [commits.sha],\n\t\trelationName: \"causedBugs\",\n\t}),\n}))\n\n// Regression pattern severity levels\nexport const severityLevels = [\"low\", \"medium\", \"high\"] as const\nexport type SeverityLevel = (typeof severityLevels)[number]\n\n// Regression pattern status\nexport const patternStatuses = [\"active\", \"resolved\"] as const\nexport type PatternStatus = (typeof patternStatuses)[number]\n\n// Regression patterns - Recurring issues\nexport const regressionPatterns = sqliteTable(\n\t\"regression_patterns\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tpatternHash: text(\"pattern_hash\").notNull().unique(),\n\t\tsubsystem: text(\"subsystem\"),\n\t\tkeywords: text(\"keywords\", { mode: \"json\" }).$type<string[]>().default([]),\n\t\tfilePatterns: text(\"file_patterns\", { mode: \"json\" }).$type<string[]>().default([]),\n\t\tfirstOccurrence: text(\"first_occurrence\").references(() => commits.sha),\n\t\toccurrenceCount: integer(\"occurrence_count\").default(1),\n\t\tcommitShas: text(\"commit_shas\", { mode: \"json\" }).$type<string[]>().default([]),\n\t\tseverity: text(\"severity\", { enum: severityLevels }).default(\"low\"),\n\t\tstatus: text(\"status\", { enum: patternStatuses }).default(\"active\"),\n\t\tcreatedAt: integer(\"created_at\", { mode: \"timestamp\" }).notNull(),\n\t\tupdatedAt: integer(\"updated_at\", { mode: \"timestamp\" }).notNull(),\n\t},\n\t(table) => [index(\"regression_patterns_subsystem_idx\").on(table.subsystem), index(\"regression_patterns_status_idx\").on(table.status)],\n)\n\n// Analysis cache types\nexport const cacheTypes = [\"blame\", \"bisect\", \"diff\", \"log\"] as const\nexport type CacheType = (typeof cacheTypes)[number]\n\n// Analysis cache - Speed up future analysis\nexport const analysisCache = sqliteTable(\n\t\"analysis_cache\",\n\t{\n\t\tid: integer(\"id\").primaryKey({ autoIncrement: true }),\n\t\tcacheKey: text(\"cache_key\").notNull().unique(),\n\t\tcacheType: text(\"cache_type\", { enum: cacheTypes }).notNull(),\n\t\tfilePath: text(\"file_path\"),\n\t\tlineRange: text(\"line_range\"),\n\t\tresultSha: text(\"result_sha\"),\n\t\tresultData: text(\"result_data\", { mode: \"json\" }),\n\t\tcreatedAt: integer(\"created_at\", { mode: \"timestamp\" }).notNull(),\n\t\texpiresAt: integer(\"expires_at\", { mode: \"timestamp\" }),\n\t},\n\t(table) => [index(\"analysis_cache_cache_type_idx\").on(table.cacheType), index(\"analysis_cache_expires_at_idx\").on(table.expiresAt)],\n)\n\n// Type exports\nexport type Commit = typeof commits.$inferSelect\nexport type InsertCommit = Omit<typeof commits.$inferInsert, \"analyzedAt\" | \"deepAnalyzedAt\">\nexport type UpdateCommit = Partial<Omit<Commit, \"sha\">>\n\nexport type FileChange = typeof fileChanges.$inferSelect\nexport type InsertFileChange = Omit<typeof fileChanges.$inferInsert, \"id\">\n\nexport type Classification = typeof classifications.$inferSelect\nexport type InsertClassification = Omit<typeof classifications.$inferInsert, \"id\">\nexport type UpdateClassification = Partial<Omit<Classification, \"id\" | \"commitSha\">>\n\nexport type Release = typeof releases.$inferSelect\nexport type InsertRelease = Omit<typeof releases.$inferInsert, \"id\">\n\nexport type BugCausality = typeof bugCausality.$inferSelect\nexport type InsertBugCausality = Omit<typeof bugCausality.$inferInsert, \"id\" | \"createdAt\">\n\nexport type RegressionPattern = typeof regressionPatterns.$inferSelect\nexport type InsertRegressionPattern = Omit<typeof regressionPatterns.$inferInsert, \"id\" | \"createdAt\" | \"updatedAt\">\n\nexport type AnalysisCache = typeof analysisCache.$inferSelect\nexport type InsertAnalysisCache = Omit<typeof analysisCache.$inferInsert, \"id\" | \"createdAt\">\n\n// Schema bundle for Drizzle\nexport const schema = {\n\tcommits,\n\tcommitsRelations,\n\tfileChanges,\n\tfileChangesRelations,\n\tclassifications,\n\tclassificationsRelations,\n\treleases,\n\tbugCausality,\n\tbugCausalityRelations,\n\tregressionPatterns,\n\tanalysisCache,\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;;AAGO,MAAM,UAAU,IAAA,gYAAW,EACjC,WACA;IACC,KAAK,IAAA,mYAAI,EAAC,OAAO,UAAU;IAC3B,UAAU,IAAA,mYAAI,EAAC,aAAa,OAAO;IACnC,QAAQ,IAAA,mYAAI,EAAC,UAAU,OAAO;IAC9B,aAAa,IAAA,mYAAI,EAAC,gBAAgB,OAAO;IACzC,MAAM,IAAA,yYAAO,EAAC,QAAQ;QAAE,MAAM;IAAY,GAAG,OAAO;IACpD,SAAS,IAAA,mYAAI,EAAC,WAAW,OAAO;IAChC,aAAa,IAAA,mYAAI,EAAC;IAClB,cAAc,IAAA,mYAAI,EAAC;IACnB,UAAU,IAAA,yYAAO,EAAC;IAClB,cAAc,IAAA,yYAAO,EAAC,iBAAiB,OAAO,CAAC;IAC/C,YAAY,IAAA,yYAAO,EAAC,cAAc,OAAO,CAAC;IAC1C,WAAW,IAAA,yYAAO,EAAC,aAAa,OAAO,CAAC;IACxC,YAAY,IAAA,yYAAO,EAAC,eAAe;QAAE,MAAM;IAAY;IACvD,gBAAgB,IAAA,yYAAO,EAAC,oBAAoB;QAAE,MAAM;IAAY;AACjE,GACA,CAAC,QAAU;QAAC,IAAA,4XAAK,EAAC,oBAAoB,EAAE,CAAC,MAAM,IAAI;QAAG,IAAA,4XAAK,EAAC,4BAA4B,EAAE,CAAC,MAAM,WAAW;KAAE;AAGxG,MAAM,mBAAmB,IAAA,gXAAS,EAAC,SAAS,CAAC,EAAE,IAAI,EAAE,GAAG,EAAE,GAAK,CAAC;QACtE,aAAa,KAAK;QAClB,gBAAgB,IAAI,iBAAiB;YACpC,QAAQ;gBAAC,QAAQ,GAAG;aAAC;YACrB,YAAY;gBAAC,gBAAgB,SAAS;aAAC;QACxC;QACA,YAAY,KAAK,cAAc;YAAE,cAAc;QAAa;QAC5D,SAAS,KAAK,cAAc;YAAE,cAAc;QAAU;IACvD,CAAC;AAGM,MAAM,cAAc,IAAA,gYAAW,EACrC,gBACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,WAAW,IAAA,mYAAI,EAAC,cACd,OAAO,GACP,UAAU,CAAC,IAAM,QAAQ,GAAG,EAAE;QAAE,UAAU;IAAU;IACtD,UAAU,IAAA,mYAAI,EAAC,aAAa,OAAO;IACnC,YAAY,IAAA,mYAAI,EAAC,eAAe;QAAE,MAAM;YAAC;YAAK;YAAK;YAAK;SAAI;IAAC,GAAG,OAAO;IACvE,YAAY,IAAA,yYAAO,EAAC,cAAc,OAAO,CAAC;IAC1C,WAAW,IAAA,yYAAO,EAAC,aAAa,OAAO,CAAC;IACxC,WAAW,IAAA,mYAAI,EAAC;AACjB,GACA,CAAC,QAAU;QACV,IAAA,4XAAK,EAAC,+BAA+B,EAAE,CAAC,MAAM,SAAS;QACvD,IAAA,4XAAK,EAAC,8BAA8B,EAAE,CAAC,MAAM,SAAS;KACtD;AAGK,MAAM,uBAAuB,IAAA,gXAAS,EAAC,aAAa,CAAC,EAAE,GAAG,EAAE,GAAK,CAAC;QACxE,QAAQ,IAAI,SAAS;YACpB,QAAQ;gBAAC,YAAY,SAAS;aAAC;YAC/B,YAAY;gBAAC,QAAQ,GAAG;aAAC;QAC1B;IACD,CAAC;AAGM,MAAM,mBAAmB;IAC/B;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;CACA;AAKM,MAAM,kBAAkB,IAAA,gYAAW,EACzC,mBACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,WAAW,IAAA,mYAAI,EAAC,cACd,OAAO,GACP,UAAU,CAAC,IAAM,QAAQ,GAAG,EAAE;QAAE,UAAU;IAAU;IACtD,UAAU,IAAA,mYAAI,EAAC,YAAY;QAAE,MAAM;IAAiB,GAAG,OAAO;IAC9D,YAAY,IAAA,mYAAI,EAAC,cAAc,OAAO,GAAG,OAAO,CAAC;IACjD,OAAO,IAAA,mYAAI,EAAC,SAAS;QAAE,MAAM;IAAO,GAAG,KAAK,GAAa,OAAO,CAAC,EAAE;IACnE,WAAW,IAAA,mYAAI,EAAC,cAAc,OAAO,GAAG,OAAO,CAAC;IAChD,iBAAiB,IAAA,yYAAO,EAAC,oBAAoB,OAAO,GAAG,OAAO,CAAC;AAChE,GACA,CAAC,QAAU;QACV,IAAA,kYAAW,EAAC,kCAAkC,EAAE,CAAC,MAAM,SAAS;QAChE,IAAA,4XAAK,EAAC,gCAAgC,EAAE,CAAC,MAAM,QAAQ;QACvD,IAAA,4XAAK,EAAC,kCAAkC,EAAE,CAAC,MAAM,SAAS;KAC1D;AAGK,MAAM,2BAA2B,IAAA,gXAAS,EAAC,iBAAiB,CAAC,EAAE,GAAG,EAAE,GAAK,CAAC;QAChF,QAAQ,IAAI,SAAS;YACpB,QAAQ;gBAAC,gBAAgB,SAAS;aAAC;YACnC,YAAY;gBAAC,QAAQ,GAAG;aAAC;QAC1B;IACD,CAAC;AAGM,MAAM,WAAW,IAAA,gYAAW,EAClC,YACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,SAAS,IAAA,mYAAI,EAAC,WAAW,OAAO,GAAG,MAAM;IACzC,MAAM,IAAA,yYAAO,EAAC,QAAQ;QAAE,MAAM;IAAY,GAAG,OAAO;IACpD,QAAQ,IAAA,mYAAI,EAAC;IACb,UAAU,IAAA,yYAAO,EAAC,aAAa,OAAO,CAAC;IACvC,cAAc,IAAA,yYAAO,EAAC,iBAAiB,OAAO,CAAC;IAC/C,WAAW,IAAA,mYAAI,EAAC,cAAc,OAAO,CAAC;AACvC,GACA,CAAC,QAAU;QAAC,IAAA,4XAAK,EAAC,qBAAqB,EAAE,CAAC,MAAM,IAAI;KAAE;AAIhD,MAAM,oBAAoB;IAAC;IAAc;CAAa;AAItD,MAAM,eAAe,IAAA,gYAAW,EACtC,iBACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,WAAW,IAAA,mYAAI,EAAC,eACd,OAAO,GACP,UAAU,CAAC,IAAM,QAAQ,GAAG,EAAE;QAAE,UAAU;IAAU;IACtD,UAAU,IAAA,mYAAI,EAAC,aACb,OAAO,GACP,UAAU,CAAC,IAAM,QAAQ,GAAG,EAAE;QAAE,UAAU;IAAU;IACtD,kBAAkB,IAAA,mYAAI,EAAC,qBAAqB;QAAE,MAAM;IAAkB,GAAG,OAAO;IAChF,YAAY,IAAA,mYAAI,EAAC,cAAc,OAAO,GAAG,OAAO,CAAC;IACjD,QAAQ,IAAA,yYAAO,EAAC;IAChB,eAAe,IAAA,yYAAO,EAAC;IACvB,gBAAgB,IAAA,mYAAI,EAAC;IACrB,OAAO,IAAA,mYAAI,EAAC;IACZ,WAAW,IAAA,yYAAO,EAAC,cAAc;QAAE,MAAM;IAAY,GAAG,OAAO;IAC/D,YAAY,IAAA,yYAAO,EAAC,eAAe;QAAE,MAAM;IAAY;IACvD,YAAY,IAAA,mYAAI,EAAC;AAClB,GACA,CAAC,QAAU;QACV,IAAA,4XAAK,EAAC,iCAAiC,EAAE,CAAC,MAAM,SAAS;QACzD,IAAA,4XAAK,EAAC,+BAA+B,EAAE,CAAC,MAAM,QAAQ;QACtD,IAAA,kYAAW,EAAC,4BAA4B,EAAE,CAAC,MAAM,SAAS,EAAE,MAAM,QAAQ;KAC1E;AAGK,MAAM,wBAAwB,IAAA,gXAAS,EAAC,cAAc,CAAC,EAAE,GAAG,EAAE,GAAK,CAAC;QAC1E,QAAQ,IAAI,SAAS;YACpB,QAAQ;gBAAC,aAAa,SAAS;aAAC;YAChC,YAAY;gBAAC,QAAQ,GAAG;aAAC;YACzB,cAAc;QACf;QACA,OAAO,IAAI,SAAS;YACnB,QAAQ;gBAAC,aAAa,QAAQ;aAAC;YAC/B,YAAY;gBAAC,QAAQ,GAAG;aAAC;YACzB,cAAc;QACf;IACD,CAAC;AAGM,MAAM,iBAAiB;IAAC;IAAO;IAAU;CAAO;AAIhD,MAAM,kBAAkB;IAAC;IAAU;CAAW;AAI9C,MAAM,qBAAqB,IAAA,gYAAW,EAC5C,uBACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,aAAa,IAAA,mYAAI,EAAC,gBAAgB,OAAO,GAAG,MAAM;IAClD,WAAW,IAAA,mYAAI,EAAC;IAChB,UAAU,IAAA,mYAAI,EAAC,YAAY;QAAE,MAAM;IAAO,GAAG,KAAK,GAAa,OAAO,CAAC,EAAE;IACzE,cAAc,IAAA,mYAAI,EAAC,iBAAiB;QAAE,MAAM;IAAO,GAAG,KAAK,GAAa,OAAO,CAAC,EAAE;IAClF,iBAAiB,IAAA,mYAAI,EAAC,oBAAoB,UAAU,CAAC,IAAM,QAAQ,GAAG;IACtE,iBAAiB,IAAA,yYAAO,EAAC,oBAAoB,OAAO,CAAC;IACrD,YAAY,IAAA,mYAAI,EAAC,eAAe;QAAE,MAAM;IAAO,GAAG,KAAK,GAAa,OAAO,CAAC,EAAE;IAC9E,UAAU,IAAA,mYAAI,EAAC,YAAY;QAAE,MAAM;IAAe,GAAG,OAAO,CAAC;IAC7D,QAAQ,IAAA,mYAAI,EAAC,UAAU;QAAE,MAAM;IAAgB,GAAG,OAAO,CAAC;IAC1D,WAAW,IAAA,yYAAO,EAAC,cAAc;QAAE,MAAM;IAAY,GAAG,OAAO;IAC/D,WAAW,IAAA,yYAAO,EAAC,cAAc;QAAE,MAAM;IAAY,GAAG,OAAO;AAChE,GACA,CAAC,QAAU;QAAC,IAAA,4XAAK,EAAC,qCAAqC,EAAE,CAAC,MAAM,SAAS;QAAG,IAAA,4XAAK,EAAC,kCAAkC,EAAE,CAAC,MAAM,MAAM;KAAE;AAI/H,MAAM,aAAa;IAAC;IAAS;IAAU;IAAQ;CAAM;AAIrD,MAAM,gBAAgB,IAAA,gYAAW,EACvC,kBACA;IACC,IAAI,IAAA,yYAAO,EAAC,MAAM,UAAU,CAAC;QAAE,eAAe;IAAK;IACnD,UAAU,IAAA,mYAAI,EAAC,aAAa,OAAO,GAAG,MAAM;IAC5C,WAAW,IAAA,mYAAI,EAAC,cAAc;QAAE,MAAM;IAAW,GAAG,OAAO;IAC3D,UAAU,IAAA,mYAAI,EAAC;IACf,WAAW,IAAA,mYAAI,EAAC;IAChB,WAAW,IAAA,mYAAI,EAAC;IAChB,YAAY,IAAA,mYAAI,EAAC,eAAe;QAAE,MAAM;IAAO;IAC/C,WAAW,IAAA,yYAAO,EAAC,cAAc;QAAE,MAAM;IAAY,GAAG,OAAO;IAC/D,WAAW,IAAA,yYAAO,EAAC,cAAc;QAAE,MAAM;IAAY;AACtD,GACA,CAAC,QAAU;QAAC,IAAA,4XAAK,EAAC,iCAAiC,EAAE,CAAC,MAAM,SAAS;QAAG,IAAA,4XAAK,EAAC,iCAAiC,EAAE,CAAC,MAAM,SAAS;KAAE;AA4B7H,MAAM,SAAS;IACrB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;AACD"}},
    {"offset": {"line": 332, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/db.ts"],"sourcesContent":["import Database from \"better-sqlite3\"\nimport { drizzle } from \"drizzle-orm/better-sqlite3\"\nimport * as schema from \"./schema\"\nimport { existsSync, mkdirSync } from \"fs\"\nimport { dirname } from \"path\"\n\nlet db: ReturnType<typeof createClient> | null = null\n\nfunction createClient(dbPath: string) {\n\t// Ensure directory exists\n\tconst dir = dirname(dbPath)\n\tif (dir !== \".\" && !existsSync(dir)) {\n\t\tmkdirSync(dir, { recursive: true })\n\t}\n\n\tconst sqlite = new Database(dbPath)\n\n\t// Enable WAL mode for better concurrent access\n\tsqlite.pragma(\"journal_mode = WAL\")\n\n\treturn drizzle(sqlite, { schema })\n}\n\nexport function getDb(dbPath?: string): ReturnType<typeof createClient> {\n\tconst path = dbPath || process.env.COMMIT_ANALYSIS_DB_PATH || \"./commit-analysis.db\"\n\n\tif (!db) {\n\t\tdb = createClient(path)\n\t}\n\n\treturn db\n}\n\nexport function closeDb() {\n\tif (db) {\n\t\t// @ts-expect-error - accessing internal client\n\t\tdb.$client?.close?.()\n\t\tdb = null\n\t}\n}\n\nexport type DatabaseClient = ReturnType<typeof getDb>\nexport type DatabaseOrTransaction = DatabaseClient | Parameters<Parameters<DatabaseClient[\"transaction\"]>[0]>[0]\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;;;;;;AAEA,IAAI,KAA6C;AAEjD,SAAS,aAAa,MAAc;IACnC,0BAA0B;IAC1B,MAAM,MAAM,IAAA,4GAAO,EAAC;IACpB,IAAI,QAAQ,OAAO,CAAC,IAAA,2GAAU,EAAC,MAAM;QACpC,IAAA,0GAAS,EAAC,KAAK;YAAE,WAAW;QAAK;IAClC;IAEA,MAAM,SAAS,IAAI,6QAAQ,CAAC;IAE5B,+CAA+C;IAC/C,OAAO,MAAM,CAAC;IAEd,OAAO,IAAA,gYAAO,EAAC,QAAQ;QAAE,QAAA;IAAO;AACjC;AAEO,SAAS,MAAM,MAAe;IACpC,MAAM,OAAO,UAAU,QAAQ,GAAG,CAAC,uBAAuB,IAAI;IAE9D,IAAI,CAAC,IAAI;QACR,KAAK,aAAa;IACnB;IAEA,OAAO;AACR;AAEO,SAAS;IACf,IAAI,IAAI;QACP,+CAA+C;QAC/C,GAAG,OAAO,EAAE;QACZ,KAAK;IACN;AACD"}},
    {"offset": {"line": 382, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/commits.ts"],"sourcesContent":["import { eq, desc, and, gte, lte, sql, inArray, isNull } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport { commits, fileChanges, type InsertCommit, type InsertFileChange, type Commit } from \"../schema\"\n\nexport async function createCommit(data: InsertCommit, db: DatabaseOrTransaction = getDb()): Promise<Commit> {\n\tconst result = await db\n\t\t.insert(commits)\n\t\t.values({\n\t\t\t...data,\n\t\t\tanalyzedAt: new Date(),\n\t\t})\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: commits.sha,\n\t\t\tset: {\n\t\t\t\t...data,\n\t\t\t\tanalyzedAt: new Date(),\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\tconst record = result[0]\n\tif (!record) {\n\t\tthrow new Error(`Failed to create commit ${data.sha}`)\n\t}\n\treturn record\n}\n\nexport async function createFileChanges(changes: InsertFileChange[], db: DatabaseOrTransaction = getDb()) {\n\tif (changes.length === 0) return []\n\n\treturn db.insert(fileChanges).values(changes).returning()\n}\n\nexport async function getCommit(sha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.commits.findFirst({\n\t\twhere: eq(commits.sha, sha),\n\t\twith: {\n\t\t\tfileChanges: true,\n\t\t\tclassification: true,\n\t\t},\n\t})\n}\n\nexport async function getCommitBySha(sha: string, db: DatabaseOrTransaction = getDb()) {\n\t// Support both full and short SHA\n\tconst commit = await db.query.commits.findFirst({\n\t\twhere: eq(commits.sha, sha),\n\t})\n\n\tif (commit) return commit\n\n\t// Try short SHA match\n\treturn db.query.commits.findFirst({\n\t\twhere: sql`${commits.sha} LIKE ${sha + \"%\"}`,\n\t})\n}\n\nexport async function getCommits(\n\toptions: {\n\t\tsince?: Date\n\t\tuntil?: Date\n\t\tlimit?: number\n\t\toffset?: number\n\t\tmessageType?: string\n\t} = {},\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst conditions = []\n\n\tif (options.since) {\n\t\tconditions.push(gte(commits.date, options.since))\n\t}\n\tif (options.until) {\n\t\tconditions.push(lte(commits.date, options.until))\n\t}\n\tif (options.messageType) {\n\t\tconditions.push(eq(commits.messageType, options.messageType))\n\t}\n\n\treturn db.query.commits.findMany({\n\t\twhere: conditions.length > 0 ? and(...conditions) : undefined,\n\t\torderBy: desc(commits.date),\n\t\tlimit: options.limit,\n\t\toffset: options.offset,\n\t\twith: {\n\t\t\tclassification: true,\n\t\t},\n\t})\n}\n\nexport async function getCommitCount(db: DatabaseOrTransaction = getDb()) {\n\tconst result = await db.select({ count: sql<number>`count(*)` }).from(commits)\n\treturn result[0]?.count ?? 0\n}\n\nexport async function getLatestCommit(db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.commits.findFirst({\n\t\torderBy: desc(commits.date),\n\t})\n}\n\nexport async function getUnanalyzedCommits(db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.commits.findMany({\n\t\twhere: isNull(commits.deepAnalyzedAt),\n\t\torderBy: desc(commits.date),\n\t})\n}\n\nexport async function markCommitDeepAnalyzed(sha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.update(commits).set({ deepAnalyzedAt: new Date() }).where(eq(commits.sha, sha))\n}\n\nexport async function getCommitsBySubsystem(subsystem: string, db: DatabaseOrTransaction = getDb()) {\n\tconst changes = await db.query.fileChanges.findMany({\n\t\twhere: eq(fileChanges.subsystem, subsystem),\n\t\twith: {\n\t\t\tcommit: {\n\t\t\t\twith: {\n\t\t\t\t\tclassification: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n\n\t// Get unique commits\n\tconst uniqueCommits = new Map<string, (typeof changes)[0][\"commit\"]>()\n\tfor (const change of changes) {\n\t\tif (change.commit && !uniqueCommits.has(change.commit.sha)) {\n\t\t\tuniqueCommits.set(change.commit.sha, change.commit)\n\t\t}\n\t}\n\n\treturn Array.from(uniqueCommits.values())\n}\n\nexport async function deleteCommit(sha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.delete(commits).where(eq(commits.sha, sha))\n}\n\nexport async function deleteCommits(shas: string[], db: DatabaseOrTransaction = getDb()) {\n\tif (shas.length === 0) return\n\treturn db.delete(commits).where(inArray(commits.sha, shas))\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAEA;AACA;;;;AAEO,eAAe,aAAa,IAAkB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACzF,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,+KAAO,EACd,MAAM,CAAC;QACP,GAAG,IAAI;QACP,YAAY,IAAI;IACjB,GACC,kBAAkB,CAAC;QACnB,QAAQ,+KAAO,CAAC,GAAG;QACnB,KAAK;YACJ,GAAG,IAAI;YACP,YAAY,IAAI;QACjB;IACD,GACC,SAAS;IAEX,MAAM,SAAS,MAAM,CAAC,EAAE;IACxB,IAAI,CAAC,QAAQ;QACZ,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,KAAK,GAAG,EAAE;IACtD;IACA,OAAO;AACR;AAEO,eAAe,kBAAkB,OAA2B,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACvG,IAAI,QAAQ,MAAM,KAAK,GAAG,OAAO,EAAE;IAEnC,OAAO,GAAG,MAAM,CAAC,mLAAW,EAAE,MAAM,CAAC,SAAS,SAAS;AACxD;AAEO,eAAe,UAAU,GAAW,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC/E,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC;QACjC,OAAO,IAAA,gYAAE,EAAC,+KAAO,CAAC,GAAG,EAAE;QACvB,MAAM;YACL,aAAa;YACb,gBAAgB;QACjB;IACD;AACD;AAEO,eAAe,eAAe,GAAW,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACpF,kCAAkC;IAClC,MAAM,SAAS,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC;QAC/C,OAAO,IAAA,gYAAE,EAAC,+KAAO,CAAC,GAAG,EAAE;IACxB;IAEA,IAAI,QAAQ,OAAO;IAEnB,sBAAsB;IACtB,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC;QACjC,OAAO,2WAAG,CAAC,EAAE,+KAAO,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,IAAI,CAAC;IAC7C;AACD;AAEO,eAAe,WACrB,UAMI,CAAC,CAAC,EACN,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,aAAa,EAAE;IAErB,IAAI,QAAQ,KAAK,EAAE;QAClB,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,+KAAO,CAAC,IAAI,EAAE,QAAQ,KAAK;IAChD;IACA,IAAI,QAAQ,KAAK,EAAE;QAClB,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,+KAAO,CAAC,IAAI,EAAE,QAAQ,KAAK;IAChD;IACA,IAAI,QAAQ,WAAW,EAAE;QACxB,WAAW,IAAI,CAAC,IAAA,gYAAE,EAAC,+KAAO,CAAC,WAAW,EAAE,QAAQ,WAAW;IAC5D;IAEA,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC;QAChC,OAAO,WAAW,MAAM,GAAG,IAAI,IAAA,iYAAG,KAAI,cAAc;QACpD,SAAS,IAAA,8XAAI,EAAC,+KAAO,CAAC,IAAI;QAC1B,OAAO,QAAQ,KAAK;QACpB,QAAQ,QAAQ,MAAM;QACtB,MAAM;YACL,gBAAgB;QACjB;IACD;AACD;AAEO,eAAe,eAAe,KAA4B,IAAA,yKAAK,GAAE;IACvE,MAAM,SAAS,MAAM,GAAG,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GAAG,IAAI,CAAC,+KAAO;IAC7E,OAAO,MAAM,CAAC,EAAE,EAAE,SAAS;AAC5B;AAEO,eAAe,gBAAgB,KAA4B,IAAA,yKAAK,GAAE;IACxE,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC;QACjC,SAAS,IAAA,8XAAI,EAAC,+KAAO,CAAC,IAAI;IAC3B;AACD;AAEO,eAAe,qBAAqB,KAA4B,IAAA,yKAAK,GAAE;IAC7E,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC;QAChC,OAAO,IAAA,oYAAM,EAAC,+KAAO,CAAC,cAAc;QACpC,SAAS,IAAA,8XAAI,EAAC,+KAAO,CAAC,IAAI;IAC3B;AACD;AAEO,eAAe,uBAAuB,GAAW,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC5F,OAAO,GAAG,MAAM,CAAC,+KAAO,EAAE,GAAG,CAAC;QAAE,gBAAgB,IAAI;IAAO,GAAG,KAAK,CAAC,IAAA,gYAAE,EAAC,+KAAO,CAAC,GAAG,EAAE;AACrF;AAEO,eAAe,sBAAsB,SAAiB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACjG,MAAM,UAAU,MAAM,GAAG,KAAK,CAAC,WAAW,CAAC,QAAQ,CAAC;QACnD,OAAO,IAAA,gYAAE,EAAC,mLAAW,CAAC,SAAS,EAAE;QACjC,MAAM;YACL,QAAQ;gBACP,MAAM;oBACL,gBAAgB;gBACjB;YACD;QACD;IACD;IAEA,qBAAqB;IACrB,MAAM,gBAAgB,IAAI;IAC1B,KAAK,MAAM,UAAU,QAAS;QAC7B,IAAI,OAAO,MAAM,IAAI,CAAC,cAAc,GAAG,CAAC,OAAO,MAAM,CAAC,GAAG,GAAG;YAC3D,cAAc,GAAG,CAAC,OAAO,MAAM,CAAC,GAAG,EAAE,OAAO,MAAM;QACnD;IACD;IAEA,OAAO,MAAM,IAAI,CAAC,cAAc,MAAM;AACvC;AAEO,eAAe,aAAa,GAAW,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAClF,OAAO,GAAG,MAAM,CAAC,+KAAO,EAAE,KAAK,CAAC,IAAA,gYAAE,EAAC,+KAAO,CAAC,GAAG,EAAE;AACjD;AAEO,eAAe,cAAc,IAAc,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACtF,IAAI,KAAK,MAAM,KAAK,GAAG;IACvB,OAAO,GAAG,MAAM,CAAC,+KAAO,EAAE,KAAK,CAAC,IAAA,qYAAO,EAAC,+KAAO,CAAC,GAAG,EAAE;AACtD"}},
    {"offset": {"line": 531, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/classifications.ts"],"sourcesContent":["import { eq, desc, and, gte, sql, inArray } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport {\n\tclassifications,\n\tcommits,\n\ttype InsertClassification,\n\ttype UpdateClassification,\n\ttype Classification,\n\ttype CommitCategory,\n} from \"../schema\"\n\nexport async function createClassification(\n\tdata: InsertClassification,\n\tdb: DatabaseOrTransaction = getDb(),\n): Promise<Classification> {\n\tconst result = await db\n\t\t.insert(classifications)\n\t\t.values(data)\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: classifications.commitSha,\n\t\t\tset: {\n\t\t\t\tcategory: data.category,\n\t\t\t\tconfidence: data.confidence,\n\t\t\t\tflags: data.flags,\n\t\t\t\triskScore: data.riskScore,\n\t\t\t\tanalysisVersion: data.analysisVersion,\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\tconst record = result[0]\n\tif (!record) {\n\t\tthrow new Error(`Failed to create classification for ${data.commitSha}`)\n\t}\n\treturn record\n}\n\nexport async function getClassification(commitSha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.classifications.findFirst({\n\t\twhere: eq(classifications.commitSha, commitSha),\n\t\twith: {\n\t\t\tcommit: true,\n\t\t},\n\t})\n}\n\nexport async function getClassifications(\n\toptions: {\n\t\tcategory?: CommitCategory\n\t\tminRisk?: number\n\t\tlimit?: number\n\t\toffset?: number\n\t} = {},\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst conditions = []\n\n\tif (options.category) {\n\t\tconditions.push(eq(classifications.category, options.category))\n\t}\n\tif (options.minRisk !== undefined) {\n\t\tconditions.push(gte(classifications.riskScore, options.minRisk))\n\t}\n\n\treturn db.query.classifications.findMany({\n\t\twhere: conditions.length > 0 ? and(...conditions) : undefined,\n\t\torderBy: desc(classifications.riskScore),\n\t\tlimit: options.limit,\n\t\toffset: options.offset,\n\t\twith: {\n\t\t\tcommit: true,\n\t\t},\n\t})\n}\n\nexport async function updateClassification(\n\tcommitSha: string,\n\tdata: UpdateClassification,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\treturn db.update(classifications).set(data).where(eq(classifications.commitSha, commitSha)).returning()\n}\n\nexport async function getHighRiskCommits(threshold: number = 50, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.classifications.findMany({\n\t\twhere: gte(classifications.riskScore, threshold),\n\t\torderBy: desc(classifications.riskScore),\n\t\twith: {\n\t\t\tcommit: true,\n\t\t},\n\t})\n}\n\nexport async function getCategoryDistribution(db: DatabaseOrTransaction = getDb()) {\n\tconst result = await db\n\t\t.select({\n\t\t\tcategory: classifications.category,\n\t\t\tcount: sql<number>`count(*)`,\n\t\t\tavgRisk: sql<number>`avg(${classifications.riskScore})`,\n\t\t})\n\t\t.from(classifications)\n\t\t.groupBy(classifications.category)\n\t\t.orderBy(desc(sql`count(*)`))\n\n\treturn result\n}\n\nexport async function getClassificationsByCommits(shas: string[], db: DatabaseOrTransaction = getDb()) {\n\tif (shas.length === 0) return []\n\treturn db.query.classifications.findMany({\n\t\twhere: inArray(classifications.commitSha, shas),\n\t\twith: {\n\t\t\tcommit: true,\n\t\t},\n\t})\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAEA;AACA;;;;AASO,eAAe,qBACrB,IAA0B,EAC1B,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,uLAAe,EACtB,MAAM,CAAC,MACP,kBAAkB,CAAC;QACnB,QAAQ,uLAAe,CAAC,SAAS;QACjC,KAAK;YACJ,UAAU,KAAK,QAAQ;YACvB,YAAY,KAAK,UAAU;YAC3B,OAAO,KAAK,KAAK;YACjB,WAAW,KAAK,SAAS;YACzB,iBAAiB,KAAK,eAAe;QACtC;IACD,GACC,SAAS;IAEX,MAAM,SAAS,MAAM,CAAC,EAAE;IACxB,IAAI,CAAC,QAAQ;QACZ,MAAM,IAAI,MAAM,CAAC,oCAAoC,EAAE,KAAK,SAAS,EAAE;IACxE;IACA,OAAO;AACR;AAEO,eAAe,kBAAkB,SAAiB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC7F,OAAO,GAAG,KAAK,CAAC,eAAe,CAAC,SAAS,CAAC;QACzC,OAAO,IAAA,gYAAE,EAAC,uLAAe,CAAC,SAAS,EAAE;QACrC,MAAM;YACL,QAAQ;QACT;IACD;AACD;AAEO,eAAe,mBACrB,UAKI,CAAC,CAAC,EACN,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,aAAa,EAAE;IAErB,IAAI,QAAQ,QAAQ,EAAE;QACrB,WAAW,IAAI,CAAC,IAAA,gYAAE,EAAC,uLAAe,CAAC,QAAQ,EAAE,QAAQ,QAAQ;IAC9D;IACA,IAAI,QAAQ,OAAO,KAAK,WAAW;QAClC,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,uLAAe,CAAC,SAAS,EAAE,QAAQ,OAAO;IAC/D;IAEA,OAAO,GAAG,KAAK,CAAC,eAAe,CAAC,QAAQ,CAAC;QACxC,OAAO,WAAW,MAAM,GAAG,IAAI,IAAA,iYAAG,KAAI,cAAc;QACpD,SAAS,IAAA,8XAAI,EAAC,uLAAe,CAAC,SAAS;QACvC,OAAO,QAAQ,KAAK;QACpB,QAAQ,QAAQ,MAAM;QACtB,MAAM;YACL,QAAQ;QACT;IACD;AACD;AAEO,eAAe,qBACrB,SAAiB,EACjB,IAA0B,EAC1B,KAA4B,IAAA,yKAAK,GAAE;IAEnC,OAAO,GAAG,MAAM,CAAC,uLAAe,EAAE,GAAG,CAAC,MAAM,KAAK,CAAC,IAAA,gYAAE,EAAC,uLAAe,CAAC,SAAS,EAAE,YAAY,SAAS;AACtG;AAEO,eAAe,mBAAmB,YAAoB,EAAE,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACnG,OAAO,GAAG,KAAK,CAAC,eAAe,CAAC,QAAQ,CAAC;QACxC,OAAO,IAAA,iYAAG,EAAC,uLAAe,CAAC,SAAS,EAAE;QACtC,SAAS,IAAA,8XAAI,EAAC,uLAAe,CAAC,SAAS;QACvC,MAAM;YACL,QAAQ;QACT;IACD;AACD;AAEO,eAAe,wBAAwB,KAA4B,IAAA,yKAAK,GAAE;IAChF,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC;QACP,UAAU,uLAAe,CAAC,QAAQ;QAClC,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;QAC5B,SAAS,2WAAG,AAAQ,CAAC,IAAI,EAAE,uLAAe,CAAC,SAAS,CAAC,CAAC,CAAC;IACxD,GACC,IAAI,CAAC,uLAAe,EACpB,OAAO,CAAC,uLAAe,CAAC,QAAQ,EAChC,OAAO,CAAC,IAAA,8XAAI,EAAC,2WAAG,CAAC,QAAQ,CAAC;IAE5B,OAAO;AACR;AAEO,eAAe,4BAA4B,IAAc,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACpG,IAAI,KAAK,MAAM,KAAK,GAAG,OAAO,EAAE;IAChC,OAAO,GAAG,KAAK,CAAC,eAAe,CAAC,QAAQ,CAAC;QACxC,OAAO,IAAA,qYAAO,EAAC,uLAAe,CAAC,SAAS,EAAE;QAC1C,MAAM;YACL,QAAQ;QACT;IACD;AACD"}},
    {"offset": {"line": 631, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/causality.ts"],"sourcesContent":["import { eq, desc, and, sql, inArray } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport { bugCausality, commits, type InsertBugCausality, type BugCausality } from \"../schema\"\n\nexport async function createBugCausality(\n\tdata: InsertBugCausality,\n\tdb: DatabaseOrTransaction = getDb(),\n): Promise<BugCausality> {\n\tconst result = await db\n\t\t.insert(bugCausality)\n\t\t.values({\n\t\t\t...data,\n\t\t\tcreatedAt: new Date(),\n\t\t})\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: [bugCausality.bugFixSha, bugCausality.causeSha],\n\t\t\tset: {\n\t\t\t\trelationshipType: data.relationshipType,\n\t\t\t\tconfidence: data.confidence,\n\t\t\t\tbugAge: data.bugAge,\n\t\t\t\tbugAgeCommits: data.bugAgeCommits,\n\t\t\t\tanalysisMethod: data.analysisMethod,\n\t\t\t\tnotes: data.notes,\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\tconst record = result[0]\n\tif (!record) {\n\t\tthrow new Error(`Failed to create bug causality for ${data.bugFixSha} -> ${data.causeSha}`)\n\t}\n\treturn record\n}\n\nexport async function getCausesForBugFix(bugFixSha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.bugCausality.findMany({\n\t\twhere: eq(bugCausality.bugFixSha, bugFixSha),\n\t\twith: {\n\t\t\tcause: {\n\t\t\t\twith: {\n\t\t\t\t\tclassification: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\torderBy: desc(bugCausality.confidence),\n\t})\n}\n\nexport async function getBugsCausedBy(causeSha: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.bugCausality.findMany({\n\t\twhere: eq(bugCausality.causeSha, causeSha),\n\t\twith: {\n\t\t\tbugFix: {\n\t\t\t\twith: {\n\t\t\t\t\tclassification: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\torderBy: desc(bugCausality.confidence),\n\t})\n}\n\nexport async function getTopBugIntroducers(limit: number = 10, db: DatabaseOrTransaction = getDb()) {\n\tconst result = await db\n\t\t.select({\n\t\t\tcauseSha: bugCausality.causeSha,\n\t\t\tbugsCaused: sql<number>`count(*)`,\n\t\t\tavgBugAge: sql<number>`avg(${bugCausality.bugAge})`,\n\t\t})\n\t\t.from(bugCausality)\n\t\t.where(eq(bugCausality.relationshipType, \"root_cause\"))\n\t\t.groupBy(bugCausality.causeSha)\n\t\t.orderBy(desc(sql`count(*)`))\n\t\t.limit(limit)\n\n\t// Get commit details for each\n\tconst shas = result.map((r) => r.causeSha)\n\tif (shas.length === 0) return []\n\n\tconst commitDetails = await db.query.commits.findMany({\n\t\twhere: inArray(commits.sha, shas),\n\t\twith: {\n\t\t\tclassification: true,\n\t\t},\n\t})\n\n\tconst commitMap = new Map(commitDetails.map((c) => [c.sha, c]))\n\n\treturn result.map((r) => ({\n\t\t...r,\n\t\tcommit: commitMap.get(r.causeSha),\n\t}))\n}\n\nexport async function verifyCausality(\n\tbugFixSha: string,\n\tcauseSha: string,\n\tverifiedBy: string,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\treturn db\n\t\t.update(bugCausality)\n\t\t.set({\n\t\t\tverifiedAt: new Date(),\n\t\t\tverifiedBy,\n\t\t})\n\t\t.where(and(eq(bugCausality.bugFixSha, bugFixSha), eq(bugCausality.causeSha, causeSha)))\n\t\t.returning()\n}\n\nexport async function deleteCausalityForCommit(sha: string, db: DatabaseOrTransaction = getDb()) {\n\t// Delete where this commit is either the fix or the cause\n\tawait db.delete(bugCausality).where(eq(bugCausality.bugFixSha, sha))\n\tawait db.delete(bugCausality).where(eq(bugCausality.causeSha, sha))\n}\n\nexport async function getCausalityStats(db: DatabaseOrTransaction = getDb()) {\n\tconst totalLinks = await db.select({ count: sql<number>`count(*)` }).from(bugCausality)\n\n\tconst rootCauses = await db\n\t\t.select({ count: sql<number>`count(*)` })\n\t\t.from(bugCausality)\n\t\t.where(eq(bugCausality.relationshipType, \"root_cause\"))\n\n\tconst verified = await db\n\t\t.select({ count: sql<number>`count(*)` })\n\t\t.from(bugCausality)\n\t\t.where(sql`${bugCausality.verifiedAt} IS NOT NULL`)\n\n\tconst avgBugAge = await db\n\t\t.select({ avg: sql<number>`avg(${bugCausality.bugAge})` })\n\t\t.from(bugCausality)\n\t\t.where(sql`${bugCausality.bugAge} IS NOT NULL`)\n\n\treturn {\n\t\ttotalLinks: totalLinks[0]?.count ?? 0,\n\t\trootCauses: rootCauses[0]?.count ?? 0,\n\t\tverified: verified[0]?.count ?? 0,\n\t\tavgBugAgeDays: avgBugAge[0]?.avg ?? 0,\n\t}\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAEA;AACA;;;;AAEO,eAAe,mBACrB,IAAwB,EACxB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,oLAAY,EACnB,MAAM,CAAC;QACP,GAAG,IAAI;QACP,WAAW,IAAI;IAChB,GACC,kBAAkB,CAAC;QACnB,QAAQ;YAAC,oLAAY,CAAC,SAAS;YAAE,oLAAY,CAAC,QAAQ;SAAC;QACvD,KAAK;YACJ,kBAAkB,KAAK,gBAAgB;YACvC,YAAY,KAAK,UAAU;YAC3B,QAAQ,KAAK,MAAM;YACnB,eAAe,KAAK,aAAa;YACjC,gBAAgB,KAAK,cAAc;YACnC,OAAO,KAAK,KAAK;QAClB;IACD,GACC,SAAS;IAEX,MAAM,SAAS,MAAM,CAAC,EAAE;IACxB,IAAI,CAAC,QAAQ;QACZ,MAAM,IAAI,MAAM,CAAC,mCAAmC,EAAE,KAAK,SAAS,CAAC,IAAI,EAAE,KAAK,QAAQ,EAAE;IAC3F;IACA,OAAO;AACR;AAEO,eAAe,mBAAmB,SAAiB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC9F,OAAO,GAAG,KAAK,CAAC,YAAY,CAAC,QAAQ,CAAC;QACrC,OAAO,IAAA,gYAAE,EAAC,oLAAY,CAAC,SAAS,EAAE;QAClC,MAAM;YACL,OAAO;gBACN,MAAM;oBACL,gBAAgB;gBACjB;YACD;QACD;QACA,SAAS,IAAA,8XAAI,EAAC,oLAAY,CAAC,UAAU;IACtC;AACD;AAEO,eAAe,gBAAgB,QAAgB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC1F,OAAO,GAAG,KAAK,CAAC,YAAY,CAAC,QAAQ,CAAC;QACrC,OAAO,IAAA,gYAAE,EAAC,oLAAY,CAAC,QAAQ,EAAE;QACjC,MAAM;YACL,QAAQ;gBACP,MAAM;oBACL,gBAAgB;gBACjB;YACD;QACD;QACA,SAAS,IAAA,8XAAI,EAAC,oLAAY,CAAC,UAAU;IACtC;AACD;AAEO,eAAe,qBAAqB,QAAgB,EAAE,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACjG,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC;QACP,UAAU,oLAAY,CAAC,QAAQ;QAC/B,YAAY,2WAAG,AAAQ,CAAC,QAAQ,CAAC;QACjC,WAAW,2WAAG,AAAQ,CAAC,IAAI,EAAE,oLAAY,CAAC,MAAM,CAAC,CAAC,CAAC;IACpD,GACC,IAAI,CAAC,oLAAY,EACjB,KAAK,CAAC,IAAA,gYAAE,EAAC,oLAAY,CAAC,gBAAgB,EAAE,eACxC,OAAO,CAAC,oLAAY,CAAC,QAAQ,EAC7B,OAAO,CAAC,IAAA,8XAAI,EAAC,2WAAG,CAAC,QAAQ,CAAC,GAC1B,KAAK,CAAC;IAER,8BAA8B;IAC9B,MAAM,OAAO,OAAO,GAAG,CAAC,CAAC,IAAM,EAAE,QAAQ;IACzC,IAAI,KAAK,MAAM,KAAK,GAAG,OAAO,EAAE;IAEhC,MAAM,gBAAgB,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC;QACrD,OAAO,IAAA,qYAAO,EAAC,+KAAO,CAAC,GAAG,EAAE;QAC5B,MAAM;YACL,gBAAgB;QACjB;IACD;IAEA,MAAM,YAAY,IAAI,IAAI,cAAc,GAAG,CAAC,CAAC,IAAM;YAAC,EAAE,GAAG;YAAE;SAAE;IAE7D,OAAO,OAAO,GAAG,CAAC,CAAC,IAAM,CAAC;YACzB,GAAG,CAAC;YACJ,QAAQ,UAAU,GAAG,CAAC,EAAE,QAAQ;QACjC,CAAC;AACF;AAEO,eAAe,gBACrB,SAAiB,EACjB,QAAgB,EAChB,UAAkB,EAClB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,OAAO,GACL,MAAM,CAAC,oLAAY,EACnB,GAAG,CAAC;QACJ,YAAY,IAAI;QAChB;IACD,GACC,KAAK,CAAC,IAAA,iYAAG,EAAC,IAAA,gYAAE,EAAC,oLAAY,CAAC,SAAS,EAAE,YAAY,IAAA,gYAAE,EAAC,oLAAY,CAAC,QAAQ,EAAE,YAC3E,SAAS;AACZ;AAEO,eAAe,yBAAyB,GAAW,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC9F,0DAA0D;IAC1D,MAAM,GAAG,MAAM,CAAC,oLAAY,EAAE,KAAK,CAAC,IAAA,gYAAE,EAAC,oLAAY,CAAC,SAAS,EAAE;IAC/D,MAAM,GAAG,MAAM,CAAC,oLAAY,EAAE,KAAK,CAAC,IAAA,gYAAE,EAAC,oLAAY,CAAC,QAAQ,EAAE;AAC/D;AAEO,eAAe,kBAAkB,KAA4B,IAAA,yKAAK,GAAE;IAC1E,MAAM,aAAa,MAAM,GAAG,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GAAG,IAAI,CAAC,oLAAY;IAEtF,MAAM,aAAa,MAAM,GACvB,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GACtC,IAAI,CAAC,oLAAY,EACjB,KAAK,CAAC,IAAA,gYAAE,EAAC,oLAAY,CAAC,gBAAgB,EAAE;IAE1C,MAAM,WAAW,MAAM,GACrB,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GACtC,IAAI,CAAC,oLAAY,EACjB,KAAK,CAAC,2WAAG,CAAC,EAAE,oLAAY,CAAC,UAAU,CAAC,YAAY,CAAC;IAEnD,MAAM,YAAY,MAAM,GACtB,MAAM,CAAC;QAAE,KAAK,2WAAG,AAAQ,CAAC,IAAI,EAAE,oLAAY,CAAC,MAAM,CAAC,CAAC,CAAC;IAAC,GACvD,IAAI,CAAC,oLAAY,EACjB,KAAK,CAAC,2WAAG,CAAC,EAAE,oLAAY,CAAC,MAAM,CAAC,YAAY,CAAC;IAE/C,OAAO;QACN,YAAY,UAAU,CAAC,EAAE,EAAE,SAAS;QACpC,YAAY,UAAU,CAAC,EAAE,EAAE,SAAS;QACpC,UAAU,QAAQ,CAAC,EAAE,EAAE,SAAS;QAChC,eAAe,SAAS,CAAC,EAAE,EAAE,OAAO;IACrC;AACD"}},
    {"offset": {"line": 770, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/patterns.ts"],"sourcesContent":["import { eq, desc, and, sql, inArray } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport {\n\tregressionPatterns,\n\ttype InsertRegressionPattern,\n\ttype RegressionPattern,\n\ttype SeverityLevel,\n\ttype PatternStatus,\n} from \"../schema\"\nimport { createHash } from \"crypto\"\n\nexport function generatePatternHash(subsystem: string, keywords: string[]): string {\n\tconst normalized = [subsystem, ...keywords.sort()].join(\":\").toLowerCase()\n\treturn createHash(\"md5\").update(normalized).digest(\"hex\")\n}\n\nexport async function createRegressionPattern(\n\tdata: InsertRegressionPattern,\n\tdb: DatabaseOrTransaction = getDb(),\n): Promise<RegressionPattern> {\n\tconst now = new Date()\n\tconst result = await db\n\t\t.insert(regressionPatterns)\n\t\t.values({\n\t\t\t...data,\n\t\t\tcreatedAt: now,\n\t\t\tupdatedAt: now,\n\t\t})\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: regressionPatterns.patternHash,\n\t\t\tset: {\n\t\t\t\toccurrenceCount: sql`${regressionPatterns.occurrenceCount} + 1`,\n\t\t\t\tcommitShas: data.commitShas,\n\t\t\t\tseverity: data.severity,\n\t\t\t\tstatus: data.status,\n\t\t\t\tupdatedAt: now,\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\tconst record = result[0]\n\tif (!record) {\n\t\tthrow new Error(`Failed to create regression pattern ${data.patternHash}`)\n\t}\n\treturn record\n}\n\nexport async function getRegressionPattern(id: number, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.regressionPatterns.findFirst({\n\t\twhere: eq(regressionPatterns.id, id),\n\t})\n}\n\nexport async function getRegressionPatternByHash(hash: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.regressionPatterns.findFirst({\n\t\twhere: eq(regressionPatterns.patternHash, hash),\n\t})\n}\n\nexport async function getRegressionPatterns(\n\toptions: {\n\t\tsubsystem?: string\n\t\tseverity?: SeverityLevel\n\t\tstatus?: PatternStatus\n\t\tminOccurrences?: number\n\t\tlimit?: number\n\t} = {},\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst conditions = []\n\n\tif (options.subsystem) {\n\t\tconditions.push(eq(regressionPatterns.subsystem, options.subsystem))\n\t}\n\tif (options.severity) {\n\t\tconditions.push(eq(regressionPatterns.severity, options.severity))\n\t}\n\tif (options.status) {\n\t\tconditions.push(eq(regressionPatterns.status, options.status))\n\t}\n\tif (options.minOccurrences !== undefined) {\n\t\tconditions.push(sql`${regressionPatterns.occurrenceCount} >= ${options.minOccurrences}`)\n\t}\n\n\treturn db.query.regressionPatterns.findMany({\n\t\twhere: conditions.length > 0 ? and(...conditions) : undefined,\n\t\torderBy: [desc(regressionPatterns.occurrenceCount), desc(regressionPatterns.updatedAt)],\n\t\tlimit: options.limit,\n\t})\n}\n\nexport async function addCommitToPattern(\n\tpatternHash: string,\n\tcommitSha: string,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst pattern = await getRegressionPatternByHash(patternHash, db)\n\tif (!pattern) {\n\t\tthrow new Error(`Pattern not found: ${patternHash}`)\n\t}\n\n\tconst existingShas = pattern.commitShas || []\n\tif (existingShas.includes(commitSha)) {\n\t\treturn pattern\n\t}\n\n\tconst updatedShas = [...existingShas, commitSha]\n\n\tconst result = await db\n\t\t.update(regressionPatterns)\n\t\t.set({\n\t\t\tcommitShas: updatedShas,\n\t\t\toccurrenceCount: updatedShas.length,\n\t\t\tupdatedAt: new Date(),\n\t\t})\n\t\t.where(eq(regressionPatterns.patternHash, patternHash))\n\t\t.returning()\n\n\treturn result[0]\n}\n\nexport async function updatePatternSeverity(\n\tpatternHash: string,\n\tseverity: SeverityLevel,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\treturn db\n\t\t.update(regressionPatterns)\n\t\t.set({\n\t\t\tseverity,\n\t\t\tupdatedAt: new Date(),\n\t\t})\n\t\t.where(eq(regressionPatterns.patternHash, patternHash))\n\t\t.returning()\n}\n\nexport async function resolvePattern(patternHash: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db\n\t\t.update(regressionPatterns)\n\t\t.set({\n\t\t\tstatus: \"resolved\",\n\t\t\tupdatedAt: new Date(),\n\t\t})\n\t\t.where(eq(regressionPatterns.patternHash, patternHash))\n\t\t.returning()\n}\n\nexport async function getActivePatterns(db: DatabaseOrTransaction = getDb()) {\n\treturn getRegressionPatterns({ status: \"active\" }, db)\n}\n\nexport async function getPatternStats(db: DatabaseOrTransaction = getDb()) {\n\tconst total = await db.select({ count: sql<number>`count(*)` }).from(regressionPatterns)\n\n\tconst active = await db\n\t\t.select({ count: sql<number>`count(*)` })\n\t\t.from(regressionPatterns)\n\t\t.where(eq(regressionPatterns.status, \"active\"))\n\n\tconst bySeverity = await db\n\t\t.select({\n\t\t\tseverity: regressionPatterns.severity,\n\t\t\tcount: sql<number>`count(*)`,\n\t\t})\n\t\t.from(regressionPatterns)\n\t\t.groupBy(regressionPatterns.severity)\n\n\tconst bySubsystem = await db\n\t\t.select({\n\t\t\tsubsystem: regressionPatterns.subsystem,\n\t\t\tcount: sql<number>`count(*)`,\n\t\t\ttotalOccurrences: sql<number>`sum(${regressionPatterns.occurrenceCount})`,\n\t\t})\n\t\t.from(regressionPatterns)\n\t\t.groupBy(regressionPatterns.subsystem)\n\t\t.orderBy(desc(sql`sum(${regressionPatterns.occurrenceCount})`))\n\n\treturn {\n\t\ttotal: total[0]?.count ?? 0,\n\t\tactive: active[0]?.count ?? 0,\n\t\tbySeverity,\n\t\tbySubsystem,\n\t}\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAEA;AACA;AAOA;;;;;AAEO,SAAS,oBAAoB,SAAiB,EAAE,QAAkB;IACxE,MAAM,aAAa;QAAC;WAAc,SAAS,IAAI;KAAG,CAAC,IAAI,CAAC,KAAK,WAAW;IACxE,OAAO,IAAA,mHAAU,EAAC,OAAO,MAAM,CAAC,YAAY,MAAM,CAAC;AACpD;AAEO,eAAe,wBACrB,IAA6B,EAC7B,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,MAAM,IAAI;IAChB,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,0LAAkB,EACzB,MAAM,CAAC;QACP,GAAG,IAAI;QACP,WAAW;QACX,WAAW;IACZ,GACC,kBAAkB,CAAC;QACnB,QAAQ,0LAAkB,CAAC,WAAW;QACtC,KAAK;YACJ,iBAAiB,2WAAG,CAAC,EAAE,0LAAkB,CAAC,eAAe,CAAC,IAAI,CAAC;YAC/D,YAAY,KAAK,UAAU;YAC3B,UAAU,KAAK,QAAQ;YACvB,QAAQ,KAAK,MAAM;YACnB,WAAW;QACZ;IACD,GACC,SAAS;IAEX,MAAM,SAAS,MAAM,CAAC,EAAE;IACxB,IAAI,CAAC,QAAQ;QACZ,MAAM,IAAI,MAAM,CAAC,oCAAoC,EAAE,KAAK,WAAW,EAAE;IAC1E;IACA,OAAO;AACR;AAEO,eAAe,qBAAqB,EAAU,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACzF,OAAO,GAAG,KAAK,CAAC,kBAAkB,CAAC,SAAS,CAAC;QAC5C,OAAO,IAAA,gYAAE,EAAC,0LAAkB,CAAC,EAAE,EAAE;IAClC;AACD;AAEO,eAAe,2BAA2B,IAAY,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACjG,OAAO,GAAG,KAAK,CAAC,kBAAkB,CAAC,SAAS,CAAC;QAC5C,OAAO,IAAA,gYAAE,EAAC,0LAAkB,CAAC,WAAW,EAAE;IAC3C;AACD;AAEO,eAAe,sBACrB,UAMI,CAAC,CAAC,EACN,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,aAAa,EAAE;IAErB,IAAI,QAAQ,SAAS,EAAE;QACtB,WAAW,IAAI,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,SAAS,EAAE,QAAQ,SAAS;IACnE;IACA,IAAI,QAAQ,QAAQ,EAAE;QACrB,WAAW,IAAI,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,QAAQ,EAAE,QAAQ,QAAQ;IACjE;IACA,IAAI,QAAQ,MAAM,EAAE;QACnB,WAAW,IAAI,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,MAAM,EAAE,QAAQ,MAAM;IAC7D;IACA,IAAI,QAAQ,cAAc,KAAK,WAAW;QACzC,WAAW,IAAI,CAAC,2WAAG,CAAC,EAAE,0LAAkB,CAAC,eAAe,CAAC,IAAI,EAAE,QAAQ,cAAc,CAAC,CAAC;IACxF;IAEA,OAAO,GAAG,KAAK,CAAC,kBAAkB,CAAC,QAAQ,CAAC;QAC3C,OAAO,WAAW,MAAM,GAAG,IAAI,IAAA,iYAAG,KAAI,cAAc;QACpD,SAAS;YAAC,IAAA,8XAAI,EAAC,0LAAkB,CAAC,eAAe;YAAG,IAAA,8XAAI,EAAC,0LAAkB,CAAC,SAAS;SAAE;QACvF,OAAO,QAAQ,KAAK;IACrB;AACD;AAEO,eAAe,mBACrB,WAAmB,EACnB,SAAiB,EACjB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,UAAU,MAAM,2BAA2B,aAAa;IAC9D,IAAI,CAAC,SAAS;QACb,MAAM,IAAI,MAAM,CAAC,mBAAmB,EAAE,aAAa;IACpD;IAEA,MAAM,eAAe,QAAQ,UAAU,IAAI,EAAE;IAC7C,IAAI,aAAa,QAAQ,CAAC,YAAY;QACrC,OAAO;IACR;IAEA,MAAM,cAAc;WAAI;QAAc;KAAU;IAEhD,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,0LAAkB,EACzB,GAAG,CAAC;QACJ,YAAY;QACZ,iBAAiB,YAAY,MAAM;QACnC,WAAW,IAAI;IAChB,GACC,KAAK,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,WAAW,EAAE,cACzC,SAAS;IAEX,OAAO,MAAM,CAAC,EAAE;AACjB;AAEO,eAAe,sBACrB,WAAmB,EACnB,QAAuB,EACvB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,OAAO,GACL,MAAM,CAAC,0LAAkB,EACzB,GAAG,CAAC;QACJ;QACA,WAAW,IAAI;IAChB,GACC,KAAK,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,WAAW,EAAE,cACzC,SAAS;AACZ;AAEO,eAAe,eAAe,WAAmB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC5F,OAAO,GACL,MAAM,CAAC,0LAAkB,EACzB,GAAG,CAAC;QACJ,QAAQ;QACR,WAAW,IAAI;IAChB,GACC,KAAK,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,WAAW,EAAE,cACzC,SAAS;AACZ;AAEO,eAAe,kBAAkB,KAA4B,IAAA,yKAAK,GAAE;IAC1E,OAAO,sBAAsB;QAAE,QAAQ;IAAS,GAAG;AACpD;AAEO,eAAe,gBAAgB,KAA4B,IAAA,yKAAK,GAAE;IACxE,MAAM,QAAQ,MAAM,GAAG,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GAAG,IAAI,CAAC,0LAAkB;IAEvF,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GACtC,IAAI,CAAC,0LAAkB,EACvB,KAAK,CAAC,IAAA,gYAAE,EAAC,0LAAkB,CAAC,MAAM,EAAE;IAEtC,MAAM,aAAa,MAAM,GACvB,MAAM,CAAC;QACP,UAAU,0LAAkB,CAAC,QAAQ;QACrC,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAC7B,GACC,IAAI,CAAC,0LAAkB,EACvB,OAAO,CAAC,0LAAkB,CAAC,QAAQ;IAErC,MAAM,cAAc,MAAM,GACxB,MAAM,CAAC;QACP,WAAW,0LAAkB,CAAC,SAAS;QACvC,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;QAC5B,kBAAkB,2WAAG,AAAQ,CAAC,IAAI,EAAE,0LAAkB,CAAC,eAAe,CAAC,CAAC,CAAC;IAC1E,GACC,IAAI,CAAC,0LAAkB,EACvB,OAAO,CAAC,0LAAkB,CAAC,SAAS,EACpC,OAAO,CAAC,IAAA,8XAAI,EAAC,2WAAG,CAAC,IAAI,EAAE,0LAAkB,CAAC,eAAe,CAAC,CAAC,CAAC;IAE9D,OAAO;QACN,OAAO,KAAK,CAAC,EAAE,EAAE,SAAS;QAC1B,QAAQ,MAAM,CAAC,EAAE,EAAE,SAAS;QAC5B;QACA;IACD;AACD"}},
    {"offset": {"line": 928, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/cache.ts"],"sourcesContent":["import { eq, sql, and, lt } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport { analysisCache, type InsertAnalysisCache, type CacheType } from \"../schema\"\nimport { createHash } from \"crypto\"\n\nconst DEFAULT_CACHE_TTL_HOURS = 24 * 7 // 1 week\n\nexport function generateCacheKey(type: CacheType, ...args: string[]): string {\n\treturn createHash(\"md5\")\n\t\t.update([type, ...args].join(\":\"))\n\t\t.digest(\"hex\")\n}\n\nexport async function getCacheEntry(cacheKey: string, db: DatabaseOrTransaction = getDb()) {\n\tconst entry = await db.query.analysisCache.findFirst({\n\t\twhere: and(eq(analysisCache.cacheKey, cacheKey), sql`${analysisCache.expiresAt} > ${Date.now()}`),\n\t})\n\n\treturn entry\n}\n\nexport async function setCacheEntry(\n\tdata: InsertAnalysisCache,\n\tttlHours: number = DEFAULT_CACHE_TTL_HOURS,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst now = new Date()\n\tconst expiresAt = new Date(now.getTime() + ttlHours * 60 * 60 * 1000)\n\n\tconst result = await db\n\t\t.insert(analysisCache)\n\t\t.values({\n\t\t\t...data,\n\t\t\tcreatedAt: now,\n\t\t\texpiresAt,\n\t\t})\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: analysisCache.cacheKey,\n\t\t\tset: {\n\t\t\t\tresultSha: data.resultSha,\n\t\t\t\tresultData: data.resultData,\n\t\t\t\tcreatedAt: now,\n\t\t\t\texpiresAt,\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\treturn result[0]\n}\n\nexport async function getBlameCache(\n\tfilePath: string,\n\tlineRange: string,\n\tcommitRange: string,\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst cacheKey = generateCacheKey(\"blame\", filePath, lineRange, commitRange)\n\treturn getCacheEntry(cacheKey, db)\n}\n\nexport async function setBlameCache(\n\tfilePath: string,\n\tlineRange: string,\n\tcommitRange: string,\n\tresultShas: string[],\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst cacheKey = generateCacheKey(\"blame\", filePath, lineRange, commitRange)\n\treturn setCacheEntry(\n\t\t{\n\t\t\tcacheKey,\n\t\t\tcacheType: \"blame\",\n\t\t\tfilePath,\n\t\t\tlineRange,\n\t\t\tresultData: resultShas,\n\t\t},\n\t\tdb,\n\t)\n}\n\nexport async function invalidateCacheForFile(filePath: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.delete(analysisCache).where(eq(analysisCache.filePath, filePath))\n}\n\nexport async function cleanupExpiredCache(db: DatabaseOrTransaction = getDb()) {\n\tconst now = Date.now()\n\treturn db.delete(analysisCache).where(lt(analysisCache.expiresAt, new Date(now)))\n}\n\nexport async function getCacheStats(db: DatabaseOrTransaction = getDb()) {\n\tconst total = await db.select({ count: sql<number>`count(*)` }).from(analysisCache)\n\n\tconst byType = await db\n\t\t.select({\n\t\t\tcacheType: analysisCache.cacheType,\n\t\t\tcount: sql<number>`count(*)`,\n\t\t})\n\t\t.from(analysisCache)\n\t\t.groupBy(analysisCache.cacheType)\n\n\tconst expired = await db\n\t\t.select({ count: sql<number>`count(*)` })\n\t\t.from(analysisCache)\n\t\t.where(lt(analysisCache.expiresAt, new Date()))\n\n\treturn {\n\t\ttotal: total[0]?.count ?? 0,\n\t\texpired: expired[0]?.count ?? 0,\n\t\tbyType,\n\t}\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAEA;AACA;AACA;;;;;AAEA,MAAM,0BAA0B,KAAK,EAAE,SAAS;;AAEzC,SAAS,iBAAiB,IAAe,EAAE,GAAG,IAAc;IAClE,OAAO,IAAA,mHAAU,EAAC,OAChB,MAAM,CAAC;QAAC;WAAS;KAAK,CAAC,IAAI,CAAC,MAC5B,MAAM,CAAC;AACV;AAEO,eAAe,cAAc,QAAgB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACxF,MAAM,QAAQ,MAAM,GAAG,KAAK,CAAC,aAAa,CAAC,SAAS,CAAC;QACpD,OAAO,IAAA,iYAAG,EAAC,IAAA,gYAAE,EAAC,qLAAa,CAAC,QAAQ,EAAE,WAAW,2WAAG,CAAC,EAAE,qLAAa,CAAC,SAAS,CAAC,GAAG,EAAE,KAAK,GAAG,GAAG,CAAC;IACjG;IAEA,OAAO;AACR;AAEO,eAAe,cACrB,IAAyB,EACzB,WAAmB,uBAAuB,EAC1C,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,MAAM,IAAI;IAChB,MAAM,YAAY,IAAI,KAAK,IAAI,OAAO,KAAK,WAAW,KAAK,KAAK;IAEhE,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,qLAAa,EACpB,MAAM,CAAC;QACP,GAAG,IAAI;QACP,WAAW;QACX;IACD,GACC,kBAAkB,CAAC;QACnB,QAAQ,qLAAa,CAAC,QAAQ;QAC9B,KAAK;YACJ,WAAW,KAAK,SAAS;YACzB,YAAY,KAAK,UAAU;YAC3B,WAAW;YACX;QACD;IACD,GACC,SAAS;IAEX,OAAO,MAAM,CAAC,EAAE;AACjB;AAEO,eAAe,cACrB,QAAgB,EAChB,SAAiB,EACjB,WAAmB,EACnB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,WAAW,iBAAiB,SAAS,UAAU,WAAW;IAChE,OAAO,cAAc,UAAU;AAChC;AAEO,eAAe,cACrB,QAAgB,EAChB,SAAiB,EACjB,WAAmB,EACnB,UAAoB,EACpB,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,WAAW,iBAAiB,SAAS,UAAU,WAAW;IAChE,OAAO,cACN;QACC;QACA,WAAW;QACX;QACA;QACA,YAAY;IACb,GACA;AAEF;AAEO,eAAe,uBAAuB,QAAgB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACjG,OAAO,GAAG,MAAM,CAAC,qLAAa,EAAE,KAAK,CAAC,IAAA,gYAAE,EAAC,qLAAa,CAAC,QAAQ,EAAE;AAClE;AAEO,eAAe,oBAAoB,KAA4B,IAAA,yKAAK,GAAE;IAC5E,MAAM,MAAM,KAAK,GAAG;IACpB,OAAO,GAAG,MAAM,CAAC,qLAAa,EAAE,KAAK,CAAC,IAAA,gYAAE,EAAC,qLAAa,CAAC,SAAS,EAAE,IAAI,KAAK;AAC5E;AAEO,eAAe,cAAc,KAA4B,IAAA,yKAAK,GAAE;IACtE,MAAM,QAAQ,MAAM,GAAG,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GAAG,IAAI,CAAC,qLAAa;IAElF,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC;QACP,WAAW,qLAAa,CAAC,SAAS;QAClC,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAC7B,GACC,IAAI,CAAC,qLAAa,EAClB,OAAO,CAAC,qLAAa,CAAC,SAAS;IAEjC,MAAM,UAAU,MAAM,GACpB,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GACtC,IAAI,CAAC,qLAAa,EAClB,KAAK,CAAC,IAAA,gYAAE,EAAC,qLAAa,CAAC,SAAS,EAAE,IAAI;IAExC,OAAO;QACN,OAAO,KAAK,CAAC,EAAE,EAAE,SAAS;QAC1B,SAAS,OAAO,CAAC,EAAE,EAAE,SAAS;QAC9B;IACD;AACD"}},
    {"offset": {"line": 1029, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/queries/releases.ts"],"sourcesContent":["import { eq, desc, and, gte, lte, sql } from \"drizzle-orm\"\nimport type { DatabaseOrTransaction } from \"../db\"\nimport { getDb } from \"../db\"\nimport { releases, commits, classifications, type InsertRelease, type Release } from \"../schema\"\n\nexport async function createRelease(data: InsertRelease, db: DatabaseOrTransaction = getDb()): Promise<Release> {\n\tconst result = await db\n\t\t.insert(releases)\n\t\t.values(data)\n\t\t.onConflictDoUpdate({\n\t\t\ttarget: releases.version,\n\t\t\tset: {\n\t\t\t\tdate: data.date,\n\t\t\t\ttagSha: data.tagSha,\n\t\t\t\tfixCount: data.fixCount,\n\t\t\t\tfeatureCount: data.featureCount,\n\t\t\t\ttotalRisk: data.totalRisk,\n\t\t\t},\n\t\t})\n\t\t.returning()\n\n\tconst record = result[0]\n\tif (!record) {\n\t\tthrow new Error(`Failed to create release ${data.version}`)\n\t}\n\treturn record\n}\n\nexport async function getRelease(version: string, db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.releases.findFirst({\n\t\twhere: eq(releases.version, version),\n\t})\n}\n\nexport async function getReleases(\n\toptions: {\n\t\tsince?: Date\n\t\tuntil?: Date\n\t\tlimit?: number\n\t} = {},\n\tdb: DatabaseOrTransaction = getDb(),\n) {\n\tconst conditions = []\n\n\tif (options.since) {\n\t\tconditions.push(gte(releases.date, options.since))\n\t}\n\tif (options.until) {\n\t\tconditions.push(lte(releases.date, options.until))\n\t}\n\n\treturn db.query.releases.findMany({\n\t\twhere: conditions.length > 0 ? and(...conditions) : undefined,\n\t\torderBy: desc(releases.date),\n\t\tlimit: options.limit,\n\t})\n}\n\nexport async function getLatestRelease(db: DatabaseOrTransaction = getDb()) {\n\treturn db.query.releases.findFirst({\n\t\torderBy: desc(releases.date),\n\t})\n}\n\nexport async function updateReleaseStats(version: string, db: DatabaseOrTransaction = getDb()) {\n\t// Get the release\n\tconst release = await getRelease(version, db)\n\tif (!release || !release.tagSha) {\n\t\treturn null\n\t}\n\n\t// Get the previous release to determine commit range\n\tconst allReleases = await getReleases({}, db)\n\tconst currentIndex = allReleases.findIndex((r) => r.version === version)\n\tconst previousRelease = allReleases[currentIndex + 1]\n\n\t// Get commits between releases\n\tconst conditions = [lte(commits.date, release.date)]\n\tif (previousRelease) {\n\t\tconditions.push(gte(commits.date, previousRelease.date))\n\t}\n\n\tconst releaseCommits = await db.query.commits.findMany({\n\t\twhere: and(...conditions),\n\t\twith: {\n\t\t\tclassification: true,\n\t\t},\n\t})\n\n\tlet fixCount = 0\n\tlet featureCount = 0\n\tlet totalRisk = 0\n\n\tfor (const commit of releaseCommits) {\n\t\tif (commit.messageType === \"fix\") fixCount++\n\t\tif (commit.messageType === \"feat\") featureCount++\n\t\tif (commit.classification) {\n\t\t\ttotalRisk += commit.classification.riskScore\n\t\t}\n\t}\n\n\tconst result = await db\n\t\t.update(releases)\n\t\t.set({\n\t\t\tfixCount,\n\t\t\tfeatureCount,\n\t\t\ttotalRisk,\n\t\t})\n\t\t.where(eq(releases.version, version))\n\t\t.returning()\n\n\treturn result[0]\n}\n\nexport async function getReleaseStats(db: DatabaseOrTransaction = getDb()) {\n\tconst total = await db.select({ count: sql<number>`count(*)` }).from(releases)\n\n\tconst avgFixes = await db.select({ avg: sql<number>`avg(${releases.fixCount})` }).from(releases)\n\n\tconst avgFeatures = await db.select({ avg: sql<number>`avg(${releases.featureCount})` }).from(releases)\n\n\tconst avgRisk = await db.select({ avg: sql<number>`avg(${releases.totalRisk})` }).from(releases)\n\n\treturn {\n\t\ttotal: total[0]?.count ?? 0,\n\t\tavgFixesPerRelease: avgFixes[0]?.avg ?? 0,\n\t\tavgFeaturesPerRelease: avgFeatures[0]?.avg ?? 0,\n\t\tavgRiskPerRelease: avgRisk[0]?.avg ?? 0,\n\t}\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAEA;AACA;;;;AAEO,eAAe,cAAc,IAAmB,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC3F,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,gLAAQ,EACf,MAAM,CAAC,MACP,kBAAkB,CAAC;QACnB,QAAQ,gLAAQ,CAAC,OAAO;QACxB,KAAK;YACJ,MAAM,KAAK,IAAI;YACf,QAAQ,KAAK,MAAM;YACnB,UAAU,KAAK,QAAQ;YACvB,cAAc,KAAK,YAAY;YAC/B,WAAW,KAAK,SAAS;QAC1B;IACD,GACC,SAAS;IAEX,MAAM,SAAS,MAAM,CAAC,EAAE;IACxB,IAAI,CAAC,QAAQ;QACZ,MAAM,IAAI,MAAM,CAAC,yBAAyB,EAAE,KAAK,OAAO,EAAE;IAC3D;IACA,OAAO;AACR;AAEO,eAAe,WAAW,OAAe,EAAE,KAA4B,IAAA,yKAAK,GAAE;IACpF,OAAO,GAAG,KAAK,CAAC,QAAQ,CAAC,SAAS,CAAC;QAClC,OAAO,IAAA,gYAAE,EAAC,gLAAQ,CAAC,OAAO,EAAE;IAC7B;AACD;AAEO,eAAe,YACrB,UAII,CAAC,CAAC,EACN,KAA4B,IAAA,yKAAK,GAAE;IAEnC,MAAM,aAAa,EAAE;IAErB,IAAI,QAAQ,KAAK,EAAE;QAClB,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,gLAAQ,CAAC,IAAI,EAAE,QAAQ,KAAK;IACjD;IACA,IAAI,QAAQ,KAAK,EAAE;QAClB,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,gLAAQ,CAAC,IAAI,EAAE,QAAQ,KAAK;IACjD;IAEA,OAAO,GAAG,KAAK,CAAC,QAAQ,CAAC,QAAQ,CAAC;QACjC,OAAO,WAAW,MAAM,GAAG,IAAI,IAAA,iYAAG,KAAI,cAAc;QACpD,SAAS,IAAA,8XAAI,EAAC,gLAAQ,CAAC,IAAI;QAC3B,OAAO,QAAQ,KAAK;IACrB;AACD;AAEO,eAAe,iBAAiB,KAA4B,IAAA,yKAAK,GAAE;IACzE,OAAO,GAAG,KAAK,CAAC,QAAQ,CAAC,SAAS,CAAC;QAClC,SAAS,IAAA,8XAAI,EAAC,gLAAQ,CAAC,IAAI;IAC5B;AACD;AAEO,eAAe,mBAAmB,OAAe,EAAE,KAA4B,IAAA,yKAAK,GAAE;IAC5F,kBAAkB;IAClB,MAAM,UAAU,MAAM,WAAW,SAAS;IAC1C,IAAI,CAAC,WAAW,CAAC,QAAQ,MAAM,EAAE;QAChC,OAAO;IACR;IAEA,qDAAqD;IACrD,MAAM,cAAc,MAAM,YAAY,CAAC,GAAG;IAC1C,MAAM,eAAe,YAAY,SAAS,CAAC,CAAC,IAAM,EAAE,OAAO,KAAK;IAChE,MAAM,kBAAkB,WAAW,CAAC,eAAe,EAAE;IAErD,+BAA+B;IAC/B,MAAM,aAAa;QAAC,IAAA,iYAAG,EAAC,+KAAO,CAAC,IAAI,EAAE,QAAQ,IAAI;KAAE;IACpD,IAAI,iBAAiB;QACpB,WAAW,IAAI,CAAC,IAAA,iYAAG,EAAC,+KAAO,CAAC,IAAI,EAAE,gBAAgB,IAAI;IACvD;IAEA,MAAM,iBAAiB,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC;QACtD,OAAO,IAAA,iYAAG,KAAI;QACd,MAAM;YACL,gBAAgB;QACjB;IACD;IAEA,IAAI,WAAW;IACf,IAAI,eAAe;IACnB,IAAI,YAAY;IAEhB,KAAK,MAAM,UAAU,eAAgB;QACpC,IAAI,OAAO,WAAW,KAAK,OAAO;QAClC,IAAI,OAAO,WAAW,KAAK,QAAQ;QACnC,IAAI,OAAO,cAAc,EAAE;YAC1B,aAAa,OAAO,cAAc,CAAC,SAAS;QAC7C;IACD;IAEA,MAAM,SAAS,MAAM,GACnB,MAAM,CAAC,gLAAQ,EACf,GAAG,CAAC;QACJ;QACA;QACA;IACD,GACC,KAAK,CAAC,IAAA,gYAAE,EAAC,gLAAQ,CAAC,OAAO,EAAE,UAC3B,SAAS;IAEX,OAAO,MAAM,CAAC,EAAE;AACjB;AAEO,eAAe,gBAAgB,KAA4B,IAAA,yKAAK,GAAE;IACxE,MAAM,QAAQ,MAAM,GAAG,MAAM,CAAC;QAAE,OAAO,2WAAG,AAAQ,CAAC,QAAQ,CAAC;IAAC,GAAG,IAAI,CAAC,gLAAQ;IAE7E,MAAM,WAAW,MAAM,GAAG,MAAM,CAAC;QAAE,KAAK,2WAAG,AAAQ,CAAC,IAAI,EAAE,gLAAQ,CAAC,QAAQ,CAAC,CAAC,CAAC;IAAC,GAAG,IAAI,CAAC,gLAAQ;IAE/F,MAAM,cAAc,MAAM,GAAG,MAAM,CAAC;QAAE,KAAK,2WAAG,AAAQ,CAAC,IAAI,EAAE,gLAAQ,CAAC,YAAY,CAAC,CAAC,CAAC;IAAC,GAAG,IAAI,CAAC,gLAAQ;IAEtG,MAAM,UAAU,MAAM,GAAG,MAAM,CAAC;QAAE,KAAK,2WAAG,AAAQ,CAAC,IAAI,EAAE,gLAAQ,CAAC,SAAS,CAAC,CAAC,CAAC;IAAC,GAAG,IAAI,CAAC,gLAAQ;IAE/F,OAAO;QACN,OAAO,KAAK,CAAC,EAAE,EAAE,SAAS;QAC1B,oBAAoB,QAAQ,CAAC,EAAE,EAAE,OAAO;QACxC,uBAAuB,WAAW,CAAC,EAAE,EAAE,OAAO;QAC9C,mBAAmB,OAAO,CAAC,EAAE,EAAE,OAAO;IACvC;AACD"}},
    {"offset": {"line": 1156, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/db/index.ts"],"sourcesContent":["export * from \"./schema\"\nexport * from \"./db\"\nexport * from \"./queries/commits\"\nexport * from \"./queries/classifications\"\nexport * from \"./queries/causality\"\nexport * from \"./queries/patterns\"\nexport * from \"./queries/cache\"\nexport * from \"./queries/releases\"\n"],"names":[],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 1177, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":""}},
    {"offset": {"line": 1279, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/git/extractor.ts"],"sourcesContent":["import { execa } from \"execa\"\nimport type { GitCommitRaw, GitFileChange } from \"../types\"\n\n// Git format string: SHA, short SHA, author name, author email, date (ISO), body\n// Note: LOG_FORMAT ends without a null - RECORD_SEPARATOR_FORMAT provides the separator\nconst LOG_FORMAT = \"%H%x00%h%x00%an%x00%ae%x00%aI%x00%B\"\nconst FIELD_SEPARATOR = \"\\x00\"\n// Git format placeholder for use in --format argument (3 nulls between records)\nconst RECORD_SEPARATOR_FORMAT = \"%x00%x00%x00\"\n// Literal null bytes for parsing git output\nconst RECORD_SEPARATOR = \"\\x00\\x00\\x00\"\n\nexport interface ExtractOptions {\n\tsince?: string // Commit ref or date\n\tuntil?: string // Commit ref or date\n\tlimit?: number\n\trepoPath?: string\n}\n\nexport async function extractCommits(options: ExtractOptions = {}): Promise<GitCommitRaw[]> {\n\t// Note: We don't use --numstat here because it complicates parsing.\n\t// File changes are fetched separately via extractFileChanges()\n\tconst args = [\"log\", `--format=${LOG_FORMAT}${RECORD_SEPARATOR_FORMAT}`]\n\n\tif (options.since) {\n\t\targs.push(`${options.since}..${options.until || \"HEAD\"}`)\n\t} else if (options.until) {\n\t\targs.push(options.until)\n\t}\n\n\tif (options.limit) {\n\t\targs.push(`-n`, String(options.limit))\n\t}\n\n\tconst { stdout } = await execa(\"git\", args, {\n\t\tcwd: options.repoPath || process.cwd(),\n\t\tmaxBuffer: 100 * 1024 * 1024, // 100MB buffer for large histories\n\t})\n\n\treturn parseGitLog(stdout)\n}\n\nfunction parseGitLog(output: string): GitCommitRaw[] {\n\tconst records = output\n\t\t.split(RECORD_SEPARATOR)\n\t\t.map((r) => r.trim())\n\t\t.filter(Boolean)\n\tconst commits: GitCommitRaw[] = []\n\n\tfor (const record of records) {\n\t\tconst parts = record.split(FIELD_SEPARATOR)\n\t\tif (parts.length < 6) continue\n\n\t\tconst [sha, shortSha, author, authorEmail, dateStr, message] = parts\n\n\t\t// Extract PR number from message\n\t\tconst prMatch = message.match(/#(\\d+)/)\n\t\tconst prNumber = prMatch ? parseInt(prMatch[1], 10) : undefined\n\n\t\tcommits.push({\n\t\t\tsha,\n\t\t\tshortSha,\n\t\t\tauthor,\n\t\t\tauthorEmail,\n\t\t\tdate: new Date(dateStr),\n\t\t\tmessage: message.trim(),\n\t\t\tprNumber,\n\t\t\t// File stats are fetched separately via extractFileChanges()\n\t\t\tfilesChanged: 0,\n\t\t\tinsertions: 0,\n\t\t\tdeletions: 0,\n\t\t})\n\t}\n\n\treturn commits\n}\n\nexport async function extractFileChanges(sha: string, repoPath?: string): Promise<GitFileChange[]> {\n\tconst { stdout } = await execa(\"git\", [\"diff-tree\", \"--no-commit-id\", \"--name-status\", \"-r\", sha], {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\n\tconst changes: GitFileChange[] = []\n\tconst lines = stdout.trim().split(\"\\n\").filter(Boolean)\n\n\t// Get numstat for insertions/deletions\n\tconst { stdout: numstat } = await execa(\"git\", [\"diff-tree\", \"--no-commit-id\", \"--numstat\", \"-r\", sha], {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\n\tconst numstatMap = new Map<string, { insertions: number; deletions: number }>()\n\tfor (const line of numstat.trim().split(\"\\n\").filter(Boolean)) {\n\t\tconst match = line.match(/^(\\d+|-)\\t(\\d+|-)\\t(.+)$/)\n\t\tif (match) {\n\t\t\tnumstatMap.set(match[3], {\n\t\t\t\tinsertions: match[1] === \"-\" ? 0 : parseInt(match[1], 10),\n\t\t\t\tdeletions: match[2] === \"-\" ? 0 : parseInt(match[2], 10),\n\t\t\t})\n\t\t}\n\t}\n\n\tfor (const line of lines) {\n\t\tconst parts = line.split(\"\\t\")\n\t\tif (parts.length < 2) continue\n\n\t\tconst changeTypeRaw = parts[0]\n\t\tconst filePath = parts[parts.length - 1] // Handle renames (R100\\told\\tnew)\n\n\t\tlet changeType: GitFileChange[\"changeType\"] = \"M\"\n\t\tif (changeTypeRaw.startsWith(\"A\")) changeType = \"A\"\n\t\telse if (changeTypeRaw.startsWith(\"D\")) changeType = \"D\"\n\t\telse if (changeTypeRaw.startsWith(\"R\")) changeType = \"R\"\n\n\t\tconst stats = numstatMap.get(filePath) || { insertions: 0, deletions: 0 }\n\n\t\tchanges.push({\n\t\t\tfilePath,\n\t\t\tchangeType,\n\t\t\tinsertions: stats.insertions,\n\t\t\tdeletions: stats.deletions,\n\t\t})\n\t}\n\n\treturn changes\n}\n\nexport async function getCommitCount(since?: string, until?: string, repoPath?: string): Promise<number> {\n\tconst args = [\"rev-list\", \"--count\"]\n\n\tif (since && until) {\n\t\targs.push(`${since}..${until}`)\n\t} else if (until) {\n\t\targs.push(until)\n\t} else {\n\t\targs.push(\"HEAD\")\n\t}\n\n\tconst { stdout } = await execa(\"git\", args, {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\n\treturn parseInt(stdout.trim(), 10)\n}\n\nexport async function getLatestTag(repoPath?: string): Promise<string | null> {\n\ttry {\n\t\tconst { stdout } = await execa(\"git\", [\"describe\", \"--tags\", \"--abbrev=0\"], {\n\t\t\tcwd: repoPath || process.cwd(),\n\t\t})\n\t\treturn stdout.trim()\n\t} catch {\n\t\treturn null\n\t}\n}\n\nexport async function getTags(repoPath?: string): Promise<{ name: string; sha: string; date: Date }[]> {\n\tconst { stdout } = await execa(\n\t\t\"git\",\n\t\t[\"for-each-ref\", \"--sort=-creatordate\", \"--format=%(refname:short)%00%(objectname)%00%(creatordate:iso)\", \"refs/tags\"],\n\t\t{\n\t\t\tcwd: repoPath || process.cwd(),\n\t\t},\n\t)\n\n\tconst tags: { name: string; sha: string; date: Date }[] = []\n\n\tfor (const line of stdout.trim().split(\"\\n\").filter(Boolean)) {\n\t\tconst [name, sha, dateStr] = line.split(\"\\x00\")\n\t\tif (name && sha && dateStr) {\n\t\t\ttags.push({\n\t\t\t\tname,\n\t\t\t\tsha,\n\t\t\t\tdate: new Date(dateStr),\n\t\t\t})\n\t\t}\n\t}\n\n\treturn tags\n}\n\nexport async function getHeadSha(repoPath?: string): Promise<string> {\n\tconst { stdout } = await execa(\"git\", [\"rev-parse\", \"HEAD\"], {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\treturn stdout.trim()\n}\n\nexport async function resolveRef(ref: string, repoPath?: string): Promise<string> {\n\tconst { stdout } = await execa(\"git\", [\"rev-parse\", ref], {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\treturn stdout.trim()\n}\n\nexport async function getCommitsBetween(since: string, until: string, repoPath?: string): Promise<string[]> {\n\tconst { stdout } = await execa(\"git\", [\"rev-list\", `${since}..${until}`], {\n\t\tcwd: repoPath || process.cwd(),\n\t})\n\treturn stdout.trim().split(\"\\n\").filter(Boolean)\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAAA;;AAGA,iFAAiF;AACjF,wFAAwF;AACxF,MAAM,aAAa;AACnB,MAAM,kBAAkB;AACxB,gFAAgF;AAChF,MAAM,0BAA0B;AAChC,4CAA4C;AAC5C,MAAM,mBAAmB;AASlB,eAAe,eAAe,UAA0B,CAAC,CAAC;IAChE,oEAAoE;IACpE,+DAA+D;IAC/D,MAAM,OAAO;QAAC;QAAO,CAAC,SAAS,EAAE,aAAa,yBAAyB;KAAC;IAExE,IAAI,QAAQ,KAAK,EAAE;QAClB,KAAK,IAAI,CAAC,GAAG,QAAQ,KAAK,CAAC,EAAE,EAAE,QAAQ,KAAK,IAAI,QAAQ;IACzD,OAAO,IAAI,QAAQ,KAAK,EAAE;QACzB,KAAK,IAAI,CAAC,QAAQ,KAAK;IACxB;IAEA,IAAI,QAAQ,KAAK,EAAE;QAClB,KAAK,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,OAAO,QAAQ,KAAK;IACrC;IAEA,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO,MAAM;QAC3C,KAAK,QAAQ,QAAQ,IAAI,QAAQ,GAAG;QACpC,WAAW,MAAM,OAAO;IACzB;IAEA,OAAO,YAAY;AACpB;AAEA,SAAS,YAAY,MAAc;IAClC,MAAM,UAAU,OACd,KAAK,CAAC,kBACN,GAAG,CAAC,CAAC,IAAM,EAAE,IAAI,IACjB,MAAM,CAAC;IACT,MAAM,UAA0B,EAAE;IAElC,KAAK,MAAM,UAAU,QAAS;QAC7B,MAAM,QAAQ,OAAO,KAAK,CAAC;QAC3B,IAAI,MAAM,MAAM,GAAG,GAAG;QAEtB,MAAM,CAAC,KAAK,UAAU,QAAQ,aAAa,SAAS,QAAQ,GAAG;QAE/D,iCAAiC;QACjC,MAAM,UAAU,QAAQ,KAAK,CAAC;QAC9B,MAAM,WAAW,UAAU,SAAS,OAAO,CAAC,EAAE,EAAE,MAAM;QAEtD,QAAQ,IAAI,CAAC;YACZ;YACA;YACA;YACA;YACA,MAAM,IAAI,KAAK;YACf,SAAS,QAAQ,IAAI;YACrB;YACA,6DAA6D;YAC7D,cAAc;YACd,YAAY;YACZ,WAAW;QACZ;IACD;IAEA,OAAO;AACR;AAEO,eAAe,mBAAmB,GAAW,EAAE,QAAiB;IACtE,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;QAAC;QAAa;QAAkB;QAAiB;QAAM;KAAI,EAAE;QAClG,KAAK,YAAY,QAAQ,GAAG;IAC7B;IAEA,MAAM,UAA2B,EAAE;IACnC,MAAM,QAAQ,OAAO,IAAI,GAAG,KAAK,CAAC,MAAM,MAAM,CAAC;IAE/C,uCAAuC;IACvC,MAAM,EAAE,QAAQ,OAAO,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;QAAC;QAAa;QAAkB;QAAa;QAAM;KAAI,EAAE;QACvG,KAAK,YAAY,QAAQ,GAAG;IAC7B;IAEA,MAAM,aAAa,IAAI;IACvB,KAAK,MAAM,QAAQ,QAAQ,IAAI,GAAG,KAAK,CAAC,MAAM,MAAM,CAAC,SAAU;QAC9D,MAAM,QAAQ,KAAK,KAAK,CAAC;QACzB,IAAI,OAAO;YACV,WAAW,GAAG,CAAC,KAAK,CAAC,EAAE,EAAE;gBACxB,YAAY,KAAK,CAAC,EAAE,KAAK,MAAM,IAAI,SAAS,KAAK,CAAC,EAAE,EAAE;gBACtD,WAAW,KAAK,CAAC,EAAE,KAAK,MAAM,IAAI,SAAS,KAAK,CAAC,EAAE,EAAE;YACtD;QACD;IACD;IAEA,KAAK,MAAM,QAAQ,MAAO;QACzB,MAAM,QAAQ,KAAK,KAAK,CAAC;QACzB,IAAI,MAAM,MAAM,GAAG,GAAG;QAEtB,MAAM,gBAAgB,KAAK,CAAC,EAAE;QAC9B,MAAM,WAAW,KAAK,CAAC,MAAM,MAAM,GAAG,EAAE,CAAC,kCAAkC;;QAE3E,IAAI,aAA0C;QAC9C,IAAI,cAAc,UAAU,CAAC,MAAM,aAAa;aAC3C,IAAI,cAAc,UAAU,CAAC,MAAM,aAAa;aAChD,IAAI,cAAc,UAAU,CAAC,MAAM,aAAa;QAErD,MAAM,QAAQ,WAAW,GAAG,CAAC,aAAa;YAAE,YAAY;YAAG,WAAW;QAAE;QAExE,QAAQ,IAAI,CAAC;YACZ;YACA;YACA,YAAY,MAAM,UAAU;YAC5B,WAAW,MAAM,SAAS;QAC3B;IACD;IAEA,OAAO;AACR;AAEO,eAAe,eAAe,KAAc,EAAE,KAAc,EAAE,QAAiB;IACrF,MAAM,OAAO;QAAC;QAAY;KAAU;IAEpC,IAAI,SAAS,OAAO;QACnB,KAAK,IAAI,CAAC,GAAG,MAAM,EAAE,EAAE,OAAO;IAC/B,OAAO,IAAI,OAAO;QACjB,KAAK,IAAI,CAAC;IACX,OAAO;QACN,KAAK,IAAI,CAAC;IACX;IAEA,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO,MAAM;QAC3C,KAAK,YAAY,QAAQ,GAAG;IAC7B;IAEA,OAAO,SAAS,OAAO,IAAI,IAAI;AAChC;AAEO,eAAe,aAAa,QAAiB;IACnD,IAAI;QACH,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;YAAC;YAAY;YAAU;SAAa,EAAE;YAC3E,KAAK,YAAY,QAAQ,GAAG;QAC7B;QACA,OAAO,OAAO,IAAI;IACnB,EAAE,OAAM;QACP,OAAO;IACR;AACD;AAEO,eAAe,QAAQ,QAAiB;IAC9C,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAC7B,OACA;QAAC;QAAgB;QAAuB;QAAkE;KAAY,EACtH;QACC,KAAK,YAAY,QAAQ,GAAG;IAC7B;IAGD,MAAM,OAAoD,EAAE;IAE5D,KAAK,MAAM,QAAQ,OAAO,IAAI,GAAG,KAAK,CAAC,MAAM,MAAM,CAAC,SAAU;QAC7D,MAAM,CAAC,MAAM,KAAK,QAAQ,GAAG,KAAK,KAAK,CAAC;QACxC,IAAI,QAAQ,OAAO,SAAS;YAC3B,KAAK,IAAI,CAAC;gBACT;gBACA;gBACA,MAAM,IAAI,KAAK;YAChB;QACD;IACD;IAEA,OAAO;AACR;AAEO,eAAe,WAAW,QAAiB;IACjD,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;QAAC;QAAa;KAAO,EAAE;QAC5D,KAAK,YAAY,QAAQ,GAAG;IAC7B;IACA,OAAO,OAAO,IAAI;AACnB;AAEO,eAAe,WAAW,GAAW,EAAE,QAAiB;IAC9D,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;QAAC;QAAa;KAAI,EAAE;QACzD,KAAK,YAAY,QAAQ,GAAG;IAC7B;IACA,OAAO,OAAO,IAAI;AACnB;AAEO,eAAe,kBAAkB,KAAa,EAAE,KAAa,EAAE,QAAiB;IACtF,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO;QAAC;QAAY,GAAG,MAAM,EAAE,EAAE,OAAO;KAAC,EAAE;QACzE,KAAK,YAAY,QAAQ,GAAG;IAC7B;IACA,OAAO,OAAO,IAAI,GAAG,KAAK,CAAC,MAAM,MAAM,CAAC;AACzC"}},
    {"offset": {"line": 1493, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/git/parser.ts"],"sourcesContent":["import type { ParsedConventionalCommit } from \"../types\"\n\n// Conventional commit regex pattern\n// Format: type(scope)!: description\nconst CONVENTIONAL_COMMIT_REGEX =\n\t/^(?<type>\\w+)(?:\\((?<scope>[^)]+)\\))?(?<breaking>!)?\\s*:\\s*(?<description>.+?)(?:\\n\\n(?<body>[\\s\\S]*?))?(?:\\n\\n(?<footer>[\\s\\S]*))?$/\n\n// Common commit type mappings\nconst TYPE_MAPPINGS: Record<string, string> = {\n\tfix: \"fix\",\n\tbugfix: \"fix\",\n\thotfix: \"fix\",\n\tfeat: \"feat\",\n\tfeature: \"feat\",\n\tdocs: \"docs\",\n\tdoc: \"docs\",\n\tstyle: \"style\",\n\trefactor: \"refactor\",\n\tperf: \"perf\",\n\tperformance: \"perf\",\n\ttest: \"test\",\n\ttests: \"test\",\n\tbuild: \"build\",\n\tci: \"ci\",\n\tchore: \"chore\",\n\trevert: \"revert\",\n\twip: \"chore\",\n}\n\nexport function parseConventionalCommit(message: string): ParsedConventionalCommit | null {\n\t// Extract first line for parsing\n\tconst firstLine = message.split(\"\\n\")[0].trim()\n\tconst rest = message.slice(firstLine.length).trim()\n\n\tconst match = CONVENTIONAL_COMMIT_REGEX.exec(message.trim())\n\n\tif (match?.groups) {\n\t\tconst { type, scope, breaking, description, body, footer } = match.groups\n\n\t\t// Extract PR number from description or footer\n\t\tconst prMatch = message.match(/#(\\d+)/)\n\t\tconst prNumber = prMatch ? parseInt(prMatch[1], 10) : undefined\n\n\t\treturn {\n\t\t\ttype: normalizeType(type),\n\t\t\tscope: scope?.trim(),\n\t\t\tbreaking: breaking === \"!\",\n\t\t\tdescription: description.trim(),\n\t\t\tbody: body?.trim(),\n\t\t\tfooter: footer?.trim(),\n\t\t\tprNumber,\n\t\t}\n\t}\n\n\t// Try simpler patterns for non-conventional commits\n\t// Pattern: \"type: description\"\n\tconst simpleMatch = firstLine.match(/^(\\w+):\\s*(.+)$/)\n\tif (simpleMatch) {\n\t\tconst [, type, description] = simpleMatch\n\t\tconst prMatch = message.match(/#(\\d+)/)\n\n\t\treturn {\n\t\t\ttype: normalizeType(type),\n\t\t\tbreaking: false,\n\t\t\tdescription: description.trim(),\n\t\t\tbody: rest || undefined,\n\t\t\tprNumber: prMatch ? parseInt(prMatch[1], 10) : undefined,\n\t\t}\n\t}\n\n\t// Pattern: \"[type] description\"\n\tconst bracketMatch = firstLine.match(/^\\[(\\w+)\\]\\s*(.+)$/)\n\tif (bracketMatch) {\n\t\tconst [, type, description] = bracketMatch\n\t\tconst prMatch = message.match(/#(\\d+)/)\n\n\t\treturn {\n\t\t\ttype: normalizeType(type),\n\t\t\tbreaking: false,\n\t\t\tdescription: description.trim(),\n\t\t\tbody: rest || undefined,\n\t\t\tprNumber: prMatch ? parseInt(prMatch[1], 10) : undefined,\n\t\t}\n\t}\n\n\treturn null\n}\n\nfunction normalizeType(type: string): string {\n\tconst normalized = type.toLowerCase().trim()\n\treturn TYPE_MAPPINGS[normalized] || normalized\n}\n\nexport function extractKeywords(message: string): string[] {\n\tconst keywords: string[] = []\n\n\t// Common bug-related keywords\n\tconst bugKeywords = [\n\t\t\"fix\",\n\t\t\"bug\",\n\t\t\"issue\",\n\t\t\"error\",\n\t\t\"crash\",\n\t\t\"fail\",\n\t\t\"broken\",\n\t\t\"regression\",\n\t\t\"revert\",\n\t\t\"incorrect\",\n\t\t\"wrong\",\n\t\t\"missing\",\n\t\t\"undefined\",\n\t\t\"null\",\n\t\t\"exception\",\n\t\t\"throw\",\n\t]\n\n\t// Feature-related keywords\n\tconst featureKeywords = [\"add\", \"new\", \"feature\", \"implement\", \"support\", \"enable\", \"introduce\"]\n\n\t// Refactor-related keywords\n\tconst refactorKeywords = [\"refactor\", \"restructure\", \"reorganize\", \"simplify\", \"clean\", \"improve\", \"optimize\"]\n\n\tconst lowerMessage = message.toLowerCase()\n\n\tfor (const kw of [...bugKeywords, ...featureKeywords, ...refactorKeywords]) {\n\t\tif (lowerMessage.includes(kw)) {\n\t\t\tkeywords.push(kw)\n\t\t}\n\t}\n\n\t// Extract technical terms (camelCase, snake_case, PascalCase identifiers)\n\tconst identifiers = message.match(/\\b[a-z]+(?:[A-Z][a-z]+)+\\b|\\b[a-z]+_[a-z_]+\\b|\\b[A-Z][a-z]+(?:[A-Z][a-z]+)+\\b/g)\n\tif (identifiers) {\n\t\tkeywords.push(...identifiers.slice(0, 5)) // Limit to 5 identifiers\n\t}\n\n\treturn [...new Set(keywords)]\n}\n\nexport function isBreakingChange(message: string): boolean {\n\tconst lowerMessage = message.toLowerCase()\n\n\t// Check for conventional commit breaking indicator\n\tif (message.includes(\"!:\")) return true\n\n\t// Check for BREAKING CHANGE in footer\n\tif (lowerMessage.includes(\"breaking change\")) return true\n\tif (lowerMessage.includes(\"breaking:\")) return true\n\n\treturn false\n}\n\nexport function extractScope(message: string): string | undefined {\n\tconst parsed = parseConventionalCommit(message)\n\treturn parsed?.scope\n}\n\nexport function extractPrNumber(message: string): number | undefined {\n\t// Common patterns:\n\t// (#123)\n\t// #123\n\t// PR #123\n\t// Fixes #123\n\tconst match = message.match(/#(\\d+)/)\n\treturn match ? parseInt(match[1], 10) : undefined\n}\n\nexport function isRevert(message: string): boolean {\n\tconst lowerMessage = message.toLowerCase()\n\treturn lowerMessage.startsWith(\"revert\") || lowerMessage.includes(\"reverts commit\") || lowerMessage.includes('revert \"')\n}\n\nexport function getRevertedSha(message: string): string | undefined {\n\t// Pattern: Revert \"...\" - This reverts commit <sha>\n\tconst match = message.match(/This reverts commit ([a-f0-9]{7,40})/i)\n\tif (match) return match[1]\n\n\t// Pattern: revert <sha>\n\tconst simpleMatch = message.match(/revert\\s+([a-f0-9]{7,40})/i)\n\tif (simpleMatch) return simpleMatch[1]\n\n\treturn undefined\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAEA,oCAAoC;AACpC,oCAAoC;AACpC,MAAM,4BACL;AAED,8BAA8B;AAC9B,MAAM,gBAAwC;IAC7C,KAAK;IACL,QAAQ;IACR,QAAQ;IACR,MAAM;IACN,SAAS;IACT,MAAM;IACN,KAAK;IACL,OAAO;IACP,UAAU;IACV,MAAM;IACN,aAAa;IACb,MAAM;IACN,OAAO;IACP,OAAO;IACP,IAAI;IACJ,OAAO;IACP,QAAQ;IACR,KAAK;AACN;AAEO,SAAS,wBAAwB,OAAe;IACtD,iCAAiC;IACjC,MAAM,YAAY,QAAQ,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC,IAAI;IAC7C,MAAM,OAAO,QAAQ,KAAK,CAAC,UAAU,MAAM,EAAE,IAAI;IAEjD,MAAM,QAAQ,0BAA0B,IAAI,CAAC,QAAQ,IAAI;IAEzD,IAAI,OAAO,QAAQ;QAClB,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,QAAQ,EAAE,WAAW,EAAE,IAAI,EAAE,MAAM,EAAE,GAAG,MAAM,MAAM;QAEzE,+CAA+C;QAC/C,MAAM,UAAU,QAAQ,KAAK,CAAC;QAC9B,MAAM,WAAW,UAAU,SAAS,OAAO,CAAC,EAAE,EAAE,MAAM;QAEtD,OAAO;YACN,MAAM,cAAc;YACpB,OAAO,OAAO;YACd,UAAU,aAAa;YACvB,aAAa,YAAY,IAAI;YAC7B,MAAM,MAAM;YACZ,QAAQ,QAAQ;YAChB;QACD;IACD;IAEA,oDAAoD;IACpD,+BAA+B;IAC/B,MAAM,cAAc,UAAU,KAAK,CAAC;IACpC,IAAI,aAAa;QAChB,MAAM,GAAG,MAAM,YAAY,GAAG;QAC9B,MAAM,UAAU,QAAQ,KAAK,CAAC;QAE9B,OAAO;YACN,MAAM,cAAc;YACpB,UAAU;YACV,aAAa,YAAY,IAAI;YAC7B,MAAM,QAAQ;YACd,UAAU,UAAU,SAAS,OAAO,CAAC,EAAE,EAAE,MAAM;QAChD;IACD;IAEA,gCAAgC;IAChC,MAAM,eAAe,UAAU,KAAK,CAAC;IACrC,IAAI,cAAc;QACjB,MAAM,GAAG,MAAM,YAAY,GAAG;QAC9B,MAAM,UAAU,QAAQ,KAAK,CAAC;QAE9B,OAAO;YACN,MAAM,cAAc;YACpB,UAAU;YACV,aAAa,YAAY,IAAI;YAC7B,MAAM,QAAQ;YACd,UAAU,UAAU,SAAS,OAAO,CAAC,EAAE,EAAE,MAAM;QAChD;IACD;IAEA,OAAO;AACR;AAEA,SAAS,cAAc,IAAY;IAClC,MAAM,aAAa,KAAK,WAAW,GAAG,IAAI;IAC1C,OAAO,aAAa,CAAC,WAAW,IAAI;AACrC;AAEO,SAAS,gBAAgB,OAAe;IAC9C,MAAM,WAAqB,EAAE;IAE7B,8BAA8B;IAC9B,MAAM,cAAc;QACnB;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;KACA;IAED,2BAA2B;IAC3B,MAAM,kBAAkB;QAAC;QAAO;QAAO;QAAW;QAAa;QAAW;QAAU;KAAY;IAEhG,4BAA4B;IAC5B,MAAM,mBAAmB;QAAC;QAAY;QAAe;QAAc;QAAY;QAAS;QAAW;KAAW;IAE9G,MAAM,eAAe,QAAQ,WAAW;IAExC,KAAK,MAAM,MAAM;WAAI;WAAgB;WAAoB;KAAiB,CAAE;QAC3E,IAAI,aAAa,QAAQ,CAAC,KAAK;YAC9B,SAAS,IAAI,CAAC;QACf;IACD;IAEA,0EAA0E;IAC1E,MAAM,cAAc,QAAQ,KAAK,CAAC;IAClC,IAAI,aAAa;QAChB,SAAS,IAAI,IAAI,YAAY,KAAK,CAAC,GAAG,KAAI,yBAAyB;IACpE;IAEA,OAAO;WAAI,IAAI,IAAI;KAAU;AAC9B;AAEO,SAAS,iBAAiB,OAAe;IAC/C,MAAM,eAAe,QAAQ,WAAW;IAExC,mDAAmD;IACnD,IAAI,QAAQ,QAAQ,CAAC,OAAO,OAAO;IAEnC,sCAAsC;IACtC,IAAI,aAAa,QAAQ,CAAC,oBAAoB,OAAO;IACrD,IAAI,aAAa,QAAQ,CAAC,cAAc,OAAO;IAE/C,OAAO;AACR;AAEO,SAAS,aAAa,OAAe;IAC3C,MAAM,SAAS,wBAAwB;IACvC,OAAO,QAAQ;AAChB;AAEO,SAAS,gBAAgB,OAAe;IAC9C,mBAAmB;IACnB,SAAS;IACT,OAAO;IACP,UAAU;IACV,aAAa;IACb,MAAM,QAAQ,QAAQ,KAAK,CAAC;IAC5B,OAAO,QAAQ,SAAS,KAAK,CAAC,EAAE,EAAE,MAAM;AACzC;AAEO,SAAS,SAAS,OAAe;IACvC,MAAM,eAAe,QAAQ,WAAW;IACxC,OAAO,aAAa,UAAU,CAAC,aAAa,aAAa,QAAQ,CAAC,qBAAqB,aAAa,QAAQ,CAAC;AAC9G;AAEO,SAAS,eAAe,OAAe;IAC7C,oDAAoD;IACpD,MAAM,QAAQ,QAAQ,KAAK,CAAC;IAC5B,IAAI,OAAO,OAAO,KAAK,CAAC,EAAE;IAE1B,wBAAwB;IACxB,MAAM,cAAc,QAAQ,KAAK,CAAC;IAClC,IAAI,aAAa,OAAO,WAAW,CAAC,EAAE;IAEtC,OAAO;AACR"}},
    {"offset": {"line": 1685, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/git/blame.ts"],"sourcesContent":["import { execa } from \"execa\"\n\nexport interface BlameResult {\n\tsha: string\n\tauthor: string\n\tdate: Date\n\tlineNumber: number\n\tcontent: string\n}\n\nexport interface BlameRange {\n\tstartLine: number\n\tendLine: number\n\tsha: string\n\tauthor: string\n\tdate: Date\n}\n\nexport async function blameFile(\n\tfilePath: string,\n\toptions: {\n\t\tstartLine?: number\n\t\tendLine?: number\n\t\tref?: string\n\t\trepoPath?: string\n\t} = {},\n): Promise<BlameResult[]> {\n\tconst args = [\"blame\", \"--porcelain\"]\n\n\tif (options.startLine && options.endLine) {\n\t\targs.push(`-L${options.startLine},${options.endLine}`)\n\t}\n\n\tif (options.ref) {\n\t\targs.push(options.ref)\n\t}\n\n\targs.push(\"--\", filePath)\n\n\ttry {\n\t\tconst { stdout } = await execa(\"git\", args, {\n\t\t\tcwd: options.repoPath || process.cwd(),\n\t\t})\n\n\t\treturn parsePorcelainBlame(stdout)\n\t} catch {\n\t\t// File might not exist at this ref\n\t\treturn []\n\t}\n}\n\nfunction parsePorcelainBlame(output: string): BlameResult[] {\n\tconst results: BlameResult[] = []\n\tconst lines = output.split(\"\\n\")\n\n\tlet currentSha = \"\"\n\tlet currentAuthor = \"\"\n\tlet currentDate: Date | null = null\n\tlet currentLineNumber = 0\n\n\tfor (let i = 0; i < lines.length; i++) {\n\t\tconst line = lines[i]\n\n\t\t// SHA line: <sha> <orig-line> <final-line> [<count>]\n\t\tconst shaMatch = line.match(/^([a-f0-9]{40})\\s+(\\d+)\\s+(\\d+)/)\n\t\tif (shaMatch) {\n\t\t\tcurrentSha = shaMatch[1]\n\t\t\tcurrentLineNumber = parseInt(shaMatch[3], 10)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Author line\n\t\tif (line.startsWith(\"author \")) {\n\t\t\tcurrentAuthor = line.slice(7)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Author time\n\t\tif (line.startsWith(\"author-time \")) {\n\t\t\tconst timestamp = parseInt(line.slice(12), 10)\n\t\t\tcurrentDate = new Date(timestamp * 1000)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Content line (starts with tab)\n\t\tif (line.startsWith(\"\\t\")) {\n\t\t\tif (currentSha && currentDate) {\n\t\t\t\tresults.push({\n\t\t\t\t\tsha: currentSha,\n\t\t\t\t\tauthor: currentAuthor,\n\t\t\t\t\tdate: currentDate,\n\t\t\t\t\tlineNumber: currentLineNumber,\n\t\t\t\t\tcontent: line.slice(1),\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn results\n}\n\nexport async function blameFileRanges(\n\tfilePath: string,\n\toptions: {\n\t\tref?: string\n\t\trepoPath?: string\n\t} = {},\n): Promise<BlameRange[]> {\n\tconst results = await blameFile(filePath, options)\n\n\tif (results.length === 0) return []\n\n\t// Group consecutive lines by SHA\n\tconst ranges: BlameRange[] = []\n\tlet currentRange: BlameRange | null = null\n\n\tfor (const result of results) {\n\t\tif (!currentRange || currentRange.sha !== result.sha || currentRange.endLine !== result.lineNumber - 1) {\n\t\t\t// Start new range\n\t\t\tif (currentRange) {\n\t\t\t\tranges.push(currentRange)\n\t\t\t}\n\t\t\tcurrentRange = {\n\t\t\t\tstartLine: result.lineNumber,\n\t\t\t\tendLine: result.lineNumber,\n\t\t\t\tsha: result.sha,\n\t\t\t\tauthor: result.author,\n\t\t\t\tdate: result.date,\n\t\t\t}\n\t\t} else {\n\t\t\t// Extend current range\n\t\t\tcurrentRange.endLine = result.lineNumber\n\t\t}\n\t}\n\n\tif (currentRange) {\n\t\tranges.push(currentRange)\n\t}\n\n\treturn ranges\n}\n\nexport async function getCommitsForLines(\n\tfilePath: string,\n\tlines: number[],\n\toptions: {\n\t\tref?: string\n\t\trepoPath?: string\n\t} = {},\n): Promise<Map<number, string>> {\n\tif (lines.length === 0) return new Map()\n\n\tconst minLine = Math.min(...lines)\n\tconst maxLine = Math.max(...lines)\n\n\tconst blameResults = await blameFile(filePath, {\n\t\tstartLine: minLine,\n\t\tendLine: maxLine,\n\t\t...options,\n\t})\n\n\tconst lineToSha = new Map<number, string>()\n\tconst lineSet = new Set(lines)\n\n\tfor (const result of blameResults) {\n\t\tif (lineSet.has(result.lineNumber)) {\n\t\t\tlineToSha.set(result.lineNumber, result.sha)\n\t\t}\n\t}\n\n\treturn lineToSha\n}\n\nexport async function getUniqueBlameShas(\n\tfilePath: string,\n\toptions: {\n\t\tstartLine?: number\n\t\tendLine?: number\n\t\tref?: string\n\t\trepoPath?: string\n\t} = {},\n): Promise<string[]> {\n\tconst results = await blameFile(filePath, options)\n\tconst shas = new Set(results.map((r) => r.sha))\n\n\t// Filter out the \"not committed yet\" SHA\n\tshas.delete(\"0\".repeat(40))\n\n\treturn [...shas]\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;AAkBO,eAAe,UACrB,QAAgB,EAChB,UAKI,CAAC,CAAC;IAEN,MAAM,OAAO;QAAC;QAAS;KAAc;IAErC,IAAI,QAAQ,SAAS,IAAI,QAAQ,OAAO,EAAE;QACzC,KAAK,IAAI,CAAC,CAAC,EAAE,EAAE,QAAQ,SAAS,CAAC,CAAC,EAAE,QAAQ,OAAO,EAAE;IACtD;IAEA,IAAI,QAAQ,GAAG,EAAE;QAChB,KAAK,IAAI,CAAC,QAAQ,GAAG;IACtB;IAEA,KAAK,IAAI,CAAC,MAAM;IAEhB,IAAI;QACH,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,wNAAK,EAAC,OAAO,MAAM;YAC3C,KAAK,QAAQ,QAAQ,IAAI,QAAQ,GAAG;QACrC;QAEA,OAAO,oBAAoB;IAC5B,EAAE,OAAM;QACP,mCAAmC;QACnC,OAAO,EAAE;IACV;AACD;AAEA,SAAS,oBAAoB,MAAc;IAC1C,MAAM,UAAyB,EAAE;IACjC,MAAM,QAAQ,OAAO,KAAK,CAAC;IAE3B,IAAI,aAAa;IACjB,IAAI,gBAAgB;IACpB,IAAI,cAA2B;IAC/B,IAAI,oBAAoB;IAExB,IAAK,IAAI,IAAI,GAAG,IAAI,MAAM,MAAM,EAAE,IAAK;QACtC,MAAM,OAAO,KAAK,CAAC,EAAE;QAErB,qDAAqD;QACrD,MAAM,WAAW,KAAK,KAAK,CAAC;QAC5B,IAAI,UAAU;YACb,aAAa,QAAQ,CAAC,EAAE;YACxB,oBAAoB,SAAS,QAAQ,CAAC,EAAE,EAAE;YAC1C;QACD;QAEA,cAAc;QACd,IAAI,KAAK,UAAU,CAAC,YAAY;YAC/B,gBAAgB,KAAK,KAAK,CAAC;YAC3B;QACD;QAEA,cAAc;QACd,IAAI,KAAK,UAAU,CAAC,iBAAiB;YACpC,MAAM,YAAY,SAAS,KAAK,KAAK,CAAC,KAAK;YAC3C,cAAc,IAAI,KAAK,YAAY;YACnC;QACD;QAEA,iCAAiC;QACjC,IAAI,KAAK,UAAU,CAAC,OAAO;YAC1B,IAAI,cAAc,aAAa;gBAC9B,QAAQ,IAAI,CAAC;oBACZ,KAAK;oBACL,QAAQ;oBACR,MAAM;oBACN,YAAY;oBACZ,SAAS,KAAK,KAAK,CAAC;gBACrB;YACD;QACD;IACD;IAEA,OAAO;AACR;AAEO,eAAe,gBACrB,QAAgB,EAChB,UAGI,CAAC,CAAC;IAEN,MAAM,UAAU,MAAM,UAAU,UAAU;IAE1C,IAAI,QAAQ,MAAM,KAAK,GAAG,OAAO,EAAE;IAEnC,iCAAiC;IACjC,MAAM,SAAuB,EAAE;IAC/B,IAAI,eAAkC;IAEtC,KAAK,MAAM,UAAU,QAAS;QAC7B,IAAI,CAAC,gBAAgB,aAAa,GAAG,KAAK,OAAO,GAAG,IAAI,aAAa,OAAO,KAAK,OAAO,UAAU,GAAG,GAAG;YACvG,kBAAkB;YAClB,IAAI,cAAc;gBACjB,OAAO,IAAI,CAAC;YACb;YACA,eAAe;gBACd,WAAW,OAAO,UAAU;gBAC5B,SAAS,OAAO,UAAU;gBAC1B,KAAK,OAAO,GAAG;gBACf,QAAQ,OAAO,MAAM;gBACrB,MAAM,OAAO,IAAI;YAClB;QACD,OAAO;YACN,uBAAuB;YACvB,aAAa,OAAO,GAAG,OAAO,UAAU;QACzC;IACD;IAEA,IAAI,cAAc;QACjB,OAAO,IAAI,CAAC;IACb;IAEA,OAAO;AACR;AAEO,eAAe,mBACrB,QAAgB,EAChB,KAAe,EACf,UAGI,CAAC,CAAC;IAEN,IAAI,MAAM,MAAM,KAAK,GAAG,OAAO,IAAI;IAEnC,MAAM,UAAU,KAAK,GAAG,IAAI;IAC5B,MAAM,UAAU,KAAK,GAAG,IAAI;IAE5B,MAAM,eAAe,MAAM,UAAU,UAAU;QAC9C,WAAW;QACX,SAAS;QACT,GAAG,OAAO;IACX;IAEA,MAAM,YAAY,IAAI;IACtB,MAAM,UAAU,IAAI,IAAI;IAExB,KAAK,MAAM,UAAU,aAAc;QAClC,IAAI,QAAQ,GAAG,CAAC,OAAO,UAAU,GAAG;YACnC,UAAU,GAAG,CAAC,OAAO,UAAU,EAAE,OAAO,GAAG;QAC5C;IACD;IAEA,OAAO;AACR;AAEO,eAAe,mBACrB,QAAgB,EAChB,UAKI,CAAC,CAAC;IAEN,MAAM,UAAU,MAAM,UAAU,UAAU;IAC1C,MAAM,OAAO,IAAI,IAAI,QAAQ,GAAG,CAAC,CAAC,IAAM,EAAE,GAAG;IAE7C,yCAAyC;IACzC,KAAK,MAAM,CAAC,IAAI,MAAM,CAAC;IAEvB,OAAO;WAAI;KAAK;AACjB"}},
    {"offset": {"line": 1821, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/git/index.ts"],"sourcesContent":["export * from \"./extractor\"\nexport * from \"./parser\"\nexport * from \"./blame\"\n"],"names":[],"mappings":";AAAA;AACA;AACA"}},
    {"offset": {"line": 1832, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/classifiers/conventional.ts"],"sourcesContent":["import type { CommitCategory } from \"../db/schema\"\nimport type { ClassificationResult } from \"../types\"\nimport { parseConventionalCommit, isBreakingChange } from \"../git/parser\"\n\n// Map conventional commit types to categories\nconst TYPE_TO_CATEGORY: Record<string, CommitCategory> = {\n\tfix: \"bugfix\",\n\tfeat: \"feature\",\n\tdocs: \"documentation\",\n\tstyle: \"style\",\n\trefactor: \"refactor\",\n\tperf: \"performance\",\n\ttest: \"test\",\n\tbuild: \"build\",\n\tci: \"ci\",\n\tchore: \"chore\",\n\trevert: \"revert\",\n}\n\nexport function classifyByConventionalCommit(message: string): ClassificationResult | null {\n\tconst parsed = parseConventionalCommit(message)\n\n\tif (!parsed) {\n\t\treturn null\n\t}\n\n\tconst category = TYPE_TO_CATEGORY[parsed.type] || \"unknown\"\n\tconst flags: string[] = []\n\n\tif (parsed.breaking) {\n\t\tflags.push(\"breaking-change\")\n\t}\n\n\tif (parsed.scope) {\n\t\tflags.push(`scope:${parsed.scope}`)\n\t}\n\n\t// High confidence for well-formed conventional commits\n\tlet confidence = 0.9\n\n\t// Reduce confidence if type is not standard\n\tif (!TYPE_TO_CATEGORY[parsed.type]) {\n\t\tconfidence = 0.7\n\t}\n\n\treturn {\n\t\tcategory,\n\t\tconfidence,\n\t\tflags,\n\t\triskScore: 0, // Will be calculated separately\n\t}\n}\n\nexport function getMessageType(message: string): string | null {\n\tconst parsed = parseConventionalCommit(message)\n\treturn parsed?.type || null\n}\n\nexport function getMessageScope(message: string): string | null {\n\tconst parsed = parseConventionalCommit(message)\n\treturn parsed?.scope || null\n}\n"],"names":[],"mappings":";;;;;;;;AAEA;;AAEA,8CAA8C;AAC9C,MAAM,mBAAmD;IACxD,KAAK;IACL,MAAM;IACN,MAAM;IACN,OAAO;IACP,UAAU;IACV,MAAM;IACN,MAAM;IACN,OAAO;IACP,IAAI;IACJ,OAAO;IACP,QAAQ;AACT;AAEO,SAAS,6BAA6B,OAAe;IAC3D,MAAM,SAAS,IAAA,gMAAuB,EAAC;IAEvC,IAAI,CAAC,QAAQ;QACZ,OAAO;IACR;IAEA,MAAM,WAAW,gBAAgB,CAAC,OAAO,IAAI,CAAC,IAAI;IAClD,MAAM,QAAkB,EAAE;IAE1B,IAAI,OAAO,QAAQ,EAAE;QACpB,MAAM,IAAI,CAAC;IACZ;IAEA,IAAI,OAAO,KAAK,EAAE;QACjB,MAAM,IAAI,CAAC,CAAC,MAAM,EAAE,OAAO,KAAK,EAAE;IACnC;IAEA,uDAAuD;IACvD,IAAI,aAAa;IAEjB,4CAA4C;IAC5C,IAAI,CAAC,gBAAgB,CAAC,OAAO,IAAI,CAAC,EAAE;QACnC,aAAa;IACd;IAEA,OAAO;QACN;QACA;QACA;QACA,WAAW;IACZ;AACD;AAEO,SAAS,eAAe,OAAe;IAC7C,MAAM,SAAS,IAAA,gMAAuB,EAAC;IACvC,OAAO,QAAQ,QAAQ;AACxB;AAEO,SAAS,gBAAgB,OAAe;IAC9C,MAAM,SAAS,IAAA,gMAAuB,EAAC;IACvC,OAAO,QAAQ,SAAS;AACzB"}},
    {"offset": {"line": 1894, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/classifiers/semantic.ts"],"sourcesContent":["import type { CommitCategory } from \"../db/schema\"\nimport type { ClassificationResult } from \"../types\"\n\n// Semantic patterns for commit classification\ninterface SemanticPattern {\n\tkeywords: string[]\n\tcategory: CommitCategory\n\tweight: number\n}\n\nconst SEMANTIC_PATTERNS: SemanticPattern[] = [\n\t// Bug fix patterns (high weight)\n\t{\n\t\tkeywords: [\"fix\", \"bug\", \"issue\", \"error\", \"crash\", \"broken\", \"regression\", \"hotfix\"],\n\t\tcategory: \"bugfix\",\n\t\tweight: 0.9,\n\t},\n\t{\n\t\tkeywords: [\"correct\", \"resolve\", \"repair\", \"patch\", \"wrong\", \"incorrect\", \"missing\"],\n\t\tcategory: \"bugfix\",\n\t\tweight: 0.7,\n\t},\n\n\t// Feature patterns\n\t{\n\t\tkeywords: [\"add\", \"new\", \"feature\", \"implement\", \"introduce\", \"support\", \"enable\"],\n\t\tcategory: \"feature\",\n\t\tweight: 0.8,\n\t},\n\t{\n\t\tkeywords: [\"create\", \"allow\", \"provide\", \"extend\"],\n\t\tcategory: \"feature\",\n\t\tweight: 0.6,\n\t},\n\n\t// Refactor patterns\n\t{\n\t\tkeywords: [\"refactor\", \"restructure\", \"reorganize\", \"simplify\", \"clean\"],\n\t\tcategory: \"refactor\",\n\t\tweight: 0.85,\n\t},\n\t{\n\t\tkeywords: [\"rename\", \"move\", \"extract\", \"inline\", \"split\", \"merge\"],\n\t\tcategory: \"refactor\",\n\t\tweight: 0.7,\n\t},\n\n\t// Performance patterns\n\t{\n\t\tkeywords: [\"perf\", \"performance\", \"optimize\", \"speed\", \"fast\", \"slow\", \"cache\"],\n\t\tcategory: \"performance\",\n\t\tweight: 0.85,\n\t},\n\t{\n\t\tkeywords: [\"memory\", \"cpu\", \"efficient\", \"reduce\", \"improve performance\"],\n\t\tcategory: \"performance\",\n\t\tweight: 0.7,\n\t},\n\n\t// Documentation patterns\n\t{\n\t\tkeywords: [\"doc\", \"docs\", \"documentation\", \"readme\", \"comment\", \"jsdoc\", \"tsdoc\"],\n\t\tcategory: \"documentation\",\n\t\tweight: 0.9,\n\t},\n\n\t// Test patterns\n\t{\n\t\tkeywords: [\"test\", \"tests\", \"spec\", \"specs\", \"coverage\", \"unit test\", \"e2e\"],\n\t\tcategory: \"test\",\n\t\tweight: 0.9,\n\t},\n\n\t// Build patterns\n\t{\n\t\tkeywords: [\"build\", \"webpack\", \"vite\", \"esbuild\", \"bundle\", \"compile\"],\n\t\tcategory: \"build\",\n\t\tweight: 0.85,\n\t},\n\t{\n\t\tkeywords: [\"dependency\", \"dependencies\", \"package\", \"npm\", \"pnpm\", \"yarn\"],\n\t\tcategory: \"build\",\n\t\tweight: 0.7,\n\t},\n\n\t// CI patterns\n\t{\n\t\tkeywords: [\"ci\", \"cd\", \"pipeline\", \"workflow\", \"github actions\", \"jenkins\"],\n\t\tcategory: \"ci\",\n\t\tweight: 0.9,\n\t},\n\n\t// Style patterns\n\t{\n\t\tkeywords: [\"style\", \"format\", \"lint\", \"prettier\", \"eslint\", \"whitespace\"],\n\t\tcategory: \"style\",\n\t\tweight: 0.85,\n\t},\n\n\t// Revert patterns\n\t{\n\t\tkeywords: [\"revert\", \"rollback\", \"undo\"],\n\t\tcategory: \"revert\",\n\t\tweight: 0.95,\n\t},\n\n\t// Chore patterns\n\t{\n\t\tkeywords: [\"chore\", \"misc\", \"cleanup\", \"housekeeping\", \"maintenance\"],\n\t\tcategory: \"chore\",\n\t\tweight: 0.8,\n\t},\n\t{\n\t\tkeywords: [\"update\", \"upgrade\", \"bump\", \"version\"],\n\t\tcategory: \"chore\",\n\t\tweight: 0.5,\n\t},\n]\n\nexport function classifyBySemantic(message: string): ClassificationResult {\n\tconst lowerMessage = message.toLowerCase()\n\tconst scores: Record<CommitCategory, number> = {} as Record<CommitCategory, number>\n\n\t// Calculate scores for each category\n\tfor (const pattern of SEMANTIC_PATTERNS) {\n\t\tfor (const keyword of pattern.keywords) {\n\t\t\tif (lowerMessage.includes(keyword)) {\n\t\t\t\tconst currentScore = scores[pattern.category] || 0\n\t\t\t\tscores[pattern.category] = Math.max(currentScore, pattern.weight)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the highest scoring category\n\tlet bestCategory: CommitCategory = \"unknown\"\n\tlet bestScore = 0\n\n\tfor (const [category, score] of Object.entries(scores)) {\n\t\tif (score > bestScore) {\n\t\t\tbestScore = score\n\t\t\tbestCategory = category as CommitCategory\n\t\t}\n\t}\n\n\t// Extract matched keywords as flags\n\tconst flags: string[] = []\n\tfor (const pattern of SEMANTIC_PATTERNS) {\n\t\tif (pattern.category === bestCategory) {\n\t\t\tfor (const keyword of pattern.keywords) {\n\t\t\t\tif (lowerMessage.includes(keyword)) {\n\t\t\t\t\tflags.push(`keyword:${keyword}`)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Confidence is based on the score and number of matching keywords\n\tconst confidence = bestScore * Math.min(1, 0.5 + flags.length * 0.1)\n\n\treturn {\n\t\tcategory: bestCategory,\n\t\tconfidence: Math.min(confidence, 0.85), // Cap at 0.85 for semantic (lower than conventional)\n\t\tflags: flags.slice(0, 5), // Limit flags\n\t\triskScore: 0,\n\t}\n}\n\nexport function extractSemanticKeywords(message: string): string[] {\n\tconst lowerMessage = message.toLowerCase()\n\tconst keywords: string[] = []\n\n\tfor (const pattern of SEMANTIC_PATTERNS) {\n\t\tfor (const keyword of pattern.keywords) {\n\t\t\tif (lowerMessage.includes(keyword)) {\n\t\t\t\tkeywords.push(keyword)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn [...new Set(keywords)]\n}\n"],"names":[],"mappings":";;;;;;AAUA,MAAM,oBAAuC;IAC5C,iCAAiC;IACjC;QACC,UAAU;YAAC;YAAO;YAAO;YAAS;YAAS;YAAS;YAAU;YAAc;SAAS;QACrF,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAW;YAAW;YAAU;YAAS;YAAS;YAAa;SAAU;QACpF,UAAU;QACV,QAAQ;IACT;IAEA,mBAAmB;IACnB;QACC,UAAU;YAAC;YAAO;YAAO;YAAW;YAAa;YAAa;YAAW;SAAS;QAClF,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAU;YAAS;YAAW;SAAS;QAClD,UAAU;QACV,QAAQ;IACT;IAEA,oBAAoB;IACpB;QACC,UAAU;YAAC;YAAY;YAAe;YAAc;YAAY;SAAQ;QACxE,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAU;YAAQ;YAAW;YAAU;YAAS;SAAQ;QACnE,UAAU;QACV,QAAQ;IACT;IAEA,uBAAuB;IACvB;QACC,UAAU;YAAC;YAAQ;YAAe;YAAY;YAAS;YAAQ;YAAQ;SAAQ;QAC/E,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAU;YAAO;YAAa;YAAU;SAAsB;QACzE,UAAU;QACV,QAAQ;IACT;IAEA,yBAAyB;IACzB;QACC,UAAU;YAAC;YAAO;YAAQ;YAAiB;YAAU;YAAW;YAAS;SAAQ;QACjF,UAAU;QACV,QAAQ;IACT;IAEA,gBAAgB;IAChB;QACC,UAAU;YAAC;YAAQ;YAAS;YAAQ;YAAS;YAAY;YAAa;SAAM;QAC5E,UAAU;QACV,QAAQ;IACT;IAEA,iBAAiB;IACjB;QACC,UAAU;YAAC;YAAS;YAAW;YAAQ;YAAW;YAAU;SAAU;QACtE,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAc;YAAgB;YAAW;YAAO;YAAQ;SAAO;QAC1E,UAAU;QACV,QAAQ;IACT;IAEA,cAAc;IACd;QACC,UAAU;YAAC;YAAM;YAAM;YAAY;YAAY;YAAkB;SAAU;QAC3E,UAAU;QACV,QAAQ;IACT;IAEA,iBAAiB;IACjB;QACC,UAAU;YAAC;YAAS;YAAU;YAAQ;YAAY;YAAU;SAAa;QACzE,UAAU;QACV,QAAQ;IACT;IAEA,kBAAkB;IAClB;QACC,UAAU;YAAC;YAAU;YAAY;SAAO;QACxC,UAAU;QACV,QAAQ;IACT;IAEA,iBAAiB;IACjB;QACC,UAAU;YAAC;YAAS;YAAQ;YAAW;YAAgB;SAAc;QACrE,UAAU;QACV,QAAQ;IACT;IACA;QACC,UAAU;YAAC;YAAU;YAAW;YAAQ;SAAU;QAClD,UAAU;QACV,QAAQ;IACT;CACA;AAEM,SAAS,mBAAmB,OAAe;IACjD,MAAM,eAAe,QAAQ,WAAW;IACxC,MAAM,SAAyC,CAAC;IAEhD,qCAAqC;IACrC,KAAK,MAAM,WAAW,kBAAmB;QACxC,KAAK,MAAM,WAAW,QAAQ,QAAQ,CAAE;YACvC,IAAI,aAAa,QAAQ,CAAC,UAAU;gBACnC,MAAM,eAAe,MAAM,CAAC,QAAQ,QAAQ,CAAC,IAAI;gBACjD,MAAM,CAAC,QAAQ,QAAQ,CAAC,GAAG,KAAK,GAAG,CAAC,cAAc,QAAQ,MAAM;YACjE;QACD;IACD;IAEA,oCAAoC;IACpC,IAAI,eAA+B;IACnC,IAAI,YAAY;IAEhB,KAAK,MAAM,CAAC,UAAU,MAAM,IAAI,OAAO,OAAO,CAAC,QAAS;QACvD,IAAI,QAAQ,WAAW;YACtB,YAAY;YACZ,eAAe;QAChB;IACD;IAEA,oCAAoC;IACpC,MAAM,QAAkB,EAAE;IAC1B,KAAK,MAAM,WAAW,kBAAmB;QACxC,IAAI,QAAQ,QAAQ,KAAK,cAAc;YACtC,KAAK,MAAM,WAAW,QAAQ,QAAQ,CAAE;gBACvC,IAAI,aAAa,QAAQ,CAAC,UAAU;oBACnC,MAAM,IAAI,CAAC,CAAC,QAAQ,EAAE,SAAS;gBAChC;YACD;QACD;IACD;IAEA,mEAAmE;IACnE,MAAM,aAAa,YAAY,KAAK,GAAG,CAAC,GAAG,MAAM,MAAM,MAAM,GAAG;IAEhE,OAAO;QACN,UAAU;QACV,YAAY,KAAK,GAAG,CAAC,YAAY;QACjC,OAAO,MAAM,KAAK,CAAC,GAAG;QACtB,WAAW;IACZ;AACD;AAEO,SAAS,wBAAwB,OAAe;IACtD,MAAM,eAAe,QAAQ,WAAW;IACxC,MAAM,WAAqB,EAAE;IAE7B,KAAK,MAAM,WAAW,kBAAmB;QACxC,KAAK,MAAM,WAAW,QAAQ,QAAQ,CAAE;YACvC,IAAI,aAAa,QAAQ,CAAC,UAAU;gBACnC,SAAS,IAAI,CAAC;YACf;QACD;IACD;IAEA,OAAO;WAAI,IAAI,IAAI;KAAU;AAC9B"}},
    {"offset": {"line": 2173, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/classifiers/subsystem.ts"],"sourcesContent":["import type { Subsystem } from \"../types\"\n\n// File path patterns for subsystem detection\ninterface SubsystemPattern {\n\tpatterns: RegExp[]\n\tsubsystem: Subsystem\n}\n\nconst SUBSYSTEM_PATTERNS: SubsystemPattern[] = [\n\t// Provider patterns (API integrations)\n\t{\n\t\tpatterns: [\n\t\t\t/src\\/api\\/providers?\\//i,\n\t\t\t/providers?\\/.*\\.(ts|js)$/i,\n\t\t\t/anthropic|openai|gemini|bedrock|vertex|ollama|azure|openrouter/i,\n\t\t\t/src\\/core\\/.*provider/i,\n\t\t],\n\t\tsubsystem: \"provider\",\n\t},\n\n\t// Tool patterns (MCP, tool execution)\n\t{\n\t\tpatterns: [\n\t\t\t/src\\/services\\/mcp/i,\n\t\t\t/tools?\\//i,\n\t\t\t/tool[-_]?(use|call|result|block)/i,\n\t\t\t/mcp[-_]?(server|client|tool)/i,\n\t\t\t/execute[-_]?tool/i,\n\t\t],\n\t\tsubsystem: \"tool\",\n\t},\n\n\t// UI patterns\n\t{\n\t\tpatterns: [\n\t\t\t/webview[-_]?ui\\//i,\n\t\t\t/src\\/webviews?\\//i,\n\t\t\t/components?\\//i,\n\t\t\t/\\.tsx$/i,\n\t\t\t/\\.css$/i,\n\t\t\t/\\.scss$/i,\n\t\t\t/styles?\\//i,\n\t\t],\n\t\tsubsystem: \"ui\",\n\t},\n\n\t// API patterns (extension API, handlers)\n\t{\n\t\tpatterns: [/src\\/api\\//i, /handlers?\\//i, /api[-_]?client/i, /routes?\\//i],\n\t\tsubsystem: \"api\",\n\t},\n\n\t// Core patterns (main logic)\n\t{\n\t\tpatterns: [/src\\/core\\//i, /src\\/services?\\//i, /src\\/agent\\//i, /roo\\.ts$/i, /cline\\.ts$/i],\n\t\tsubsystem: \"core\",\n\t},\n\n\t// Test patterns\n\t{\n\t\tpatterns: [/\\.test\\.(ts|js|tsx|jsx)$/i, /\\.spec\\.(ts|js|tsx|jsx)$/i, /__tests__\\//i, /test\\//i, /tests\\//i],\n\t\tsubsystem: \"test\",\n\t},\n\n\t// Build patterns\n\t{\n\t\tpatterns: [\n\t\t\t/package\\.json$/i,\n\t\t\t/tsconfig.*\\.json$/i,\n\t\t\t/webpack/i,\n\t\t\t/vite/i,\n\t\t\t/esbuild/i,\n\t\t\t/rollup/i,\n\t\t\t/turbo\\.json$/i,\n\t\t\t/pnpm-workspace/i,\n\t\t],\n\t\tsubsystem: \"build\",\n\t},\n\n\t// Documentation patterns\n\t{\n\t\tpatterns: [/\\.md$/i, /readme/i, /changelog/i, /docs?\\//i, /documentation\\//i],\n\t\tsubsystem: \"docs\",\n\t},\n\n\t// Config patterns\n\t{\n\t\tpatterns: [\n\t\t\t/\\.config\\.(ts|js|mjs|cjs)$/i,\n\t\t\t/eslint/i,\n\t\t\t/prettier/i,\n\t\t\t/\\.env/i,\n\t\t\t/\\.gitignore$/i,\n\t\t\t/settings\\.json$/i,\n\t\t],\n\t\tsubsystem: \"config\",\n\t},\n]\n\nexport function detectSubsystem(filePath: string): Subsystem {\n\tfor (const { patterns, subsystem } of SUBSYSTEM_PATTERNS) {\n\t\tfor (const pattern of patterns) {\n\t\t\tif (pattern.test(filePath)) {\n\t\t\t\treturn subsystem\n\t\t\t}\n\t\t}\n\t}\n\n\treturn \"unknown\"\n}\n\nexport function detectSubsystems(filePaths: string[]): Map<Subsystem, number> {\n\tconst counts = new Map<Subsystem, number>()\n\n\tfor (const filePath of filePaths) {\n\t\tconst subsystem = detectSubsystem(filePath)\n\t\tcounts.set(subsystem, (counts.get(subsystem) || 0) + 1)\n\t}\n\n\treturn counts\n}\n\nexport function getPrimarySubsystem(filePaths: string[]): Subsystem {\n\tconst counts = detectSubsystems(filePaths)\n\n\tlet maxCount = 0\n\tlet primary: Subsystem = \"unknown\"\n\n\tfor (const [subsystem, count] of counts) {\n\t\tif (count > maxCount) {\n\t\t\tmaxCount = count\n\t\t\tprimary = subsystem\n\t\t}\n\t}\n\n\treturn primary\n}\n\nexport function getSubsystemsAffected(filePaths: string[]): Subsystem[] {\n\tconst subsystems = new Set<Subsystem>()\n\n\tfor (const filePath of filePaths) {\n\t\tsubsystems.add(detectSubsystem(filePath))\n\t}\n\n\treturn [...subsystems].filter((s) => s !== \"unknown\")\n}\n\n// Critical paths that indicate higher risk\nconst CRITICAL_PATHS = [\n\t/src\\/core\\/.*\\.(ts|js)$/i,\n\t/src\\/api\\/providers?\\//i,\n\t/src\\/services\\/mcp/i,\n\t/src\\/agent\\//i,\n\t/package\\.json$/i,\n]\n\nexport function touchesCriticalPath(filePaths: string[]): boolean {\n\tfor (const filePath of filePaths) {\n\t\tfor (const pattern of CRITICAL_PATHS) {\n\t\t\tif (pattern.test(filePath)) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n\nexport function hasTestFiles(filePaths: string[]): boolean {\n\treturn filePaths.some(\n\t\t(fp) =>\n\t\t\tfp.includes(\".test.\") ||\n\t\t\tfp.includes(\".spec.\") ||\n\t\t\tfp.includes(\"__tests__\") ||\n\t\t\tfp.includes(\"/test/\") ||\n\t\t\tfp.includes(\"/tests/\"),\n\t)\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAQA,MAAM,qBAAyC;IAC9C,uCAAuC;IACvC;QACC,UAAU;YACT;YACA;YACA;YACA;SACA;QACD,WAAW;IACZ;IAEA,sCAAsC;IACtC;QACC,UAAU;YACT;YACA;YACA;YACA;YACA;SACA;QACD,WAAW;IACZ;IAEA,cAAc;IACd;QACC,UAAU;YACT;YACA;YACA;YACA;YACA;YACA;YACA;SACA;QACD,WAAW;IACZ;IAEA,yCAAyC;IACzC;QACC,UAAU;YAAC;YAAe;YAAgB;YAAmB;SAAa;QAC1E,WAAW;IACZ;IAEA,6BAA6B;IAC7B;QACC,UAAU;YAAC;YAAgB;YAAqB;YAAiB;YAAa;SAAc;QAC5F,WAAW;IACZ;IAEA,gBAAgB;IAChB;QACC,UAAU;YAAC;YAA6B;YAA6B;YAAgB;YAAW;SAAW;QAC3G,WAAW;IACZ;IAEA,iBAAiB;IACjB;QACC,UAAU;YACT;YACA;YACA;YACA;YACA;YACA;YACA;YACA;SACA;QACD,WAAW;IACZ;IAEA,yBAAyB;IACzB;QACC,UAAU;YAAC;YAAU;YAAW;YAAc;YAAY;SAAmB;QAC7E,WAAW;IACZ;IAEA,kBAAkB;IAClB;QACC,UAAU;YACT;YACA;YACA;YACA;YACA;YACA;SACA;QACD,WAAW;IACZ;CACA;AAEM,SAAS,gBAAgB,QAAgB;IAC/C,KAAK,MAAM,EAAE,QAAQ,EAAE,SAAS,EAAE,IAAI,mBAAoB;QACzD,KAAK,MAAM,WAAW,SAAU;YAC/B,IAAI,QAAQ,IAAI,CAAC,WAAW;gBAC3B,OAAO;YACR;QACD;IACD;IAEA,OAAO;AACR;AAEO,SAAS,iBAAiB,SAAmB;IACnD,MAAM,SAAS,IAAI;IAEnB,KAAK,MAAM,YAAY,UAAW;QACjC,MAAM,YAAY,gBAAgB;QAClC,OAAO,GAAG,CAAC,WAAW,CAAC,OAAO,GAAG,CAAC,cAAc,CAAC,IAAI;IACtD;IAEA,OAAO;AACR;AAEO,SAAS,oBAAoB,SAAmB;IACtD,MAAM,SAAS,iBAAiB;IAEhC,IAAI,WAAW;IACf,IAAI,UAAqB;IAEzB,KAAK,MAAM,CAAC,WAAW,MAAM,IAAI,OAAQ;QACxC,IAAI,QAAQ,UAAU;YACrB,WAAW;YACX,UAAU;QACX;IACD;IAEA,OAAO;AACR;AAEO,SAAS,sBAAsB,SAAmB;IACxD,MAAM,aAAa,IAAI;IAEvB,KAAK,MAAM,YAAY,UAAW;QACjC,WAAW,GAAG,CAAC,gBAAgB;IAChC;IAEA,OAAO;WAAI;KAAW,CAAC,MAAM,CAAC,CAAC,IAAM,MAAM;AAC5C;AAEA,2CAA2C;AAC3C,MAAM,iBAAiB;IACtB;IACA;IACA;IACA;IACA;CACA;AAEM,SAAS,oBAAoB,SAAmB;IACtD,KAAK,MAAM,YAAY,UAAW;QACjC,KAAK,MAAM,WAAW,eAAgB;YACrC,IAAI,QAAQ,IAAI,CAAC,WAAW;gBAC3B,OAAO;YACR;QACD;IACD;IACA,OAAO;AACR;AAEO,SAAS,aAAa,SAAmB;IAC/C,OAAO,UAAU,IAAI,CACpB,CAAC,KACA,GAAG,QAAQ,CAAC,aACZ,GAAG,QAAQ,CAAC,aACZ,GAAG,QAAQ,CAAC,gBACZ,GAAG,QAAQ,CAAC,aACZ,GAAG,QAAQ,CAAC;AAEf"}},
    {"offset": {"line": 2356, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/classifiers/index.ts"],"sourcesContent":["export * from \"./conventional\"\nexport * from \"./semantic\"\nexport * from \"./subsystem\"\n"],"names":[],"mappings":";AAAA;AACA;AACA"}},
    {"offset": {"line": 2367, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/causality/blame-method.ts"],"sourcesContent":["import type { CausalityResult } from \"../types\"\nimport type { Commit } from \"../db/schema\"\nimport { getDb } from \"../db/db\"\nimport { blameFileRanges, getUniqueBlameShas } from \"../git/blame\"\nimport { extractFileChanges } from \"../git/extractor\"\nimport { getCommit } from \"../db/queries/commits\"\n\nexport async function analyzeByBlame(\n\tbugFix: Commit,\n\tmaxAgeDays: number,\n\trepoPath?: string,\n): Promise<CausalityResult[]> {\n\tconst results: CausalityResult[] = []\n\tconst db = getDb()\n\n\t// Get file changes for this bug fix\n\tconst fileChanges = await extractFileChanges(bugFix.sha, repoPath)\n\n\tif (fileChanges.length === 0) {\n\t\treturn results\n\t}\n\n\t// Get the parent commit SHA to blame against\n\tconst parentRef = `${bugFix.sha}^`\n\n\t// Collect all commits that touched the fixed files\n\tconst blameShas = new Set<string>()\n\n\tfor (const change of fileChanges) {\n\t\t// Skip deleted files (can't blame them)\n\t\tif (change.changeType === \"D\") continue\n\n\t\t// Skip new files (nothing to blame)\n\t\tif (change.changeType === \"A\") continue\n\n\t\ttry {\n\t\t\tconst shas = await getUniqueBlameShas(change.filePath, {\n\t\t\t\tref: parentRef,\n\t\t\t\trepoPath,\n\t\t\t})\n\n\t\t\tfor (const sha of shas) {\n\t\t\t\t// Skip the bug fix commit itself\n\t\t\t\tif (sha !== bugFix.sha) {\n\t\t\t\t\tblameShas.add(sha)\n\t\t\t\t}\n\t\t\t}\n\t\t} catch {\n\t\t\t// File might not exist at parent ref\n\t\t\tcontinue\n\t\t}\n\t}\n\n\t// Score each blamed commit\n\tconst cutoffDate = new Date(bugFix.date.getTime() - maxAgeDays * 24 * 60 * 60 * 1000)\n\n\tfor (const sha of blameShas) {\n\t\tconst causeCommit = await getCommit(sha, db)\n\n\t\tif (!causeCommit) continue\n\n\t\t// Skip commits outside our time window\n\t\tif (causeCommit.date < cutoffDate) continue\n\n\t\t// Calculate confidence based on various factors\n\t\tlet confidence = 0.6 // Base confidence for blame\n\n\t\t// Higher confidence if same author\n\t\tif (causeCommit.authorEmail === bugFix.authorEmail) {\n\t\t\tconfidence += 0.1\n\t\t}\n\n\t\t// Higher confidence if recent commit\n\t\tconst ageInDays = (bugFix.date.getTime() - causeCommit.date.getTime()) / (24 * 60 * 60 * 1000)\n\t\tif (ageInDays < 7) {\n\t\t\tconfidence += 0.15\n\t\t} else if (ageInDays < 30) {\n\t\t\tconfidence += 0.05\n\t\t}\n\n\t\t// Calculate bug age\n\t\tconst bugAge = Math.floor(ageInDays)\n\n\t\tresults.push({\n\t\t\tcauseSha: sha,\n\t\t\trelationshipType: confidence >= 0.7 ? \"root_cause\" : \"related_to\",\n\t\t\tconfidence: Math.min(confidence, 0.85),\n\t\t\tbugAge,\n\t\t\tanalysisMethod: \"blame\",\n\t\t\tnotes: `Blamed commit touched ${fileChanges.length} file(s)`,\n\t\t})\n\t}\n\n\t// Sort by confidence and return top results\n\treturn results.sort((a, b) => b.confidence - a.confidence).slice(0, 5)\n}\n"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AACA;;;;;AAEO,eAAe,eACrB,MAAc,EACd,UAAkB,EAClB,QAAiB;IAEjB,MAAM,UAA6B,EAAE;IACrC,MAAM,KAAK,IAAA,yKAAK;IAEhB,oCAAoC;IACpC,MAAM,cAAc,MAAM,IAAA,8LAAkB,EAAC,OAAO,GAAG,EAAE;IAEzD,IAAI,YAAY,MAAM,KAAK,GAAG;QAC7B,OAAO;IACR;IAEA,6CAA6C;IAC7C,MAAM,YAAY,GAAG,OAAO,GAAG,CAAC,CAAC,CAAC;IAElC,mDAAmD;IACnD,MAAM,YAAY,IAAI;IAEtB,KAAK,MAAM,UAAU,YAAa;QACjC,wCAAwC;QACxC,IAAI,OAAO,UAAU,KAAK,KAAK;QAE/B,oCAAoC;QACpC,IAAI,OAAO,UAAU,KAAK,KAAK;QAE/B,IAAI;YACH,MAAM,OAAO,MAAM,IAAA,0LAAkB,EAAC,OAAO,QAAQ,EAAE;gBACtD,KAAK;gBACL;YACD;YAEA,KAAK,MAAM,OAAO,KAAM;gBACvB,iCAAiC;gBACjC,IAAI,QAAQ,OAAO,GAAG,EAAE;oBACvB,UAAU,GAAG,CAAC;gBACf;YACD;QACD,EAAE,OAAM;YAEP;QACD;IACD;IAEA,2BAA2B;IAC3B,MAAM,aAAa,IAAI,KAAK,OAAO,IAAI,CAAC,OAAO,KAAK,aAAa,KAAK,KAAK,KAAK;IAEhF,KAAK,MAAM,OAAO,UAAW;QAC5B,MAAM,cAAc,MAAM,IAAA,6LAAS,EAAC,KAAK;QAEzC,IAAI,CAAC,aAAa;QAElB,uCAAuC;QACvC,IAAI,YAAY,IAAI,GAAG,YAAY;QAEnC,gDAAgD;QAChD,IAAI,aAAa,IAAI,4BAA4B;;QAEjD,mCAAmC;QACnC,IAAI,YAAY,WAAW,KAAK,OAAO,WAAW,EAAE;YACnD,cAAc;QACf;QAEA,qCAAqC;QACrC,MAAM,YAAY,CAAC,OAAO,IAAI,CAAC,OAAO,KAAK,YAAY,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,KAAK,KAAK,KAAK,IAAI;QAC7F,IAAI,YAAY,GAAG;YAClB,cAAc;QACf,OAAO,IAAI,YAAY,IAAI;YAC1B,cAAc;QACf;QAEA,oBAAoB;QACpB,MAAM,SAAS,KAAK,KAAK,CAAC;QAE1B,QAAQ,IAAI,CAAC;YACZ,UAAU;YACV,kBAAkB,cAAc,MAAM,eAAe;YACrD,YAAY,KAAK,GAAG,CAAC,YAAY;YACjC;YACA,gBAAgB;YAChB,OAAO,CAAC,sBAAsB,EAAE,YAAY,MAAM,CAAC,QAAQ,CAAC;QAC7D;IACD;IAEA,4CAA4C;IAC5C,OAAO,QAAQ,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,UAAU,GAAG,EAAE,UAAU,EAAE,KAAK,CAAC,GAAG;AACrE"}},
    {"offset": {"line": 2450, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/causality/semantic-method.ts"],"sourcesContent":["import type { CausalityResult } from \"../types\"\nimport type { Commit } from \"../db/schema\"\nimport { getDb } from \"../db/db\"\nimport { commits } from \"../db/schema\"\nimport { and, lt, gt, desc } from \"drizzle-orm\"\nimport { extractKeywords } from \"../git/parser\"\nimport { extractSemanticKeywords } from \"../classifiers/semantic\"\nimport { detectSubsystem } from \"../classifiers/subsystem\"\n\nexport async function analyzeBySemantic(bugFix: Commit, maxAgeDays: number): Promise<CausalityResult[]> {\n\tconst results: CausalityResult[] = []\n\tconst db = getDb()\n\n\t// Extract keywords from the bug fix message\n\tconst fixKeywords = new Set([\n\t\t...extractKeywords(bugFix.message),\n\t\t...extractSemanticKeywords(bugFix.message),\n\t])\n\n\tif (fixKeywords.size === 0) {\n\t\treturn results\n\t}\n\n\t// Get recent commits within the time window\n\tconst cutoffDate = new Date(bugFix.date.getTime() - maxAgeDays * 24 * 60 * 60 * 1000)\n\n\tconst recentCommits = await db.query.commits.findMany({\n\t\twhere: and(lt(commits.date, bugFix.date), gt(commits.date, cutoffDate)),\n\t\torderBy: desc(commits.date),\n\t\tlimit: 200, // Limit to prevent scanning too many commits\n\t\twith: {\n\t\t\tfileChanges: true,\n\t\t},\n\t})\n\n\tfor (const candidate of recentCommits) {\n\t\t// Skip the same commit\n\t\tif (candidate.sha === bugFix.sha) continue\n\n\t\t// Extract keywords from candidate\n\t\tconst candidateKeywords = new Set([\n\t\t\t...extractKeywords(candidate.message),\n\t\t\t...extractSemanticKeywords(candidate.message),\n\t\t])\n\n\t\t// Calculate keyword overlap\n\t\tconst intersection = new Set([...fixKeywords].filter((k) => candidateKeywords.has(k)))\n\t\tconst union = new Set([...fixKeywords, ...candidateKeywords])\n\n\t\tif (intersection.size === 0) continue\n\n\t\t// Jaccard similarity\n\t\tconst similarity = intersection.size / union.size\n\n\t\t// Check subsystem overlap\n\t\tlet subsystemMatch = false\n\t\tif (candidate.fileChanges && candidate.fileChanges.length > 0) {\n\t\t\tconst candidateSubsystems = new Set(candidate.fileChanges.map((fc) => fc.subsystem))\n\t\t\t// Get fix subsystem from scope if available\n\t\t\tif (bugFix.messageScope && candidateSubsystems.has(bugFix.messageScope)) {\n\t\t\t\tsubsystemMatch = true\n\t\t\t}\n\t\t}\n\n\t\t// Calculate confidence\n\t\tlet confidence = similarity * 0.5 // Base from keyword similarity\n\n\t\tif (subsystemMatch) {\n\t\t\tconfidence += 0.15\n\t\t}\n\n\t\t// Boost for same scope\n\t\tif (bugFix.messageScope && candidate.messageScope === bugFix.messageScope) {\n\t\t\tconfidence += 0.1\n\t\t}\n\n\t\t// Only include if confidence is meaningful\n\t\tif (confidence < 0.3) continue\n\n\t\tconst ageInDays = (bugFix.date.getTime() - candidate.date.getTime()) / (24 * 60 * 60 * 1000)\n\n\t\tresults.push({\n\t\t\tcauseSha: candidate.sha,\n\t\t\trelationshipType: \"related_to\", // Semantic is lower confidence\n\t\t\tconfidence: Math.min(confidence, 0.65),\n\t\t\tbugAge: Math.floor(ageInDays),\n\t\t\tanalysisMethod: \"semantic\",\n\t\t\tnotes: `Matched keywords: ${[...intersection].slice(0, 5).join(\", \")}`,\n\t\t})\n\t}\n\n\treturn results.sort((a, b) => b.confidence - a.confidence).slice(0, 5)\n}\n"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AAAA;AACA;AACA;;;;;;AAGO,eAAe,kBAAkB,MAAc,EAAE,UAAkB;IACzE,MAAM,UAA6B,EAAE;IACrC,MAAM,KAAK,IAAA,yKAAK;IAEhB,4CAA4C;IAC5C,MAAM,cAAc,IAAI,IAAI;WACxB,IAAA,wLAAe,EAAC,OAAO,OAAO;WAC9B,IAAA,0MAAuB,EAAC,OAAO,OAAO;KACzC;IAED,IAAI,YAAY,IAAI,KAAK,GAAG;QAC3B,OAAO;IACR;IAEA,4CAA4C;IAC5C,MAAM,aAAa,IAAI,KAAK,OAAO,IAAI,CAAC,OAAO,KAAK,aAAa,KAAK,KAAK,KAAK;IAEhF,MAAM,gBAAgB,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC;QACrD,OAAO,IAAA,iYAAG,EAAC,IAAA,gYAAE,EAAC,+KAAO,CAAC,IAAI,EAAE,OAAO,IAAI,GAAG,IAAA,gYAAE,EAAC,+KAAO,CAAC,IAAI,EAAE;QAC3D,SAAS,IAAA,8XAAI,EAAC,+KAAO,CAAC,IAAI;QAC1B,OAAO;QACP,MAAM;YACL,aAAa;QACd;IACD;IAEA,KAAK,MAAM,aAAa,cAAe;QACtC,uBAAuB;QACvB,IAAI,UAAU,GAAG,KAAK,OAAO,GAAG,EAAE;QAElC,kCAAkC;QAClC,MAAM,oBAAoB,IAAI,IAAI;eAC9B,IAAA,wLAAe,EAAC,UAAU,OAAO;eACjC,IAAA,0MAAuB,EAAC,UAAU,OAAO;SAC5C;QAED,4BAA4B;QAC5B,MAAM,eAAe,IAAI,IAAI;eAAI;SAAY,CAAC,MAAM,CAAC,CAAC,IAAM,kBAAkB,GAAG,CAAC;QAClF,MAAM,QAAQ,IAAI,IAAI;eAAI;eAAgB;SAAkB;QAE5D,IAAI,aAAa,IAAI,KAAK,GAAG;QAE7B,qBAAqB;QACrB,MAAM,aAAa,aAAa,IAAI,GAAG,MAAM,IAAI;QAEjD,0BAA0B;QAC1B,IAAI,iBAAiB;QACrB,IAAI,UAAU,WAAW,IAAI,UAAU,WAAW,CAAC,MAAM,GAAG,GAAG;YAC9D,MAAM,sBAAsB,IAAI,IAAI,UAAU,WAAW,CAAC,GAAG,CAAC,CAAC,KAAO,GAAG,SAAS;YAClF,4CAA4C;YAC5C,IAAI,OAAO,YAAY,IAAI,oBAAoB,GAAG,CAAC,OAAO,YAAY,GAAG;gBACxE,iBAAiB;YAClB;QACD;QAEA,uBAAuB;QACvB,IAAI,aAAa,aAAa,IAAI,+BAA+B;;QAEjE,IAAI,gBAAgB;YACnB,cAAc;QACf;QAEA,uBAAuB;QACvB,IAAI,OAAO,YAAY,IAAI,UAAU,YAAY,KAAK,OAAO,YAAY,EAAE;YAC1E,cAAc;QACf;QAEA,2CAA2C;QAC3C,IAAI,aAAa,KAAK;QAEtB,MAAM,YAAY,CAAC,OAAO,IAAI,CAAC,OAAO,KAAK,UAAU,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,KAAK,KAAK,KAAK,IAAI;QAE3F,QAAQ,IAAI,CAAC;YACZ,UAAU,UAAU,GAAG;YACvB,kBAAkB;YAClB,YAAY,KAAK,GAAG,CAAC,YAAY;YACjC,QAAQ,KAAK,KAAK,CAAC;YACnB,gBAAgB;YAChB,OAAO,CAAC,kBAAkB,EAAE;mBAAI;aAAa,CAAC,KAAK,CAAC,GAAG,GAAG,IAAI,CAAC,OAAO;QACvE;IACD;IAEA,OAAO,QAAQ,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,UAAU,GAAG,EAAE,UAAU,EAAE,KAAK,CAAC,GAAG;AACrE"}},
    {"offset": {"line": 2544, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/causality/temporal-method.ts"],"sourcesContent":["import type { CausalityResult } from \"../types\"\nimport type { Commit } from \"../db/schema\"\nimport { getDb } from \"../db/db\"\nimport { commits, fileChanges } from \"../db/schema\"\nimport { and, lt, gt, desc, eq, inArray } from \"drizzle-orm\"\n\n// Time windows for temporal analysis\nconst TIME_WINDOWS = {\n\timmediate: 24, // hours - very suspicious\n\trecent: 72, // hours - suspicious\n\tmoderate: 168, // hours (1 week) - possible\n}\n\nexport async function analyzeByTemporal(bugFix: Commit, maxAgeDays: number): Promise<CausalityResult[]> {\n\tconst results: CausalityResult[] = []\n\tconst db = getDb()\n\n\t// Get files changed in the bug fix\n\tconst fixFileChanges = await db.query.fileChanges.findMany({\n\t\twhere: eq(fileChanges.commitSha, bugFix.sha),\n\t})\n\n\tif (fixFileChanges.length === 0) {\n\t\treturn results\n\t}\n\n\tconst fixFilePaths = fixFileChanges.map((fc) => fc.filePath)\n\n\t// Look for commits that touched the same files within the time window\n\tconst cutoffDate = new Date(bugFix.date.getTime() - maxAgeDays * 24 * 60 * 60 * 1000)\n\n\t// Find commits that touched the same files\n\tconst relatedFileChanges = await db.query.fileChanges.findMany({\n\t\twhere: and(inArray(fileChanges.filePath, fixFilePaths)),\n\t\twith: {\n\t\t\tcommit: true,\n\t\t},\n\t})\n\n\t// Group by commit\n\tconst commitMap = new Map<string, { commit: Commit; fileOverlap: number }>()\n\n\tfor (const fc of relatedFileChanges) {\n\t\tif (!fc.commit) continue\n\t\tif (fc.commit.sha === bugFix.sha) continue\n\t\tif (fc.commit.date >= bugFix.date) continue\n\t\tif (fc.commit.date < cutoffDate) continue\n\n\t\tconst existing = commitMap.get(fc.commit.sha)\n\t\tif (existing) {\n\t\t\texisting.fileOverlap++\n\t\t} else {\n\t\t\tcommitMap.set(fc.commit.sha, { commit: fc.commit, fileOverlap: 1 })\n\t\t}\n\t}\n\n\tfor (const [sha, { commit, fileOverlap }] of commitMap) {\n\t\tconst ageInHours = (bugFix.date.getTime() - commit.date.getTime()) / (60 * 60 * 1000)\n\t\tconst ageInDays = ageInHours / 24\n\n\t\t// Calculate confidence based on temporal proximity\n\t\tlet confidence = 0.3 // Base confidence\n\n\t\tif (ageInHours <= TIME_WINDOWS.immediate) {\n\t\t\tconfidence += 0.25\n\t\t} else if (ageInHours <= TIME_WINDOWS.recent) {\n\t\t\tconfidence += 0.15\n\t\t} else if (ageInHours <= TIME_WINDOWS.moderate) {\n\t\t\tconfidence += 0.05\n\t\t}\n\n\t\t// Boost for file overlap\n\t\tconst overlapRatio = fileOverlap / fixFilePaths.length\n\t\tconfidence += overlapRatio * 0.2\n\n\t\t// Boost for same author (might be fixing own bug)\n\t\tif (commit.authorEmail === bugFix.authorEmail) {\n\t\t\tconfidence += 0.1\n\t\t}\n\n\t\t// Skip low confidence results\n\t\tif (confidence < 0.35) continue\n\n\t\tresults.push({\n\t\t\tcauseSha: sha,\n\t\t\trelationshipType: \"related_to\",\n\t\t\tconfidence: Math.min(confidence, 0.55), // Cap temporal confidence\n\t\t\tbugAge: Math.floor(ageInDays),\n\t\t\tanalysisMethod: \"temporal\",\n\t\t\tnotes: `${fileOverlap} file(s) overlap, ${Math.floor(ageInHours)}h before fix`,\n\t\t})\n\t}\n\n\treturn results.sort((a, b) => b.confidence - a.confidence).slice(0, 5)\n}\n"],"names":[],"mappings":";;;;AAEA;AACA;AACA;;;;AAEA,qCAAqC;AACrC,MAAM,eAAe;IACpB,WAAW;IACX,QAAQ;IACR,UAAU;AACX;AAEO,eAAe,kBAAkB,MAAc,EAAE,UAAkB;IACzE,MAAM,UAA6B,EAAE;IACrC,MAAM,KAAK,IAAA,yKAAK;IAEhB,mCAAmC;IACnC,MAAM,iBAAiB,MAAM,GAAG,KAAK,CAAC,WAAW,CAAC,QAAQ,CAAC;QAC1D,OAAO,IAAA,gYAAE,EAAC,mLAAW,CAAC,SAAS,EAAE,OAAO,GAAG;IAC5C;IAEA,IAAI,eAAe,MAAM,KAAK,GAAG;QAChC,OAAO;IACR;IAEA,MAAM,eAAe,eAAe,GAAG,CAAC,CAAC,KAAO,GAAG,QAAQ;IAE3D,sEAAsE;IACtE,MAAM,aAAa,IAAI,KAAK,OAAO,IAAI,CAAC,OAAO,KAAK,aAAa,KAAK,KAAK,KAAK;IAEhF,2CAA2C;IAC3C,MAAM,qBAAqB,MAAM,GAAG,KAAK,CAAC,WAAW,CAAC,QAAQ,CAAC;QAC9D,OAAO,IAAA,iYAAG,EAAC,IAAA,qYAAO,EAAC,mLAAW,CAAC,QAAQ,EAAE;QACzC,MAAM;YACL,QAAQ;QACT;IACD;IAEA,kBAAkB;IAClB,MAAM,YAAY,IAAI;IAEtB,KAAK,MAAM,MAAM,mBAAoB;QACpC,IAAI,CAAC,GAAG,MAAM,EAAE;QAChB,IAAI,GAAG,MAAM,CAAC,GAAG,KAAK,OAAO,GAAG,EAAE;QAClC,IAAI,GAAG,MAAM,CAAC,IAAI,IAAI,OAAO,IAAI,EAAE;QACnC,IAAI,GAAG,MAAM,CAAC,IAAI,GAAG,YAAY;QAEjC,MAAM,WAAW,UAAU,GAAG,CAAC,GAAG,MAAM,CAAC,GAAG;QAC5C,IAAI,UAAU;YACb,SAAS,WAAW;QACrB,OAAO;YACN,UAAU,GAAG,CAAC,GAAG,MAAM,CAAC,GAAG,EAAE;gBAAE,QAAQ,GAAG,MAAM;gBAAE,aAAa;YAAE;QAClE;IACD;IAEA,KAAK,MAAM,CAAC,KAAK,EAAE,MAAM,EAAE,WAAW,EAAE,CAAC,IAAI,UAAW;QACvD,MAAM,aAAa,CAAC,OAAO,IAAI,CAAC,OAAO,KAAK,OAAO,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,KAAK,KAAK,IAAI;QACpF,MAAM,YAAY,aAAa;QAE/B,mDAAmD;QACnD,IAAI,aAAa,IAAI,kBAAkB;;QAEvC,IAAI,cAAc,aAAa,SAAS,EAAE;YACzC,cAAc;QACf,OAAO,IAAI,cAAc,aAAa,MAAM,EAAE;YAC7C,cAAc;QACf,OAAO,IAAI,cAAc,aAAa,QAAQ,EAAE;YAC/C,cAAc;QACf;QAEA,yBAAyB;QACzB,MAAM,eAAe,cAAc,aAAa,MAAM;QACtD,cAAc,eAAe;QAE7B,kDAAkD;QAClD,IAAI,OAAO,WAAW,KAAK,OAAO,WAAW,EAAE;YAC9C,cAAc;QACf;QAEA,8BAA8B;QAC9B,IAAI,aAAa,MAAM;QAEvB,QAAQ,IAAI,CAAC;YACZ,UAAU;YACV,kBAAkB;YAClB,YAAY,KAAK,GAAG,CAAC,YAAY;YACjC,QAAQ,KAAK,KAAK,CAAC;YACnB,gBAAgB;YAChB,OAAO,GAAG,YAAY,kBAAkB,EAAE,KAAK,KAAK,CAAC,YAAY,YAAY,CAAC;QAC/E;IACD;IAEA,OAAO,QAAQ,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,UAAU,GAAG,EAAE,UAAU,EAAE,KAAK,CAAC,GAAG;AACrE"}},
    {"offset": {"line": 2634, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/causality/analyzer.ts"],"sourcesContent":["import type { CausalityResult, AnalysisMethod, DeepAnalysisConfig } from \"../types\"\nimport type { Commit } from \"../db/schema\"\nimport { analyzeByBlame } from \"./blame-method\"\nimport { analyzeBySemantic } from \"./semantic-method\"\nimport { analyzeByTemporal } from \"./temporal-method\"\nimport { getRevertedSha, isRevert } from \"../git/parser\"\nimport { getCommit } from \"../db/queries/commits\"\n\nconst DEFAULT_CONFIG: DeepAnalysisConfig = {\n\tbatchSize: 50,\n\tconcurrency: 4,\n\tmethods: [\"explicit\", \"blame\", \"semantic\", \"temporal\"],\n\tmaxAgeDays: 90,\n}\n\nexport async function analyzeBugCausality(\n\tbugFix: Commit,\n\toptions: Partial<DeepAnalysisConfig> = {},\n\trepoPath?: string,\n): Promise<CausalityResult[]> {\n\tconst config = { ...DEFAULT_CONFIG, ...options }\n\tconst results: CausalityResult[] = []\n\n\t// 1. Check for explicit references (highest confidence)\n\tif (config.methods.includes(\"explicit\")) {\n\t\tconst explicitResult = await analyzeExplicitReferences(bugFix)\n\t\tif (explicitResult) {\n\t\t\tresults.push(explicitResult)\n\t\t}\n\t}\n\n\t// 2. Blame-based analysis\n\tif (config.methods.includes(\"blame\")) {\n\t\tconst blameResults = await analyzeByBlame(bugFix, config.maxAgeDays, repoPath)\n\t\tresults.push(...blameResults)\n\t}\n\n\t// 3. Semantic similarity analysis\n\tif (config.methods.includes(\"semantic\")) {\n\t\tconst semanticResults = await analyzeBySemantic(bugFix, config.maxAgeDays)\n\t\tresults.push(...semanticResults)\n\t}\n\n\t// 4. Temporal proximity analysis\n\tif (config.methods.includes(\"temporal\")) {\n\t\tconst temporalResults = await analyzeByTemporal(bugFix, config.maxAgeDays)\n\t\tresults.push(...temporalResults)\n\t}\n\n\t// Deduplicate and merge results\n\treturn mergeResults(results)\n}\n\nasync function analyzeExplicitReferences(bugFix: Commit): Promise<CausalityResult | null> {\n\tconst message = bugFix.message\n\n\t// Check if this is a revert\n\tif (isRevert(message)) {\n\t\tconst revertedSha = getRevertedSha(message)\n\t\tif (revertedSha) {\n\t\t\treturn {\n\t\t\t\tcauseSha: revertedSha,\n\t\t\t\trelationshipType: \"root_cause\",\n\t\t\t\tconfidence: 0.95,\n\t\t\t\tanalysisMethod: \"explicit\",\n\t\t\t\tnotes: \"Revert commit\",\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check for \"introduced in\", \"caused by\" patterns\n\tconst patterns = [\n\t\t/introduced\\s+in\\s+([a-f0-9]{7,40})/i,\n\t\t/caused\\s+by\\s+([a-f0-9]{7,40})/i,\n\t\t/regression\\s+from\\s+([a-f0-9]{7,40})/i,\n\t\t/broke\\s+in\\s+([a-f0-9]{7,40})/i,\n\t\t/broken\\s+by\\s+([a-f0-9]{7,40})/i,\n\t]\n\n\tfor (const pattern of patterns) {\n\t\tconst match = message.match(pattern)\n\t\tif (match) {\n\t\t\treturn {\n\t\t\t\tcauseSha: match[1],\n\t\t\t\trelationshipType: \"root_cause\",\n\t\t\t\tconfidence: 0.95,\n\t\t\t\tanalysisMethod: \"explicit\",\n\t\t\t\tnotes: `Matched pattern: ${pattern.source}`,\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check for \"fixes #<issue>\" that references another PR\n\t// This would require GitHub API access, so we skip for now\n\n\treturn null\n}\n\nfunction mergeResults(results: CausalityResult[]): CausalityResult[] {\n\tconst byCommit = new Map<string, CausalityResult>()\n\n\tfor (const result of results) {\n\t\tconst existing = byCommit.get(result.causeSha)\n\n\t\tif (!existing) {\n\t\t\tbyCommit.set(result.causeSha, result)\n\t\t} else {\n\t\t\t// Merge: keep highest confidence, prefer root_cause over related_to\n\t\t\tconst merged: CausalityResult = {\n\t\t\t\tcauseSha: result.causeSha,\n\t\t\t\trelationshipType:\n\t\t\t\t\texisting.relationshipType === \"root_cause\" || result.relationshipType === \"root_cause\"\n\t\t\t\t\t\t? \"root_cause\"\n\t\t\t\t\t\t: \"related_to\",\n\t\t\t\tconfidence: Math.max(existing.confidence, result.confidence),\n\t\t\t\tbugAge: existing.bugAge ?? result.bugAge,\n\t\t\t\tbugAgeCommits: existing.bugAgeCommits ?? result.bugAgeCommits,\n\t\t\t\tanalysisMethod: `${existing.analysisMethod},${result.analysisMethod}`,\n\t\t\t\tnotes: [existing.notes, result.notes].filter(Boolean).join(\"; \"),\n\t\t\t}\n\t\t\tbyCommit.set(result.causeSha, merged)\n\t\t}\n\t}\n\n\t// Sort by confidence descending\n\treturn Array.from(byCommit.values()).sort((a, b) => b.confidence - a.confidence)\n}\n\nexport { analyzeByBlame } from \"./blame-method\"\nexport { analyzeBySemantic } from \"./semantic-method\"\nexport { analyzeByTemporal } from \"./temporal-method\"\n"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AACA;;;;;AAGA,MAAM,iBAAqC;IAC1C,WAAW;IACX,aAAa;IACb,SAAS;QAAC;QAAY;QAAS;QAAY;KAAW;IACtD,YAAY;AACb;AAEO,eAAe,oBACrB,MAAc,EACd,UAAuC,CAAC,CAAC,EACzC,QAAiB;IAEjB,MAAM,SAAS;QAAE,GAAG,cAAc;QAAE,GAAG,OAAO;IAAC;IAC/C,MAAM,UAA6B,EAAE;IAErC,wDAAwD;IACxD,IAAI,OAAO,OAAO,CAAC,QAAQ,CAAC,aAAa;QACxC,MAAM,iBAAiB,MAAM,0BAA0B;QACvD,IAAI,gBAAgB;YACnB,QAAQ,IAAI,CAAC;QACd;IACD;IAEA,0BAA0B;IAC1B,IAAI,OAAO,OAAO,CAAC,QAAQ,CAAC,UAAU;QACrC,MAAM,eAAe,MAAM,IAAA,sMAAc,EAAC,QAAQ,OAAO,UAAU,EAAE;QACrE,QAAQ,IAAI,IAAI;IACjB;IAEA,kCAAkC;IAClC,IAAI,OAAO,OAAO,CAAC,QAAQ,CAAC,aAAa;QACxC,MAAM,kBAAkB,MAAM,IAAA,4MAAiB,EAAC,QAAQ,OAAO,UAAU;QACzE,QAAQ,IAAI,IAAI;IACjB;IAEA,iCAAiC;IACjC,IAAI,OAAO,OAAO,CAAC,QAAQ,CAAC,aAAa;QACxC,MAAM,kBAAkB,MAAM,IAAA,4MAAiB,EAAC,QAAQ,OAAO,UAAU;QACzE,QAAQ,IAAI,IAAI;IACjB;IAEA,gCAAgC;IAChC,OAAO,aAAa;AACrB;AAEA,eAAe,0BAA0B,MAAc;IACtD,MAAM,UAAU,OAAO,OAAO;IAE9B,4BAA4B;IAC5B,IAAI,IAAA,iLAAQ,EAAC,UAAU;QACtB,MAAM,cAAc,IAAA,uLAAc,EAAC;QACnC,IAAI,aAAa;YAChB,OAAO;gBACN,UAAU;gBACV,kBAAkB;gBAClB,YAAY;gBACZ,gBAAgB;gBAChB,OAAO;YACR;QACD;IACD;IAEA,kDAAkD;IAClD,MAAM,WAAW;QAChB;QACA;QACA;QACA;QACA;KACA;IAED,KAAK,MAAM,WAAW,SAAU;QAC/B,MAAM,QAAQ,QAAQ,KAAK,CAAC;QAC5B,IAAI,OAAO;YACV,OAAO;gBACN,UAAU,KAAK,CAAC,EAAE;gBAClB,kBAAkB;gBAClB,YAAY;gBACZ,gBAAgB;gBAChB,OAAO,CAAC,iBAAiB,EAAE,QAAQ,MAAM,EAAE;YAC5C;QACD;IACD;IAEA,wDAAwD;IACxD,2DAA2D;IAE3D,OAAO;AACR;AAEA,SAAS,aAAa,OAA0B;IAC/C,MAAM,WAAW,IAAI;IAErB,KAAK,MAAM,UAAU,QAAS;QAC7B,MAAM,WAAW,SAAS,GAAG,CAAC,OAAO,QAAQ;QAE7C,IAAI,CAAC,UAAU;YACd,SAAS,GAAG,CAAC,OAAO,QAAQ,EAAE;QAC/B,OAAO;YACN,oEAAoE;YACpE,MAAM,SAA0B;gBAC/B,UAAU,OAAO,QAAQ;gBACzB,kBACC,SAAS,gBAAgB,KAAK,gBAAgB,OAAO,gBAAgB,KAAK,eACvE,eACA;gBACJ,YAAY,KAAK,GAAG,CAAC,SAAS,UAAU,EAAE,OAAO,UAAU;gBAC3D,QAAQ,SAAS,MAAM,IAAI,OAAO,MAAM;gBACxC,eAAe,SAAS,aAAa,IAAI,OAAO,aAAa;gBAC7D,gBAAgB,GAAG,SAAS,cAAc,CAAC,CAAC,EAAE,OAAO,cAAc,EAAE;gBACrE,OAAO;oBAAC,SAAS,KAAK;oBAAE,OAAO,KAAK;iBAAC,CAAC,MAAM,CAAC,SAAS,IAAI,CAAC;YAC5D;YACA,SAAS,GAAG,CAAC,OAAO,QAAQ,EAAE;QAC/B;IACD;IAEA,gCAAgC;IAChC,OAAO,MAAM,IAAI,CAAC,SAAS,MAAM,IAAI,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,UAAU,GAAG,EAAE,UAAU;AAChF"}},
    {"offset": {"line": 2760, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/causality/index.ts"],"sourcesContent":["export * from \"./analyzer\"\nexport * from \"./blame-method\"\nexport * from \"./semantic-method\"\nexport * from \"./temporal-method\"\n"],"names":[],"mappings":";AAAA;AACA;AACA;AACA"}},
    {"offset": {"line": 2773, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/detection/regression.ts"],"sourcesContent":["import type { PatternSignature, PatternMatch, Subsystem } from \"../types\"\nimport type { Commit, InsertRegressionPattern } from \"../db/schema\"\nimport { getDb } from \"../db/db\"\nimport {\n\tcreateRegressionPattern,\n\tgetRegressionPatterns,\n\tgetRegressionPatternByHash,\n\taddCommitToPattern,\n\tgeneratePatternHash,\n} from \"../db/queries/patterns\"\nimport { extractKeywords } from \"../git/parser\"\nimport { extractSemanticKeywords } from \"../classifiers/semantic\"\nimport { getPrimarySubsystem } from \"../classifiers/subsystem\"\n\n// Minimum similarity threshold to consider a match\nconst SIMILARITY_THRESHOLD = 0.4\n\nexport function extractPatternSignature(commit: Commit, filePaths: string[]): PatternSignature {\n\tconst keywords = [\n\t\t...extractKeywords(commit.message),\n\t\t...extractSemanticKeywords(commit.message),\n\t].slice(0, 10)\n\n\tconst subsystem = getPrimarySubsystem(filePaths)\n\n\t// Extract file patterns (directories)\n\tconst filePatterns = new Set<string>()\n\tfor (const filePath of filePaths) {\n\t\tconst parts = filePath.split(\"/\")\n\t\tif (parts.length >= 2) {\n\t\t\tfilePatterns.add(`${parts[0]}/${parts[1]}/*`)\n\t\t}\n\t}\n\n\treturn {\n\t\tsubsystem,\n\t\tkeywords,\n\t\tfilePatterns: [...filePatterns].slice(0, 5),\n\t}\n}\n\nexport function calculatePatternSimilarity(sig1: PatternSignature, sig2: PatternSignature): PatternMatch | null {\n\t// Must be same subsystem for a match\n\tif (sig1.subsystem !== sig2.subsystem || sig1.subsystem === \"unknown\") {\n\t\treturn null\n\t}\n\n\t// Calculate Jaccard similarity for keywords\n\tconst kw1 = new Set(sig1.keywords.map((k) => k.toLowerCase()))\n\tconst kw2 = new Set(sig2.keywords.map((k) => k.toLowerCase()))\n\n\tconst intersection = new Set([...kw1].filter((k) => kw2.has(k)))\n\tconst union = new Set([...kw1, ...kw2])\n\n\tif (intersection.size === 0 || union.size === 0) {\n\t\treturn null\n\t}\n\n\tconst keywordSimilarity = intersection.size / union.size\n\n\t// Calculate file pattern similarity\n\tconst fp1 = new Set(sig1.filePatterns)\n\tconst fp2 = new Set(sig2.filePatterns)\n\n\tconst fpIntersection = new Set([...fp1].filter((f) => fp2.has(f)))\n\tconst fpUnion = new Set([...fp1, ...fp2])\n\n\tconst fileSimilarity = fpUnion.size > 0 ? fpIntersection.size / fpUnion.size : 0\n\n\t// Combined similarity (weighted)\n\tconst similarity = keywordSimilarity * 0.7 + fileSimilarity * 0.3\n\n\tif (similarity < SIMILARITY_THRESHOLD) {\n\t\treturn null\n\t}\n\n\treturn {\n\t\tpatternHash: generatePatternHash(sig1.subsystem, [...intersection]),\n\t\tsimilarity,\n\t\tmatchedKeywords: [...intersection],\n\t}\n}\n\nexport async function findMatchingPattern(signature: PatternSignature): Promise<PatternMatch | null> {\n\tconst db = getDb()\n\n\t// Get existing patterns for the same subsystem\n\tconst patterns = await getRegressionPatterns({\n\t\tsubsystem: signature.subsystem,\n\t\tstatus: \"active\",\n\t})\n\n\tlet bestMatch: PatternMatch | null = null\n\tlet bestSimilarity = 0\n\n\tfor (const pattern of patterns) {\n\t\tconst patternSig: PatternSignature = {\n\t\t\tsubsystem: pattern.subsystem as Subsystem,\n\t\t\tkeywords: pattern.keywords || [],\n\t\t\tfilePatterns: pattern.filePatterns || [],\n\t\t}\n\n\t\tconst match = calculatePatternSimilarity(signature, patternSig)\n\n\t\tif (match && match.similarity > bestSimilarity) {\n\t\t\tbestMatch = {\n\t\t\t\tpatternHash: pattern.patternHash,\n\t\t\t\tsimilarity: match.similarity,\n\t\t\t\tmatchedKeywords: match.matchedKeywords,\n\t\t\t}\n\t\t\tbestSimilarity = match.similarity\n\t\t}\n\t}\n\n\treturn bestMatch\n}\n\nexport async function detectRegression(\n\tcommit: Commit,\n\tfilePaths: string[],\n): Promise<{ isRegression: boolean; patternHash?: string; isNew?: boolean }> {\n\tconst db = getDb()\n\n\t// Only bug fixes can be regressions\n\tif (commit.messageType !== \"fix\") {\n\t\treturn { isRegression: false }\n\t}\n\n\tconst signature = extractPatternSignature(commit, filePaths)\n\n\t// Skip if subsystem is unknown\n\tif (signature.subsystem === \"unknown\" || signature.keywords.length === 0) {\n\t\treturn { isRegression: false }\n\t}\n\n\t// Look for matching pattern\n\tconst match = await findMatchingPattern(signature)\n\n\tif (match && match.similarity >= SIMILARITY_THRESHOLD) {\n\t\t// Add this commit to the existing pattern\n\t\tawait addCommitToPattern(match.patternHash, commit.sha)\n\n\t\treturn {\n\t\t\tisRegression: true,\n\t\t\tpatternHash: match.patternHash,\n\t\t\tisNew: false,\n\t\t}\n\t}\n\n\t// Check if we should create a new pattern\n\t// Only create patterns for commits with meaningful keywords\n\tif (signature.keywords.length >= 2) {\n\t\tconst patternHash = generatePatternHash(signature.subsystem, signature.keywords)\n\n\t\t// Check if pattern already exists\n\t\tconst existing = await getRegressionPatternByHash(patternHash)\n\t\tif (existing) {\n\t\t\tawait addCommitToPattern(patternHash, commit.sha)\n\t\t\treturn {\n\t\t\t\tisRegression: existing.occurrenceCount! >= 2,\n\t\t\t\tpatternHash,\n\t\t\t\tisNew: false,\n\t\t\t}\n\t\t}\n\n\t\t// Create new pattern (not a regression yet until we see it again)\n\t\tawait createRegressionPattern({\n\t\t\tpatternHash,\n\t\t\tsubsystem: signature.subsystem,\n\t\t\tkeywords: signature.keywords,\n\t\t\tfilePatterns: signature.filePatterns,\n\t\t\tfirstOccurrence: commit.sha,\n\t\t\toccurrenceCount: 1,\n\t\t\tcommitShas: [commit.sha],\n\t\t\tseverity: \"low\",\n\t\t\tstatus: \"active\",\n\t\t})\n\n\t\treturn {\n\t\t\tisRegression: false,\n\t\t\tpatternHash,\n\t\t\tisNew: true,\n\t\t}\n\t}\n\n\treturn { isRegression: false }\n}\n\nexport async function getRecurringRegressions(minOccurrences: number = 2) {\n\treturn getRegressionPatterns({\n\t\tminOccurrences,\n\t\tstatus: \"active\",\n\t})\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAEA;AACA;AAOA;AACA;AACA;;;;;;AAEA,mDAAmD;AACnD,MAAM,uBAAuB;AAEtB,SAAS,wBAAwB,MAAc,EAAE,SAAmB;IAC1E,MAAM,WAAW;WACb,IAAA,wLAAe,EAAC,OAAO,OAAO;WAC9B,IAAA,0MAAuB,EAAC,OAAO,OAAO;KACzC,CAAC,KAAK,CAAC,GAAG;IAEX,MAAM,YAAY,IAAA,uMAAmB,EAAC;IAEtC,sCAAsC;IACtC,MAAM,eAAe,IAAI;IACzB,KAAK,MAAM,YAAY,UAAW;QACjC,MAAM,QAAQ,SAAS,KAAK,CAAC;QAC7B,IAAI,MAAM,MAAM,IAAI,GAAG;YACtB,aAAa,GAAG,CAAC,GAAG,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,EAAE,CAAC,EAAE,CAAC;QAC7C;IACD;IAEA,OAAO;QACN;QACA;QACA,cAAc;eAAI;SAAa,CAAC,KAAK,CAAC,GAAG;IAC1C;AACD;AAEO,SAAS,2BAA2B,IAAsB,EAAE,IAAsB;IACxF,qCAAqC;IACrC,IAAI,KAAK,SAAS,KAAK,KAAK,SAAS,IAAI,KAAK,SAAS,KAAK,WAAW;QACtE,OAAO;IACR;IAEA,4CAA4C;IAC5C,MAAM,MAAM,IAAI,IAAI,KAAK,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAM,EAAE,WAAW;IAC1D,MAAM,MAAM,IAAI,IAAI,KAAK,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAM,EAAE,WAAW;IAE1D,MAAM,eAAe,IAAI,IAAI;WAAI;KAAI,CAAC,MAAM,CAAC,CAAC,IAAM,IAAI,GAAG,CAAC;IAC5D,MAAM,QAAQ,IAAI,IAAI;WAAI;WAAQ;KAAI;IAEtC,IAAI,aAAa,IAAI,KAAK,KAAK,MAAM,IAAI,KAAK,GAAG;QAChD,OAAO;IACR;IAEA,MAAM,oBAAoB,aAAa,IAAI,GAAG,MAAM,IAAI;IAExD,oCAAoC;IACpC,MAAM,MAAM,IAAI,IAAI,KAAK,YAAY;IACrC,MAAM,MAAM,IAAI,IAAI,KAAK,YAAY;IAErC,MAAM,iBAAiB,IAAI,IAAI;WAAI;KAAI,CAAC,MAAM,CAAC,CAAC,IAAM,IAAI,GAAG,CAAC;IAC9D,MAAM,UAAU,IAAI,IAAI;WAAI;WAAQ;KAAI;IAExC,MAAM,iBAAiB,QAAQ,IAAI,GAAG,IAAI,eAAe,IAAI,GAAG,QAAQ,IAAI,GAAG;IAE/E,iCAAiC;IACjC,MAAM,aAAa,oBAAoB,MAAM,iBAAiB;IAE9D,IAAI,aAAa,sBAAsB;QACtC,OAAO;IACR;IAEA,OAAO;QACN,aAAa,IAAA,wMAAmB,EAAC,KAAK,SAAS,EAAE;eAAI;SAAa;QAClE;QACA,iBAAiB;eAAI;SAAa;IACnC;AACD;AAEO,eAAe,oBAAoB,SAA2B;IACpE,MAAM,KAAK,IAAA,yKAAK;IAEhB,+CAA+C;IAC/C,MAAM,WAAW,MAAM,IAAA,0MAAqB,EAAC;QAC5C,WAAW,UAAU,SAAS;QAC9B,QAAQ;IACT;IAEA,IAAI,YAAiC;IACrC,IAAI,iBAAiB;IAErB,KAAK,MAAM,WAAW,SAAU;QAC/B,MAAM,aAA+B;YACpC,WAAW,QAAQ,SAAS;YAC5B,UAAU,QAAQ,QAAQ,IAAI,EAAE;YAChC,cAAc,QAAQ,YAAY,IAAI,EAAE;QACzC;QAEA,MAAM,QAAQ,2BAA2B,WAAW;QAEpD,IAAI,SAAS,MAAM,UAAU,GAAG,gBAAgB;YAC/C,YAAY;gBACX,aAAa,QAAQ,WAAW;gBAChC,YAAY,MAAM,UAAU;gBAC5B,iBAAiB,MAAM,eAAe;YACvC;YACA,iBAAiB,MAAM,UAAU;QAClC;IACD;IAEA,OAAO;AACR;AAEO,eAAe,iBACrB,MAAc,EACd,SAAmB;IAEnB,MAAM,KAAK,IAAA,yKAAK;IAEhB,oCAAoC;IACpC,IAAI,OAAO,WAAW,KAAK,OAAO;QACjC,OAAO;YAAE,cAAc;QAAM;IAC9B;IAEA,MAAM,YAAY,wBAAwB,QAAQ;IAElD,+BAA+B;IAC/B,IAAI,UAAU,SAAS,KAAK,aAAa,UAAU,QAAQ,CAAC,MAAM,KAAK,GAAG;QACzE,OAAO;YAAE,cAAc;QAAM;IAC9B;IAEA,4BAA4B;IAC5B,MAAM,QAAQ,MAAM,oBAAoB;IAExC,IAAI,SAAS,MAAM,UAAU,IAAI,sBAAsB;QACtD,0CAA0C;QAC1C,MAAM,IAAA,uMAAkB,EAAC,MAAM,WAAW,EAAE,OAAO,GAAG;QAEtD,OAAO;YACN,cAAc;YACd,aAAa,MAAM,WAAW;YAC9B,OAAO;QACR;IACD;IAEA,0CAA0C;IAC1C,4DAA4D;IAC5D,IAAI,UAAU,QAAQ,CAAC,MAAM,IAAI,GAAG;QACnC,MAAM,cAAc,IAAA,wMAAmB,EAAC,UAAU,SAAS,EAAE,UAAU,QAAQ;QAE/E,kCAAkC;QAClC,MAAM,WAAW,MAAM,IAAA,+MAA0B,EAAC;QAClD,IAAI,UAAU;YACb,MAAM,IAAA,uMAAkB,EAAC,aAAa,OAAO,GAAG;YAChD,OAAO;gBACN,cAAc,SAAS,eAAe,IAAK;gBAC3C;gBACA,OAAO;YACR;QACD;QAEA,kEAAkE;QAClE,MAAM,IAAA,4MAAuB,EAAC;YAC7B;YACA,WAAW,UAAU,SAAS;YAC9B,UAAU,UAAU,QAAQ;YAC5B,cAAc,UAAU,YAAY;YACpC,iBAAiB,OAAO,GAAG;YAC3B,iBAAiB;YACjB,YAAY;gBAAC,OAAO,GAAG;aAAC;YACxB,UAAU;YACV,QAAQ;QACT;QAEA,OAAO;YACN,cAAc;YACd;YACA,OAAO;QACR;IACD;IAEA,OAAO;QAAE,cAAc;IAAM;AAC9B;AAEO,eAAe,wBAAwB,iBAAyB,CAAC;IACvE,OAAO,IAAA,0MAAqB,EAAC;QAC5B;QACA,QAAQ;IACT;AACD"}},
    {"offset": {"line": 2965, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/detection/index.ts"],"sourcesContent":["export * from \"./regression\"\n"],"names":[],"mappings":";AAAA"}},
    {"offset": {"line": 2972, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/scoring/risk.ts"],"sourcesContent":["import type { CommitCategory } from \"../db/schema\"\nimport type { RiskFactors, RiskBreakdown, Subsystem } from \"../types\"\nimport { touchesCriticalPath, hasTestFiles, getSubsystemsAffected } from \"../classifiers/subsystem\"\nimport { isBreakingChange } from \"../git/parser\"\n\n// Weight factors for risk calculation\nconst RISK_WEIGHTS = {\n\tfilesChanged: 2, // Per file up to cap\n\tlinesChanged: 0.1, // Per line up to cap\n\tsubsystemsAffected: 10, // Per subsystem\n\tbreakingChange: 25,\n\tcriticalPath: 15,\n\tnoTests: 10,\n\tlowAuthorExperience: 5,\n\trecentRegressions: 8, // Per regression\n}\n\nconst CAPS = {\n\tfilesChanged: 20, // Cap at 20 files\n\tlinesChanged: 500, // Cap at 500 lines\n\tsubsystemsAffected: 5,\n\trecentRegressions: 3,\n}\n\n// Category base risk scores\nconst CATEGORY_BASE_RISK: Record<CommitCategory, number> = {\n\tbugfix: 20, // Bug fixes can introduce new bugs\n\tfeature: 30, // New features are risky\n\trefactor: 25, // Refactoring can break things\n\tperformance: 20,\n\trevert: 15, // Reverts are usually safe\n\tdocumentation: 5,\n\ttest: 5,\n\tbuild: 15,\n\tci: 10,\n\tstyle: 5,\n\tchore: 10,\n\tunknown: 20,\n}\n\nexport function calculateRiskScore(\n\tcategory: CommitCategory,\n\tmessage: string,\n\tfilePaths: string[],\n\tinsertions: number,\n\tdeletions: number,\n\tauthorCommitsInArea: number = 0,\n\trecentRegressions: number = 0,\n): RiskBreakdown {\n\tconst factors: Record<string, number> = {}\n\n\t// Base score from category\n\tconst baseScore = CATEGORY_BASE_RISK[category] || CATEGORY_BASE_RISK.unknown\n\tfactors.category = baseScore\n\n\t// Files changed factor\n\tconst filesChangedFactor =\n\t\tMath.min(filePaths.length, CAPS.filesChanged) * RISK_WEIGHTS.filesChanged\n\tfactors.filesChanged = filesChangedFactor\n\n\t// Lines changed factor\n\tconst linesChanged = insertions + deletions\n\tconst linesChangedFactor =\n\t\tMath.min(linesChanged, CAPS.linesChanged) * RISK_WEIGHTS.linesChanged\n\tfactors.linesChanged = linesChangedFactor\n\n\t// Subsystems affected factor\n\tconst subsystems = getSubsystemsAffected(filePaths)\n\tconst subsystemsFactor =\n\t\tMath.min(subsystems.length, CAPS.subsystemsAffected) * RISK_WEIGHTS.subsystemsAffected\n\tfactors.subsystemsAffected = subsystemsFactor\n\n\t// Breaking change factor\n\tif (isBreakingChange(message)) {\n\t\tfactors.breakingChange = RISK_WEIGHTS.breakingChange\n\t}\n\n\t// Critical path factor\n\tif (touchesCriticalPath(filePaths)) {\n\t\tfactors.criticalPath = RISK_WEIGHTS.criticalPath\n\t}\n\n\t// Test coverage factor (penalty for no tests)\n\tif (!hasTestFiles(filePaths) && filePaths.length > 2 && category !== \"documentation\") {\n\t\tfactors.noTests = RISK_WEIGHTS.noTests\n\t}\n\n\t// Author experience factor\n\tif (authorCommitsInArea < 5) {\n\t\tfactors.lowAuthorExperience = RISK_WEIGHTS.lowAuthorExperience\n\t}\n\n\t// Recent regressions factor\n\tif (recentRegressions > 0) {\n\t\tconst regressionFactor =\n\t\t\tMath.min(recentRegressions, CAPS.recentRegressions) * RISK_WEIGHTS.recentRegressions\n\t\tfactors.recentRegressions = regressionFactor\n\t}\n\n\t// Calculate final score\n\tconst totalFactors = Object.values(factors).reduce((sum, val) => sum + val, 0)\n\n\t// Normalize to 0-100 range\n\tconst finalScore = Math.min(100, Math.max(0, totalFactors))\n\n\treturn {\n\t\tbaseScore,\n\t\tfactors,\n\t\tfinalScore,\n\t}\n}\n\nexport function getRiskLevel(score: number): \"low\" | \"medium\" | \"high\" | \"critical\" {\n\tif (score < 25) return \"low\"\n\tif (score < 50) return \"medium\"\n\tif (score < 75) return \"high\"\n\treturn \"critical\"\n}\n\nexport function getRiskColor(score: number): string {\n\tif (score < 25) return \"green\"\n\tif (score < 50) return \"yellow\"\n\tif (score < 75) return \"orange\"\n\treturn \"red\"\n}\n\nexport function aggregateRisk(scores: number[]): number {\n\tif (scores.length === 0) return 0\n\n\t// Use weighted average with emphasis on higher risks\n\tconst sortedScores = [...scores].sort((a, b) => b - a)\n\tlet totalWeight = 0\n\tlet weightedSum = 0\n\n\tfor (let i = 0; i < sortedScores.length; i++) {\n\t\t// Higher weight for higher risk scores\n\t\tconst weight = Math.pow(0.8, i) // Exponential decay\n\t\tweightedSum += sortedScores[i] * weight\n\t\ttotalWeight += weight\n\t}\n\n\treturn weightedSum / totalWeight\n}\n"],"names":[],"mappings":";;;;;;;;;;AAEA;AACA;;;AAEA,sCAAsC;AACtC,MAAM,eAAe;IACpB,cAAc;IACd,cAAc;IACd,oBAAoB;IACpB,gBAAgB;IAChB,cAAc;IACd,SAAS;IACT,qBAAqB;IACrB,mBAAmB;AACpB;AAEA,MAAM,OAAO;IACZ,cAAc;IACd,cAAc;IACd,oBAAoB;IACpB,mBAAmB;AACpB;AAEA,4BAA4B;AAC5B,MAAM,qBAAqD;IAC1D,QAAQ;IACR,SAAS;IACT,UAAU;IACV,aAAa;IACb,QAAQ;IACR,eAAe;IACf,MAAM;IACN,OAAO;IACP,IAAI;IACJ,OAAO;IACP,OAAO;IACP,SAAS;AACV;AAEO,SAAS,mBACf,QAAwB,EACxB,OAAe,EACf,SAAmB,EACnB,UAAkB,EAClB,SAAiB,EACjB,sBAA8B,CAAC,EAC/B,oBAA4B,CAAC;IAE7B,MAAM,UAAkC,CAAC;IAEzC,2BAA2B;IAC3B,MAAM,YAAY,kBAAkB,CAAC,SAAS,IAAI,mBAAmB,OAAO;IAC5E,QAAQ,QAAQ,GAAG;IAEnB,uBAAuB;IACvB,MAAM,qBACL,KAAK,GAAG,CAAC,UAAU,MAAM,EAAE,KAAK,YAAY,IAAI,aAAa,YAAY;IAC1E,QAAQ,YAAY,GAAG;IAEvB,uBAAuB;IACvB,MAAM,eAAe,aAAa;IAClC,MAAM,qBACL,KAAK,GAAG,CAAC,cAAc,KAAK,YAAY,IAAI,aAAa,YAAY;IACtE,QAAQ,YAAY,GAAG;IAEvB,6BAA6B;IAC7B,MAAM,aAAa,IAAA,yMAAqB,EAAC;IACzC,MAAM,mBACL,KAAK,GAAG,CAAC,WAAW,MAAM,EAAE,KAAK,kBAAkB,IAAI,aAAa,kBAAkB;IACvF,QAAQ,kBAAkB,GAAG;IAE7B,yBAAyB;IACzB,IAAI,IAAA,yLAAgB,EAAC,UAAU;QAC9B,QAAQ,cAAc,GAAG,aAAa,cAAc;IACrD;IAEA,uBAAuB;IACvB,IAAI,IAAA,uMAAmB,EAAC,YAAY;QACnC,QAAQ,YAAY,GAAG,aAAa,YAAY;IACjD;IAEA,8CAA8C;IAC9C,IAAI,CAAC,IAAA,gMAAY,EAAC,cAAc,UAAU,MAAM,GAAG,KAAK,aAAa,iBAAiB;QACrF,QAAQ,OAAO,GAAG,aAAa,OAAO;IACvC;IAEA,2BAA2B;IAC3B,IAAI,sBAAsB,GAAG;QAC5B,QAAQ,mBAAmB,GAAG,aAAa,mBAAmB;IAC/D;IAEA,4BAA4B;IAC5B,IAAI,oBAAoB,GAAG;QAC1B,MAAM,mBACL,KAAK,GAAG,CAAC,mBAAmB,KAAK,iBAAiB,IAAI,aAAa,iBAAiB;QACrF,QAAQ,iBAAiB,GAAG;IAC7B;IAEA,wBAAwB;IACxB,MAAM,eAAe,OAAO,MAAM,CAAC,SAAS,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,KAAK;IAE5E,2BAA2B;IAC3B,MAAM,aAAa,KAAK,GAAG,CAAC,KAAK,KAAK,GAAG,CAAC,GAAG;IAE7C,OAAO;QACN;QACA;QACA;IACD;AACD;AAEO,SAAS,aAAa,KAAa;IACzC,IAAI,QAAQ,IAAI,OAAO;IACvB,IAAI,QAAQ,IAAI,OAAO;IACvB,IAAI,QAAQ,IAAI,OAAO;IACvB,OAAO;AACR;AAEO,SAAS,aAAa,KAAa;IACzC,IAAI,QAAQ,IAAI,OAAO;IACvB,IAAI,QAAQ,IAAI,OAAO;IACvB,IAAI,QAAQ,IAAI,OAAO;IACvB,OAAO;AACR;AAEO,SAAS,cAAc,MAAgB;IAC7C,IAAI,OAAO,MAAM,KAAK,GAAG,OAAO;IAEhC,qDAAqD;IACrD,MAAM,eAAe;WAAI;KAAO,CAAC,IAAI,CAAC,CAAC,GAAG,IAAM,IAAI;IACpD,IAAI,cAAc;IAClB,IAAI,cAAc;IAElB,IAAK,IAAI,IAAI,GAAG,IAAI,aAAa,MAAM,EAAE,IAAK;QAC7C,uCAAuC;QACvC,MAAM,SAAS,KAAK,GAAG,CAAC,KAAK,GAAG,oBAAoB;;QACpD,eAAe,YAAY,CAAC,EAAE,GAAG;QACjC,eAAe;IAChB;IAEA,OAAO,cAAc;AACtB"}},
    {"offset": {"line": 3098, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/scoring/index.ts"],"sourcesContent":["export * from \"./risk\"\n"],"names":[],"mappings":";AAAA"}},
    {"offset": {"line": 3105, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/sync/advisor.ts"],"sourcesContent":["import type { SyncRecommendation } from \"../types\"\nimport { getDb } from \"../db/db\"\nimport { getCommits } from \"../db/queries/commits\"\nimport { getClassificationsByCommits } from \"../db/queries/classifications\"\nimport { getCommitsBetween, resolveRef } from \"../git/extractor\"\nimport { aggregateRisk, getRiskLevel } from \"../scoring/risk\"\n\nexport interface SyncAdvisorOptions {\n\tupstream: string // e.g., \"origin/main\"\n\tlocal: string // e.g., \"HEAD\" or a tag\n\tmaxRisk: number // Maximum acceptable aggregate risk\n\trepoPath?: string\n}\n\nexport async function analyzeSyncRange(options: SyncAdvisorOptions): Promise<SyncRecommendation> {\n\tconst db = getDb()\n\n\t// Resolve refs to SHAs\n\tconst upstreamSha = await resolveRef(options.upstream, options.repoPath)\n\tconst localSha = await resolveRef(options.local, options.repoPath)\n\n\t// Get commits between local and upstream\n\tconst commitShas = await getCommitsBetween(localSha, upstreamSha, options.repoPath)\n\n\tif (commitShas.length === 0) {\n\t\treturn {\n\t\t\trecommendedCommit: upstreamSha,\n\t\t\ttotalRisk: 0,\n\t\t\tcommitCount: 0,\n\t\t\tbreakdown: { features: 0, fixes: 0, other: 0 },\n\t\t\twarnings: [],\n\t\t\tsafeToSync: true,\n\t\t}\n\t}\n\n\t// Get classifications for these commits\n\tconst classifications = await getClassificationsByCommits(commitShas, db)\n\tconst classificationMap = new Map(classifications.map((c) => [c.commitSha, c]))\n\n\t// Get commit details\n\tconst commitDetails = await getCommits({}, db)\n\tconst commitMap = new Map(commitDetails.map((c) => [c.sha, c]))\n\n\t// Analyze commits\n\tconst riskScores: number[] = []\n\tlet features = 0\n\tlet fixes = 0\n\tlet other = 0\n\tconst warnings: string[] = []\n\n\tfor (const sha of commitShas) {\n\t\tconst commit = commitMap.get(sha)\n\t\tconst classification = classificationMap.get(sha)\n\n\t\tif (!commit) continue\n\n\t\tconst riskScore = classification?.riskScore ?? 25 // Default moderate risk for unanalyzed\n\t\triskScores.push(riskScore)\n\n\t\t// Count by type\n\t\tif (commit.messageType === \"feat\") features++\n\t\telse if (commit.messageType === \"fix\") fixes++\n\t\telse other++\n\n\t\t// Check for high-risk commits\n\t\tif (riskScore >= 70) {\n\t\t\twarnings.push(`High risk: ${commit.shortSha} - ${commit.message.slice(0, 50)}`)\n\t\t}\n\t}\n\n\tconst totalRisk = aggregateRisk(riskScores)\n\tconst safeToSync = totalRisk <= options.maxRisk\n\n\t// Find recommended sync point if not safe\n\tlet recommendedCommit = upstreamSha\n\n\tif (!safeToSync) {\n\t\t// Find the latest commit where cumulative risk is acceptable\n\t\tlet cumulativeRisk = 0\n\t\tconst riskScoresReversed = [...riskScores].reverse()\n\t\tconst commitsReversed = [...commitShas].reverse()\n\n\t\tfor (let i = 0; i < commitsReversed.length; i++) {\n\t\t\tconst newRisk = aggregateRisk([...riskScoresReversed.slice(0, i + 1)])\n\t\t\tif (newRisk > options.maxRisk) {\n\t\t\t\tif (i > 0) {\n\t\t\t\t\trecommendedCommit = commitsReversed[i - 1]\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\twarnings.unshift(`Total risk (${totalRisk.toFixed(1)}) exceeds threshold (${options.maxRisk})`)\n\t}\n\n\treturn {\n\t\trecommendedCommit,\n\t\ttotalRisk,\n\t\tcommitCount: commitShas.length,\n\t\tbreakdown: { features, fixes, other },\n\t\twarnings,\n\t\tsafeToSync,\n\t}\n}\n\nexport async function getSyncSummary(\n\tupstream: string,\n\tlocal: string,\n\trepoPath?: string,\n): Promise<{\n\tbehind: number\n\tahead: number\n\tlastSyncDate?: Date\n}> {\n\tconst db = getDb()\n\n\t// Get commits we're behind\n\tconst upstreamSha = await resolveRef(upstream, repoPath)\n\tconst localSha = await resolveRef(local, repoPath)\n\n\tconst behind = await getCommitsBetween(localSha, upstreamSha, repoPath)\n\n\t// Get commits we're ahead (local changes not in upstream)\n\tlet ahead: string[] = []\n\ttry {\n\t\tahead = await getCommitsBetween(upstreamSha, localSha, repoPath)\n\t} catch {\n\t\t// Might fail if local is behind upstream\n\t}\n\n\t// Get the date of the local commit\n\tconst localCommit = await getCommits({ limit: 1 }, db)\n\tconst lastSyncDate = localCommit[0]?.date\n\n\treturn {\n\t\tbehind: behind.length,\n\t\tahead: ahead.length,\n\t\tlastSyncDate,\n\t}\n}\n"],"names":[],"mappings":";;;;;;AACA;AACA;AACA;AACA;AACA;;;;;;AASO,eAAe,iBAAiB,OAA2B;IACjE,MAAM,KAAK,IAAA,yKAAK;IAEhB,uBAAuB;IACvB,MAAM,cAAc,MAAM,IAAA,sLAAU,EAAC,QAAQ,QAAQ,EAAE,QAAQ,QAAQ;IACvE,MAAM,WAAW,MAAM,IAAA,sLAAU,EAAC,QAAQ,KAAK,EAAE,QAAQ,QAAQ;IAEjE,yCAAyC;IACzC,MAAM,aAAa,MAAM,IAAA,6LAAiB,EAAC,UAAU,aAAa,QAAQ,QAAQ;IAElF,IAAI,WAAW,MAAM,KAAK,GAAG;QAC5B,OAAO;YACN,mBAAmB;YACnB,WAAW;YACX,aAAa;YACb,WAAW;gBAAE,UAAU;gBAAG,OAAO;gBAAG,OAAO;YAAE;YAC7C,UAAU,EAAE;YACZ,YAAY;QACb;IACD;IAEA,wCAAwC;IACxC,MAAM,kBAAkB,MAAM,IAAA,uNAA2B,EAAC,YAAY;IACtE,MAAM,oBAAoB,IAAI,IAAI,gBAAgB,GAAG,CAAC,CAAC,IAAM;YAAC,EAAE,SAAS;YAAE;SAAE;IAE7E,qBAAqB;IACrB,MAAM,gBAAgB,MAAM,IAAA,8LAAU,EAAC,CAAC,GAAG;IAC3C,MAAM,YAAY,IAAI,IAAI,cAAc,GAAG,CAAC,CAAC,IAAM;YAAC,EAAE,GAAG;YAAE;SAAE;IAE7D,kBAAkB;IAClB,MAAM,aAAuB,EAAE;IAC/B,IAAI,WAAW;IACf,IAAI,QAAQ;IACZ,IAAI,QAAQ;IACZ,MAAM,WAAqB,EAAE;IAE7B,KAAK,MAAM,OAAO,WAAY;QAC7B,MAAM,SAAS,UAAU,GAAG,CAAC;QAC7B,MAAM,iBAAiB,kBAAkB,GAAG,CAAC;QAE7C,IAAI,CAAC,QAAQ;QAEb,MAAM,YAAY,gBAAgB,aAAa,GAAG,uCAAuC;;QACzF,WAAW,IAAI,CAAC;QAEhB,gBAAgB;QAChB,IAAI,OAAO,WAAW,KAAK,QAAQ;aAC9B,IAAI,OAAO,WAAW,KAAK,OAAO;aAClC;QAEL,8BAA8B;QAC9B,IAAI,aAAa,IAAI;YACpB,SAAS,IAAI,CAAC,CAAC,WAAW,EAAE,OAAO,QAAQ,CAAC,GAAG,EAAE,OAAO,OAAO,CAAC,KAAK,CAAC,GAAG,KAAK;QAC/E;IACD;IAEA,MAAM,YAAY,IAAA,wLAAa,EAAC;IAChC,MAAM,aAAa,aAAa,QAAQ,OAAO;IAE/C,0CAA0C;IAC1C,IAAI,oBAAoB;IAExB,IAAI,CAAC,YAAY;QAChB,6DAA6D;QAC7D,IAAI,iBAAiB;QACrB,MAAM,qBAAqB;eAAI;SAAW,CAAC,OAAO;QAClD,MAAM,kBAAkB;eAAI;SAAW,CAAC,OAAO;QAE/C,IAAK,IAAI,IAAI,GAAG,IAAI,gBAAgB,MAAM,EAAE,IAAK;YAChD,MAAM,UAAU,IAAA,wLAAa,EAAC;mBAAI,mBAAmB,KAAK,CAAC,GAAG,IAAI;aAAG;YACrE,IAAI,UAAU,QAAQ,OAAO,EAAE;gBAC9B,IAAI,IAAI,GAAG;oBACV,oBAAoB,eAAe,CAAC,IAAI,EAAE;gBAC3C;gBACA;YACD;QACD;QAEA,SAAS,OAAO,CAAC,CAAC,YAAY,EAAE,UAAU,OAAO,CAAC,GAAG,qBAAqB,EAAE,QAAQ,OAAO,CAAC,CAAC,CAAC;IAC/F;IAEA,OAAO;QACN;QACA;QACA,aAAa,WAAW,MAAM;QAC9B,WAAW;YAAE;YAAU;YAAO;QAAM;QACpC;QACA;IACD;AACD;AAEO,eAAe,eACrB,QAAgB,EAChB,KAAa,EACb,QAAiB;IAMjB,MAAM,KAAK,IAAA,yKAAK;IAEhB,2BAA2B;IAC3B,MAAM,cAAc,MAAM,IAAA,sLAAU,EAAC,UAAU;IAC/C,MAAM,WAAW,MAAM,IAAA,sLAAU,EAAC,OAAO;IAEzC,MAAM,SAAS,MAAM,IAAA,6LAAiB,EAAC,UAAU,aAAa;IAE9D,0DAA0D;IAC1D,IAAI,QAAkB,EAAE;IACxB,IAAI;QACH,QAAQ,MAAM,IAAA,6LAAiB,EAAC,aAAa,UAAU;IACxD,EAAE,OAAM;IACP,yCAAyC;IAC1C;IAEA,mCAAmC;IACnC,MAAM,cAAc,MAAM,IAAA,8LAAU,EAAC;QAAE,OAAO;IAAE,GAAG;IACnD,MAAM,eAAe,WAAW,CAAC,EAAE,EAAE;IAErC,OAAO;QACN,QAAQ,OAAO,MAAM;QACrB,OAAO,MAAM,MAAM;QACnB;IACD;AACD"}},
    {"offset": {"line": 3243, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/sync/index.ts"],"sourcesContent":["export * from \"./advisor\"\n"],"names":[],"mappings":";AAAA"}},
    {"offset": {"line": 3250, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/packages/commit-analysis/src/index.ts"],"sourcesContent":["// Main package exports\nexport * from \"./db\"\nexport * from \"./types\"\nexport * from \"./git\"\nexport * from \"./classifiers\"\nexport * from \"./causality\"\nexport * from \"./detection\"\nexport * from \"./scoring\"\nexport * from \"./sync\"\n"],"names":[],"mappings":";AAAA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 3272, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/apps/web-commit-analysis/src/actions/timeline.ts"],"sourcesContent":["\"use server\"\n\nimport {\n\tgetReleases,\n\tgetCommits,\n\tgetClassifications,\n\tgetCategoryDistribution,\n\ttype Release,\n\ttype Commit,\n\ttype Classification,\n} from \"@roo-code/commit-analysis\"\n\nexport interface ReleaseWithCommits {\n\trelease: Release\n\tcommits: (Commit & { classification?: Classification | null })[]\n}\n\nexport async function getTimelineData(): Promise<ReleaseWithCommits[]> {\n\ttry {\n\t\tconst releases = await getReleases({ limit: 20 })\n\t\tconst commits = await getCommits({ limit: 500 })\n\n\t\t// Group commits by release\n\t\tconst result: ReleaseWithCommits[] = []\n\n\t\tfor (let i = 0; i < releases.length; i++) {\n\t\t\tconst release = releases[i]\n\t\t\tconst nextRelease = releases[i + 1]\n\n\t\t\t// Get commits between this release and the next one\n\t\t\tconst releaseCommits = commits.filter((c) => {\n\t\t\t\tif (nextRelease) {\n\t\t\t\t\treturn c.date <= release.date && c.date > nextRelease.date\n\t\t\t\t}\n\t\t\t\treturn c.date <= release.date\n\t\t\t})\n\n\t\t\tresult.push({\n\t\t\t\trelease,\n\t\t\t\tcommits: releaseCommits.slice(0, 50), // Limit commits per release\n\t\t\t})\n\t\t}\n\n\t\treturn result\n\t} catch (error) {\n\t\tconsole.error(\"Error fetching timeline data:\", error)\n\t\treturn []\n\t}\n}\n\nexport async function getCommitDetails(sha: string) {\n\ttry {\n\t\tconst commits = await getCommits({ limit: 1 })\n\t\tconst commit = commits.find((c) => c.sha === sha || c.shortSha === sha)\n\t\treturn commit || null\n\t} catch (error) {\n\t\tconsole.error(\"Error fetching commit details:\", error)\n\t\treturn null\n\t}\n}\n\nexport async function getDashboardStats() {\n\ttry {\n\t\tconst commits = await getCommits({})\n\t\tconst classifications = await getClassifications({})\n\t\tconst distribution = await getCategoryDistribution()\n\n\t\tconst totalCommits = commits.length\n\t\tconst totalClassified = classifications.length\n\t\tconst avgRisk =\n\t\t\tclassifications.reduce((sum, c) => sum + c.riskScore, 0) / (classifications.length || 1)\n\n\t\treturn {\n\t\t\ttotalCommits,\n\t\t\ttotalClassified,\n\t\t\tavgRisk,\n\t\t\tdistribution,\n\t\t}\n\t} catch (error) {\n\t\tconsole.error(\"Error fetching dashboard stats:\", error)\n\t\treturn {\n\t\t\ttotalCommits: 0,\n\t\t\ttotalClassified: 0,\n\t\t\tavgRisk: 0,\n\t\t\tdistribution: [],\n\t\t}\n\t}\n}\n\nexport async function getHighRiskCommits(threshold: number = 50) {\n\ttry {\n\t\treturn await getClassifications({ minRisk: threshold, limit: 20 })\n\t} catch (error) {\n\t\tconsole.error(\"Error fetching high risk commits:\", error)\n\t\treturn []\n\t}\n}\n"],"names":[],"mappings":";;;;;;;;;;;AAEA;AAAA;AAAA;AAAA;;;;AAeO,eAAe;IACrB,IAAI;QACH,MAAM,WAAW,MAAM,IAAA,gMAAW,EAAC;YAAE,OAAO;QAAG;QAC/C,MAAM,UAAU,MAAM,IAAA,8LAAU,EAAC;YAAE,OAAO;QAAI;QAE9C,2BAA2B;QAC3B,MAAM,SAA+B,EAAE;QAEvC,IAAK,IAAI,IAAI,GAAG,IAAI,SAAS,MAAM,EAAE,IAAK;YACzC,MAAM,UAAU,QAAQ,CAAC,EAAE;YAC3B,MAAM,cAAc,QAAQ,CAAC,IAAI,EAAE;YAEnC,oDAAoD;YACpD,MAAM,iBAAiB,QAAQ,MAAM,CAAC,CAAC;gBACtC,IAAI,aAAa;oBAChB,OAAO,EAAE,IAAI,IAAI,QAAQ,IAAI,IAAI,EAAE,IAAI,GAAG,YAAY,IAAI;gBAC3D;gBACA,OAAO,EAAE,IAAI,IAAI,QAAQ,IAAI;YAC9B;YAEA,OAAO,IAAI,CAAC;gBACX;gBACA,SAAS,eAAe,KAAK,CAAC,GAAG;YAClC;QACD;QAEA,OAAO;IACR,EAAE,OAAO,OAAO;QACf,QAAQ,KAAK,CAAC,iCAAiC;QAC/C,OAAO,EAAE;IACV;AACD;AAEO,eAAe,iBAAiB,GAAW;IACjD,IAAI;QACH,MAAM,UAAU,MAAM,IAAA,8LAAU,EAAC;YAAE,OAAO;QAAE;QAC5C,MAAM,SAAS,QAAQ,IAAI,CAAC,CAAC,IAAM,EAAE,GAAG,KAAK,OAAO,EAAE,QAAQ,KAAK;QACnE,OAAO,UAAU;IAClB,EAAE,OAAO,OAAO;QACf,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO;IACR;AACD;AAEO,eAAe;IACrB,IAAI;QACH,MAAM,UAAU,MAAM,IAAA,8LAAU,EAAC,CAAC;QAClC,MAAM,kBAAkB,MAAM,IAAA,8MAAkB,EAAC,CAAC;QAClD,MAAM,eAAe,MAAM,IAAA,mNAAuB;QAElD,MAAM,eAAe,QAAQ,MAAM;QACnC,MAAM,kBAAkB,gBAAgB,MAAM;QAC9C,MAAM,UACL,gBAAgB,MAAM,CAAC,CAAC,KAAK,IAAM,MAAM,EAAE,SAAS,EAAE,KAAK,CAAC,gBAAgB,MAAM,IAAI,CAAC;QAExF,OAAO;YACN;YACA;YACA;YACA;QACD;IACD,EAAE,OAAO,OAAO;QACf,QAAQ,KAAK,CAAC,mCAAmC;QACjD,OAAO;YACN,cAAc;YACd,iBAAiB;YACjB,SAAS;YACT,cAAc,EAAE;QACjB;IACD;AACD;AAEO,eAAe,mBAAmB,YAAoB,EAAE;IAC9D,IAAI;QACH,OAAO,MAAM,IAAA,8MAAkB,EAAC;YAAE,SAAS;YAAW,OAAO;QAAG;IACjE,EAAE,OAAO,OAAO;QACf,QAAQ,KAAK,CAAC,qCAAqC;QACnD,OAAO,EAAE;IACV;AACD;;;IA/EsB;IAiCA;IAWA;IA4BA;;AAxEA,ydAAA;AAiCA,ydAAA;AAWA,ydAAA;AA4BA,ydAAA"}},
    {"offset": {"line": 3383, "column": 0}, "map": {"version":3,"sources":["file:///Users/andre/work/Roo-Code/apps/web-commit-analysis/.next-internal/server/app/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {getTimelineData as '008206b6ad99d6bae606bf10310876c9597b8f1515'} from 'ACTIONS_MODULE0'\nexport {getDashboardStats as '00ff52ab13a516834e168e95da9643206e1b50e5b1'} from 'ACTIONS_MODULE0'\nexport {getCommitDetails as '404c2ee49666f6ffedaa184592eca2e1d4e7e87c79'} from 'ACTIONS_MODULE0'\nexport {getHighRiskCommits as '40d6263b15d180508a8204e6199dbfc869813adb66'} from 'ACTIONS_MODULE0'\n"],"names":[],"mappings":";AAAA"}}]
}